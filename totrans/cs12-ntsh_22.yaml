- en: Chapter 22\. Parallel Programming
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第22章 并行编程
- en: 'In this chapter, we cover the multithreading APIs and constructs aimed at leveraging
    multicore processors:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了旨在利用多核处理器的多线程API和构造体：
- en: Parallel LINQ or *PLINQ*
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行LINQ或*PLINQ*
- en: The `Parallel` class
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Parallel`类'
- en: The *task parallelism* constructs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*任务并行*构造体'
- en: The *concurrent collections*
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发集合
- en: These constructs are collectively known (loosely) as Parallel Framework (PFX).
    The `Parallel` class together with the task parallelism constructs is called the
    *Task Parallel Library* (TPL).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些构造体（松散地）被称为Parallel Framework（PFX）。`Parallel`类与任务并行构造体一起被称为*任务并行库*（TPL）。
- en: You’ll need to be comfortable with the fundamentals in [Chapter 14](ch14.html#concurrency_and_asynchron)
    before reading this chapter—particularly locking, thread safety, and the `Task`
    class.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章之前，特别是锁定、线程安全和`Task`类，你需要熟悉[第14章](ch14.html#concurrency_and_asynchron)中的基础知识。
- en: Note
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '.NET offers a number of additional specialized APIs to help with parallel and
    asynchronous programming:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: .NET提供了许多专门的API来帮助并行和异步编程：
- en: '`System.Threading.Channels.Channel` is a high-performance asynchronous producer/consumer
    queue, introduced in .NET Core 3.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`System.Threading.Channels.Channel`是一个高性能的异步生产者/消费者队列，引入于.NET Core 3。'
- en: '*Microsoft Dataflow* (in the `System.Thread⁠ing.Tasks​.Dataflow` namespace)
    is a sophisticated API for creating networks of buffered *blocks* that execute
    actions or data transformations in parallel, with a semblance to actor/agent programming.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Microsoft Dataflow*（在`System.Thread⁠ing.Tasks​.Dataflow`命名空间中）是一个复杂的API，用于创建并行执行操作或数据转换的缓冲*块*网络，类似于actor/agent编程。'
- en: '*Reactive Extensions* implements LINQ over `IObservable` (an alternative abstraction
    to `IAsyncEnumerable`) and excels at combining asynchronous streams. Reactive
    extensions ships in the *System.Reactive* NuGet package.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*响应式扩展*实现了LINQ在`IObservable`（与`IAsyncEnumerable`的替代抽象）上，并擅长于组合异步流。响应式扩展在*System.Reactive*
    NuGet包中发布。'
- en: Why PFX?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么使用PFX？
- en: Over the past 15 years, CPU manufacturers have shifted from single-core to multicore
    processors. This is problematic for us as programmers because single-threaded
    code does not automatically run faster as a result of those extra cores.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的15年中，CPU制造商已经从单核转向多核处理器。这对程序员来说是个问题，因为单线程代码不会因为额外的核心而自动运行得更快。
- en: 'Utilizing multiple cores is easy for most server applications, where each thread
    can independently handle a separate client request, but it’s more difficult on
    the desktop because it typically requires that you take your computationally intensive
    code and do the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数服务器应用程序来说，利用多核是很容易的，每个线程可以独立处理一个单独的客户端请求，但是在桌面上更难，因为通常需要将计算密集型代码拿出来并执行以下操作：
- en: '*Partition* it into small chunks.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将其分割*成小块。'
- en: Execute those chunks in parallel via multithreading.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过多线程并行执行这些块。
- en: '*Collate* the results as they become available, in a thread-safe and performant
    manner.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*整理*结果，以线程安全和高性能的方式。'
- en: Although you can do all of this with the classic multithreading constructs,
    it’s awkward—particularly the steps of partitioning and collating. A further problem
    is that the usual strategy of locking for thread safety causes a lot of contention
    when many threads work on the same data at once.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以使用经典的多线程构造体完成所有这些工作，但这样做很笨重——特别是分割和整理的步骤。另一个问题是，在许多线程同时处理相同数据时，常规的线程安全锁定策略会导致很多争用。
- en: The PFX libraries have been designed specifically to help in these scenarios.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PFX库专门设计用于帮助这些场景。
- en: Note
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Programming to leverage multicores or multiple processors is called *parallel
    programming*. This is a subset of the broader concept of multithreading.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 利用多核或多处理器进行编程被称为*并行编程*。这是多线程概念的一个子集。
- en: PFX Concepts
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PFX概念
- en: 'There are two strategies for partitioning work among threads: *data parallelism*
    and *task parallelism*.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种策略用于在线程之间分区工作：*数据并行*和*任务并行*。
- en: When a set of tasks must be performed on many data values, we can parallelize
    by having each thread perform the (same) set of tasks on a subset of values. This
    is called *data parallelism* because we are partitioning the *data* between threads.
    In contrast, with *task parallelism* we partition the *tasks*; in other words,
    we have each thread perform a different task.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要在许多数据值上执行一组任务时，我们可以通过让每个线程在值的子集上执行（相同的）任务集来并行化。这被称为*数据并行性*，因为我们在线程之间分区*数据*。相比之下，*任务并行性*是分区*任务*；换句话说，我们让每个线程执行不同的任务。
- en: In general, data parallelism is easier and scales better to highly parallel
    hardware because it reduces or eliminates shared data (thereby reducing contention
    and thread-safety issues). Also, data parallelism exploits the fact that there
    are often more data values than discrete tasks, increasing the parallelism potential.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，数据并行性更简单，并且更适应高度并行硬件，因为它减少或消除了共享数据（从而减少争用和线程安全问题）。此外，数据并行性利用了数据值通常比离散任务多的事实，增加了并行化的潜力。
- en: Data parallelism is also conducive to *structured parallelism*, which means
    that parallel work units start and finish in the same place in your program. In
    contrast, task parallelism tends to be unstructured, meaning that parallel work
    units may start and finish in places scattered across your program. Structured
    parallelism is simpler and less error prone and allows you to farm the difficult
    job of partitioning and thread coordination (and even result collation) out to
    libraries.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行性也有助于*结构化并行性*，这意味着并行工作单元在程序中的开始和结束在同一地点。相反，任务并行性往往是非结构化的，意味着并行工作单元可能在程序中分散的位置开始和结束。结构化并行性更简单，更少出错，并允许您将分区和线程协调（甚至结果整合）的困难工作交给库处理。
- en: PFX Components
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PFX 组件
- en: 'PFX comprises two layers of functionality, as shown in [Figure 22-1](#pfx_components-id00085).
    The higher layer consists of two *structured data parallelism* APIs: PLINQ and
    the `Parallel` class. The lower layer contains the task parallelism classes—plus
    a set of additional constructs to help with parallel programming activities.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: PFX 由两层功能组成，如[图 22-1](#pfx_components-id00085) 所示。较高层包括两个*结构化数据并行性* API：PLINQ
    和 `Parallel` 类。较低层包含任务并行性类以及一组额外的构造用于帮助并行编程活动。
- en: '![PFX components](assets/cn10_2201.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![PFX 组件](assets/cn10_2201.png)'
- en: Figure 22-1\. PFX components
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 22-1\. PFX 组件
- en: 'PLINQ offers the richest functionality: it automates all the steps of parallelization—including
    partitioning the work into tasks, executing those tasks on threads, and collating
    the results into a single output sequence. It’s called *declarative*—because you
    simply declare that you want to parallelize your work (which you structure as
    a LINQ query) and let the runtime take care of the implementation details. In
    contrast, the other approaches are *imperative*, in that you need to explicitly
    write code to partition or collate. As the following synopsis shows, in the case
    of the `Parallel` class, you must collate results yourself; with the task parallelism
    constructs, you must partition the work yourself, too:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ 提供了最丰富的功能：它自动化了并行化的所有步骤，包括将工作分区为任务、在线程上执行这些任务以及将结果整合为单一输出序列。它被称为*声明性*，因为您只需声明要并行化的工作（将其结构化为
    LINQ 查询），然后让运行时处理实现细节。相比之下，其他方法是*命令式*的，您需要显式编写代码来分区或整合。如下面的概述所示，在`Parallel` 类的情况下，您必须自行整合结果；而在任务并行性构造中，您还必须自行分区工作：
- en: '|  | Partitions work | Collates results |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | 分区工作 | 整合结果 |'
- en: '| --- | --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| PLINQ | Yes | Yes |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| PLINQ | 是 | 是 |'
- en: '| The `Parallel` class | Yes | No |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `Parallel` 类 | 是 | 否 |'
- en: '| PFX’s task parallelism | No | No |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| PFX 的任务并行性 | 否 | 否 |'
- en: 'The concurrent collections and spinning primitives help you with lower-level
    parallel programming activities. These are important because PFX has been designed
    to work not only with today’s hardware, but also with future generations of processors
    with far more cores. If you want to move a pile of chopped wood and you have 32
    workers to do the job, the biggest challenge is moving the wood without the workers
    getting in each other’s way. It’s the same with dividing an algorithm among 32
    cores: if ordinary locks are used to protect common resources, the resultant blocking
    can mean that only a fraction of those cores are ever actually busy at once. The
    concurrent collections are tuned specifically for highly concurrent access, with
    the focus on minimizing or eliminating blocking. PLINQ and the `Parallel` class
    themselves rely on the concurrent collections and on spinning primitives for efficient
    management of work.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 并发集合和自旋原语帮助您处理低级并行编程活动。这些很重要，因为PFX不仅设计用于当前的硬件，还可以适用于未来更多核心的处理器。如果你想搬运一堆劈好的木头，有32名工人来做这份工作，最大的挑战是在不让工人互相干扰的情况下搬动木头。同样的情况也出现在将算法分配给32个核心上：如果使用普通的锁来保护共享资源，由此引起的阻塞可能意味着只有少部分核心实际上忙碌。并发集合专门针对高度并发访问进行了调整，重点是尽量减少或消除阻塞。PLINQ和`Parallel`类本身依赖于并发集合和自旋原语，以有效地管理工作。
- en: When to Use PFX
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PFX的时机
- en: 'The primary use case for PFX is *parallel programming*: leveraging multicore
    processors to speed up computationally intensive code.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: PFX的主要用途是*并行编程*：利用多核处理器加速计算密集型代码。
- en: A challenge in parallel programming is Amdahl’s law, which states that the maximum
    performance improvement from parallelization is governed by the portion of the
    code that must execute sequentially. For instance, if only two-thirds of an algorithm’s
    execution time is parallelizable, you can never exceed a threefold performance
    gain—even with an infinite number of cores.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 并行编程中的挑战之一是阿姆达尔定律，该定律指出并行化带来的最大性能提升受限于必须顺序执行的代码部分。例如，如果算法执行时间的三分之二只能并行化，即使有无限数量的核心，性能提升也不能超过三倍。
- en: So, before proceeding, it’s worth verifying that the bottleneck is in parallelizable
    code. It’s also worth considering whether your code *needs* to be computationally
    intensive—optimization is often the easiest and most effective approach. There’s
    a trade-off, though, in that some optimization techniques can make it more difficult
    to parallelize code.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在继续之前，值得验证的是瓶颈是否在可以并行化的代码上。还值得考虑的是，你的代码是否*需要*计算密集型—优化通常是最简单和最有效的方法。然而，有一个权衡，某些优化技术可能会使代码更难以并行化。
- en: The easiest gains come with what’s called *embarrassingly parallel* problems—this
    is when a job can be easily divided into tasks that efficiently execute on their
    own (structured parallelism is very well suited to such problems). Examples include
    many image-processing tasks, ray tracing, and brute-force approaches in mathematics
    or cryptography. An example of a non-embarrassingly parallel problem is implementing
    an optimized version of the quicksort algorithm—a good result takes some thought
    and might require unstructured parallelism.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最容易获得的收益来自于所谓的*极易并行*问题—当工作可以轻松地分成有效执行的任务时（结构化并行非常适合这类问题）。例如，许多图像处理任务、光线追踪以及数学或密码学中的穷举方法都属于此类问题。非极易并行问题的一个例子是实现快速排序算法的优化版本—这需要一些思考，并且可能需要非结构化的并行。
- en: PLINQ
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PLINQ
- en: PLINQ automatically parallelizes local LINQ queries. PLINQ has the advantage
    of being easy to use in that it offloads the burden of both work partitioning
    and result collation to .NET.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ会自动并行化本地LINQ查询。PLINQ的优势在于使用简单，因为它将工作分割和结果收集的负担都交给了.NET。
- en: 'To use PLINQ, simply call `AsParallel()` on the input sequence and then continue
    the LINQ query as usual. The following query calculates the prime numbers between
    3 and 100,000, making full use of all cores on the target machine:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用PLINQ，只需在输入序列上调用`AsParallel()`，然后像往常一样继续LINQ查询。以下查询计算了在3到100,000之间的素数，充分利用了目标机器上的所有核心：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`AsParallel` is an extension method in `System.Linq.ParallelEnumerable`. It
    wraps the input in a sequence based on `ParallelQuery<TSource>`, which causes
    the LINQ query operators that you subsequently call to bind to an alternate set
    of extension methods defined in `ParallelEnumerable`. These provide parallel implementations
    of each of the standard query operators. Essentially, they work by partitioning
    the input sequence into chunks that execute on different threads, collating the
    results back into a single output sequence for consumption, as depicted in [Figure 22-2](#plinq_execution_model).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`AsParallel` 是 `System.Linq.ParallelEnumerable` 中的扩展方法。它将输入包装在基于 `ParallelQuery<TSource>`
    的序列中，这会导致随后调用的 LINQ 查询操作符绑定到在 `ParallelEnumerable` 中定义的另一组扩展方法。这些方法提供了每个标准查询操作符的并行实现。基本上，它们通过将输入序列分区为在不同线程上执行的块，并将结果汇总回一个用于消费的单个输出序列中，如
    [图 22-2](#plinq_execution_model) 所示。'
- en: '![PLINQ execution model](assets/cn10_2202.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![PLINQ 执行模型](assets/cn10_2202.png)'
- en: Figure 22-2\. PLINQ execution model
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 22-2\. PLINQ 执行模型
- en: Calling `AsSequential()` unwraps a `ParallelQuery` sequence so that subsequent
    query operators bind to the standard query operators and execute sequentially.
    This is necessary before calling methods that have side effects or are not thread-safe.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `AsSequential()` 会取消 `ParallelQuery` 序列的包装，这样随后的查询操作符就会绑定到标准查询操作符并按顺序执行。在调用具有副作用或不是线程安全的方法之前，这是必要的。
- en: 'For query operators that accept two input sequences (`Join`, `GroupJoin`, `Concat`,
    `Union`, `Intersect`, `Except`, and `Zip`), you must apply `AsParallel()` to both
    input sequences (otherwise, an exception is thrown). You don’t, however, need
    to keep applying `AsParallel` to a query as it progresses, because PLINQ’s query
    operators output another `ParallelQuery` sequence. In fact, calling `AsParallel`
    again introduces inefficiency in that it forces merging and repartitioning of
    the query:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接受两个输入序列的查询操作符（`Join`、`GroupJoin`、`Concat`、`Union`、`Intersect`、`Except` 和
    `Zip`），你必须对两个输入序列都应用 `AsParallel()`（否则会抛出异常）。然而，你无需在查询进度中继续应用 `AsParallel`，因为
    PLINQ 的查询操作符会输出另一个 `ParallelQuery` 序列。事实上，再次调用 `AsParallel` 会导致效率低下，因为它会强制合并和重新分区查询：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Not all query operators can be effectively parallelized. For those that cannot
    (see [“PLINQ Limitations”](#plinq_limitations)), PLINQ implements the operator
    sequentially, instead. PLINQ might also operate sequentially if it suspects that
    the overhead of parallelization will actually slow a particular query.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有查询操作符都能有效地并行化。对于那些不能并行化的操作符（参见 [“PLINQ 限制”](#plinq_limitations)），PLINQ 将顺序实现该操作符。如果
    PLINQ 怀疑并行化的开销实际上会减慢特定查询的速度，它也可能会顺序操作。
- en: 'PLINQ is only for local collections: it doesn’t work with Entity Framework,
    for instance, because in those cases the LINQ translates into SQL, which then
    executes on a database server. However, you *can* use PLINQ to perform additional
    local querying on the result sets obtained from database queries.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ 仅适用于本地集合：例如，它不能与 Entity Framework 一起使用，因为在这些情况下，LINQ 会转换为 SQL，然后在数据库服务器上执行。但是，你*可以*使用
    PLINQ 对从数据库查询中获取的结果集执行额外的本地查询。
- en: Warning
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: If a PLINQ query throws an exception, it’s rethrown as an `AggregateException`
    whose `InnerExceptions` property contains the real exception (or exceptions).
    For more details, see [“Working with AggregateException”](#working_with_aggregateexception).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 PLINQ 查询引发异常，则会作为 `AggregateException` 重新抛出，其 `InnerExceptions` 属性包含实际的异常（或异常）。有关详细信息，请参阅
    [“使用 AggregateException”](#working_with_aggregateexception)。
- en: Parallel Execution Ballistics
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行执行的策略
- en: Like ordinary LINQ queries, PLINQ queries are lazily evaluated. This means that
    execution is triggered only when you begin consuming the results—typically via
    a `foreach` loop (although it can also be via a conversion operator such as `ToArray`
    or an operator that returns a single element or value).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 像普通的 LINQ 查询一样，PLINQ 查询也是惰性评估的。这意味着只有在开始消耗结果时才会触发执行，通常通过 `foreach` 循环（尽管也可以通过像
    `ToArray` 这样的转换操作符或返回单个元素或值的操作符来触发）。
- en: 'As you enumerate the results, though, execution proceeds somewhat differently
    from that of an ordinary sequential query. A sequential query is powered entirely
    by the consumer in a “pull” fashion: each element from the input sequence is fetched
    exactly when required by the consumer. A parallel query ordinarily uses independent
    threads to fetch elements from the input sequence slightly *ahead* of when they’re
    needed by the consumer (rather like a teleprompter for newsreaders). It then processes
    the elements in parallel through the query chain, holding the results in a small
    buffer so that they’re ready for the consumer on demand. If the consumer pauses
    or breaks out of the enumeration early, the query processor also pauses or stops
    so as not to waste CPU time or memory.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在枚举结果时，执行方式与普通的顺序查询有些不同。顺序查询完全由消费者以“拉取”方式驱动：输入序列的每个元素都会在消费者需要时精确获取。并行查询通常使用独立线程轻微提前获取输入序列中的元素（类似于新闻主播的电视提词器）。然后通过查询链并行处理元素，并将结果保存在小缓冲区中，以便按需提供给消费者。如果消费者暂停或提前退出枚举，查询处理器也会暂停或停止，以避免浪费
    CPU 时间或内存。
- en: Note
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can tweak PLINQ’s buffering behavior by calling `WithMergeOptions` after
    `AsParallel`. The default value of `AutoBuffered` generally gives the best overall
    results. `NotBuffered` disables the buffer and is useful if you want to see results
    as soon as possible; `FullyBuffered` caches the entire result set before presenting
    it to the consumer (the `OrderBy` and `Reverse` operators naturally work this
    way, as do the element, aggregation, and conversion operators).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 `AsParallel` 后调用 `WithMergeOptions` 调整 PLINQ 的缓冲行为。`AutoBuffered` 的默认值通常提供最佳的整体结果。`NotBuffered`
    禁用缓冲区，如果你希望尽快看到结果，则很有用；`FullyBuffered` 在向消费者呈现整个结果集之前缓存整个结果（`OrderBy` 和 `Reverse`
    操作符自然以此方式工作，聚合和转换操作符也是如此）。
- en: PLINQ and Ordering
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PLINQ 和排序
- en: A side effect of parallelizing the query operators is that when the results
    are collated, it’s not necessarily in the same order that they were submitted
    (see [Figure 22-2](#plinq_execution_model)). In other words, LINQ’s normal order-preservation
    guarantee for sequences no longer holds.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化查询操作符的一个副作用是，在整理结果时，它们的顺序不一定与提交时的顺序相同（参见 [图 22-2](#plinq_execution_model)）。换句话说，LINQ
    对序列的正常顺序保留保证不再适用。
- en: 'If you need order preservation, you can force it by calling `AsOrdered()` after
    `AsParallel()`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要保留顺序，可以在 `AsParallel()` 后调用 `AsOrdered()` 强制执行：
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Calling `AsOrdered` incurs a performance hit with large numbers of elements
    because PLINQ must keep track of each element’s original position.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `AsOrdered` 会导致大量元素时的性能损失，因为 PLINQ 必须跟踪每个元素的原始位置。
- en: 'You can negate the effect of `AsOrdered` later in a query by calling `AsUnordered`:
    this introduces a “random shuffle point,” which allows the query to execute more
    efficiently from that point on. So, if you wanted to preserve input-sequence ordering
    for just the first two query operators, you’d do this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过调用 `AsUnordered` 来取消 `AsOrdered` 在查询中的影响：这引入了一个“随机洗牌点”，允许查询从那一点开始更高效地执行。因此，如果你只想保留前两个查询操作的输入顺序，可以这样做：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`AsOrdered` is not the default because for most queries, the original input
    ordering doesn’t matter. In other words, if `AsOrdered` were the default, you’d
    need to apply `AsUnordered` to the majority of your parallel queries to get the
    best performance, which would be burdensome.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`AsOrdered` 不是默认选项，因为对于大多数查询来说，原始输入的顺序并不重要。换句话说，如果 `AsOrdered` 是默认选项，你需要对大多数并行查询应用
    `AsUnordered` 以获得最佳性能，这会增加负担。'
- en: PLINQ Limitations
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PLINQ 的限制
- en: 'There are practical limitations on what PLINQ can parallelize. The following
    query operators prevent parallelization by default unless the source elements
    are in their original indexing position:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在什么情况下 PLINQ 可以并行化存在实际限制。以下查询操作符默认情况下阻止并行化，除非源元素处于它们的原始索引位置：
- en: The indexed versions of `Select`, `SelectMany`, and `ElementAt`
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Select`、`SelectMany` 和 `ElementAt` 的索引版本'
- en: Most query operators change the indexing position of elements (including those
    that remove elements, such as `Where`). This means that if you want to use the
    preceding operators, they’ll usually need to be at the start of the query.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数查询操作符会更改元素的索引位置（包括删除元素的操作，如 `Where`）。这意味着如果要使用前面的操作符，它们通常需要位于查询的开始位置。
- en: 'The following query operators are parallelizable but use an expensive partitioning
    strategy that can sometimes be slower than sequential processing:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下列查询运算符是可以并行化的，但使用昂贵的分区策略，有时比顺序处理更慢：
- en: '`Join`, `GroupBy`, `GroupJoin`, `Distinct`, `Union`, `Intersect`, and `Except`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Join`、`GroupBy`、`GroupJoin`、`Distinct`、`Union`、`Intersect`和`Except`'
- en: The `Aggregate` operator’s *seeded* overloads in their standard incarnations
    are not parallelizable—PLINQ provides special overloads to deal with this (see
    [“Optimizing PLINQ”](#optimizing_plinq)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`Aggregate`运算符的标准化版本的*种子*重载不可并行化 —— PLINQ提供了特殊的重载来处理这个问题（见[“优化PLINQ”](#optimizing_plinq)）。'
- en: 'All other operators are parallelizable, although use of these operators doesn’t
    guarantee that your query will be parallelized. PLINQ might run your query sequentially
    if it suspects that the overhead of parallelization will slow down that particular
    query. You can override this behavior and force parallelism by calling the following
    after `AsParallel()`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他运算符都是可以并行化的，尽管使用这些运算符并不保证您的查询会并行化。如果PLINQ认为并行化的开销会减慢特定查询的速度，它可能会顺序运行您的查询。您可以在`AsParallel()`后调用以下方法来覆盖此行为并强制并行处理：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Example: Parallel Spellchecker'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：并行拼写检查器
- en: Suppose that we want to write a spellchecker that runs quickly with very large
    documents by utilizing all available cores. By formulating our algorithm into
    a LINQ query, we can very easily parallelize it.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要编写一个拼写检查器，通过利用所有可用核心，快速处理非常大的文档。通过将我们的算法制定为LINQ查询，我们可以非常容易地并行化它。
- en: 'The first step is to download a dictionary of English words into a `HashSet`
    for efficient lookup:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将英文单词的字典下载到一个`HashSet`中，以便进行高效的查找：
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We then use our word lookup to create a test “document” comprising an array
    of a million random words. After we build the array, let’s introduce a couple
    of spelling mistakes:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用我们的单词查找来创建一个测试“文档”，包含一个百万个随机单词的数组。在我们构建数组之后，让我们引入一些拼写错误：
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we can perform our parallel spellcheck by testing `wordsToTest` against
    `wordLookup`. PLINQ makes this very easy:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过将`wordsToTest`与`wordLookup`进行测试来执行并行拼写检查。PLINQ使这一过程非常简单：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `wordLookup.Contains` method in the predicate gives the query some “meat”
    and makes it worth parallelizing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 谓词中的`wordLookup.Contains`方法为查询提供了一些“实质”，使其值得并行化。
- en: Note
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Notice that our query uses tuples `(word, index)` rather than anonymous types.
    Because tuples are implemented as value types rather than reference types, this
    improves peak memory consumption and performance by reducing heap allocations
    and subsequent garbage collections. (Benchmarking reveals the gains to be moderate
    in practice, due to the efficiency of the memory manager and the fact that the
    allocations in question don’t survive beyond Generation 0.)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的查询使用元组`(word, index)`而不是匿名类型。因为元组是作为值类型而不是引用类型实现的，这通过减少堆分配和随后的垃圾回收，改善了峰值内存消耗和性能。（基准测试显示，在实践中，由于内存管理器的效率和这些分配不超过Generation
    0，这些收益是适度的。）
- en: Using ThreadLocal<T>
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用`ThreadLocal<T>`
- en: 'Let’s extend our example by parallelizing the creation of the random test-word
    list itself. We structured this as a LINQ query, so it should be easy. Here’s
    the sequential version:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过并行化随机测试词列表的创建来扩展我们的示例。我们将其构造为LINQ查询，因此应该很容易。以下是顺序版本：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Unfortunately, the call to `random.Next` is not thread-safe, so it’s not as
    simple as inserting `AsParallel()` into the query. A potential solution is to
    write a function that locks around `random.Next`; however, this would limit concurrency.
    The better option is to use `ThreadLocal<Random>` (see [“Thread-Local Storage”](ch21.html#thread_local_storage))
    to create a separate `Random` object for each thread. We then can parallelize
    the query, as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，对`random.Next`的调用不是线程安全的，因此将`AsParallel()`插入查询中并不简单。一个潜在的解决方案是编写一个在`random.Next`周围加锁的函数；然而，这会限制并发性。更好的选择是使用`ThreadLocal<Random>`（参见[“线程本地存储”](ch21.html#thread_local_storage)），为每个线程创建一个单独的`Random`对象。然后我们可以按如下方式并行化查询：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In our factory function for instantiating a `Random` object, we pass in a `Guid`’s
    hashcode to ensure that if two `Random` objects are created within a short period
    of time, they’ll yield different random number sequences.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们用于实例化`Random`对象的工厂函数中，我们传递一个`Guid`的哈希码，以确保如果在短时间内创建了两个`Random`对象，它们将产生不同的随机数序列。
- en: Functional Purity
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 函数纯度
- en: 'Because PLINQ runs your query on parallel threads, you must be careful not
    to perform thread-unsafe operations. In particular, writing to variables is *side-effecting*
    and therefore thread-unsafe:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 PLINQ 在并行线程上运行查询，所以必须小心不要执行线程不安全的操作。特别是写入变量是*副作用*，因此是线程不安全的：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We could make incrementing `i` thread-safe by using locks, but the problem would
    still remain that `i` won’t necessarily correspond to the position of the input
    element. And adding `AsOrdered` to the query wouldn’t fix the latter problem,
    because `AsOrdered` ensures only that the elements are output in an order consistent
    with them having been processed sequentially—it doesn’t actually *process* them
    sequentially.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用锁使增加`i`线程安全，但问题仍然存在，即`i`不一定对应于输入元素的位置。并且添加`AsOrdered`到查询中也不能解决后一个问题，因为`AsOrdered`仅确保元素按照它们被顺序处理的顺序输出——它实际上不会*顺序处理*它们。
- en: 'The correct solution is to rewrite our query to use the indexed version of
    `Select`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的解决方案是重写我们的查询，使用索引版本的`Select`：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For best performance, any methods called from query operators should be thread-safe
    by virtue of not writing to fields or properties (non-side-effecting, or *functionally
    pure*). If they’re thread-safe by virtue of *locking*, the query’s parallelism
    potential will be limited by the effects of contention.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最佳性能，从查询操作符调用的任何方法都应该通过不写入字段或属性（非副作用，或*功能纯粹*）来保持线程安全。如果它们通过*锁定*而不是副作用来保持线程安全，查询的并行潜力将受到争用效果的限制。
- en: Setting the Degree of Parallelism
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置并行度
- en: 'By default, PLINQ chooses an optimum degree of parallelism for the processor
    in use. You can override it by calling `WithDegreeOfParallelism` after `AsParallel`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，PLINQ选择适合正在使用的处理器的最佳并行度。您可以通过在`AsParallel`后调用`WithDegreeOfParallelism`来覆盖它：
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: An example of when you might increase the parallelism beyond the core count
    is with I/O-bound work (downloading many web pages at once, for instance). However,
    task combinators and asynchronous functions provide a similarly easy and more
    *efficient* solution (see [“Task Combinators”](ch14.html#task_combinators)). Unlike
    with `Task`s, PLINQ cannot perform I/O-bound work without blocking threads (and
    *pooled* threads, to make matters worse).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是在 I/O 绑定的工作中可能会增加并行性（例如同时下载多个网页）。然而，任务组合器和异步函数提供了一个同样简单且更*高效*的解决方案（参见[“任务组合器”](ch14.html#task_combinators)）。与`Task`不同，PLINQ无法执行I/O绑定工作而不阻塞线程（并且*池化*线程会使情况变得更糟）。
- en: Changing the degree of parallelism
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更改并行度
- en: 'You can call `WithDegreeOfParallelism` only once within a PLINQ query. If you
    need to call it again, you must force merging and repartitioning of the query
    by calling `AsParallel()` again within the query:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PLINQ 查询中，只能调用一次`WithDegreeOfParallelism`。如果需要再次调用它，必须通过在查询中再次调用`AsParallel()`来强制合并和重新分区查询：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Cancellation
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 取消
- en: 'Canceling a PLINQ query whose results you’re consuming in a `foreach` loop
    is easy: simply break out of the `foreach` and the query will be automatically
    canceled as the enumerator is implicitly disposed.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 取消在 `foreach` 循环中消耗其结果的 PLINQ 查询非常简单：只需中断 `foreach`，查询将自动取消，因为枚举器会被隐式处理。
- en: 'For a query that terminates with a conversion, element, or aggregation operator,
    you can cancel it from another thread via a *cancellation token* (see [“Cancellation”](ch14.html#cancellation)).
    To insert a token, call `WithCancellation` after calling `AsParallel`, passing
    in the `Token` property of a `CancellationTokenSource` object. Another thread
    can then call `Cancel` on the token source (or we can call it ourselves with a
    delay). This then throws an `OperationCanceledException` on the query’s consumer:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以转换、元素或聚合操作结束的查询，可以通过*取消令牌*（参见[“取消”](ch14.html#cancellation)）从另一个线程取消它。要插入一个令牌，在调用`AsParallel`后调用`WithCancellation`，传递`CancellationTokenSource`对象的`Token`属性。然后，另一个线程可以调用令牌源的`Cancel`（或者我们可以自己延迟调用）。然后，在查询的消费者上抛出`OperationCanceledException`：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Upon cancellation, PLINQ waits for each worker thread to finish with its current
    element before ending the query. This means that any external methods that the
    query calls will run to completion.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在取消时，PLINQ 等待每个工作线程完成其当前元素后结束查询。这意味着查询调用的任何外部方法都将完全运行。
- en: Optimizing PLINQ
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化 PLINQ
- en: Output-side optimization
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出端优化
- en: 'One of PLINQ’s advantages is that it conveniently collates the results from
    parallelized work into a single output sequence. Sometimes, though, all that you
    end up doing with that sequence is running some function once over each element:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ的一个优点是方便地将并行工作的结果整理到单一输出序列中。但有时，您需要做的只是对每个元素运行某个函数一次：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If this is the case—and you don’t care about the order in which the elements
    are processed—you can improve efficiency with PLINQ’s `ForAll` method.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这种情况——并且您不关心元素处理顺序——您可以通过PLINQ的`ForAll`方法提高效率。
- en: 'The `ForAll` method runs a delegate over every output element of a `ParallelQuery`.
    It hooks directly into PLINQ’s internals, bypassing the steps of collating and
    enumerating the results. Here’s a trivial example:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`ForAll`方法在`ParallelQuery`的每个输出元素上运行委托。它直接连接到PLINQ的内部，跳过整理和枚举结果的步骤。这里是一个简单的示例：'
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Figure 22-3](#plinq_forall) shows the process.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 22-3](#plinq_forall)展示了该过程。'
- en: '![PLINQ ForAll](assets/cn10_2203.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![PLINQ ForAll](assets/cn10_2203.png)'
- en: Figure 22-3\. PLINQ `ForAll`
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 22-3\. PLINQ `ForAll`
- en: Note
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Collating and enumerating results is not a massively expensive operation, so
    the `ForAll` optimization yields the greatest gains when there are large numbers
    of quickly executing input elements.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 整理和枚举结果并非代价高昂，因此`ForAll`优化在输入元素快速执行较多的情况下获得最大收益。
- en: Input-side optimization
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入端优化
- en: 'PLINQ has three partitioning strategies for assigning input elements to threads:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ有三种分区策略用于将输入元素分配给线程：
- en: '| Strategy | Element allocation | Relative performance |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | 元素分配 | 相对性能 |'
- en: '| --- | --- | --- |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Chunk partitioning | Dynamic | Average |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 分块分区 | 动态 | 平均 |'
- en: '| Range partitioning | Static | Poor to excellent |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 范围分区 | 静态 | 差至优 |'
- en: '| Hash partitioning | Static | Poor |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 哈希分区 | 静态 | 一般 |'
- en: 'For query operators that require comparing elements (`GroupBy`, `Join`, `GroupJoin`,
    `Intersect`, `Except`, `Union`, and `Distinct`), you have no choice: PLINQ always
    uses *hash partitioning*. Hash partitioning is relatively inefficient in that
    it must precalculate the hashcode of every element (so that elements with identical
    hashcodes can be processed on the same thread). If you find this to be too slow,
    your only option is to call `AsSequential` to disable parallelization.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要比较元素的查询操作符（`GroupBy`、`Join`、`GroupJoin`、`Intersect`、`Except`、`Union`和`Distinct`），您没有选择：PLINQ始终使用*哈希分区*。哈希分区相对低效，因为它必须预先计算每个元素的哈希码（以便具有相同哈希码的元素可以在同一线程上处理）。如果发现这太慢，则唯一选择是调用`AsSequential`禁用并行化。
- en: 'For all other query operators, you have a choice as to whether to use range
    or chunk partitioning. By default:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有其他查询操作符，您可以选择使用范围或分块分区。默认情况下：
- en: If the input sequence is *indexable* (if it’s an array or implements `IList<T>`),
    PLINQ chooses *range partitioning*.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果输入序列是*可索引*的（如果是数组或实现了`IList<T>`），PLINQ会选择*范围分区*。
- en: Otherwise, PLINQ chooses *chunk partitioning*.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，PLINQ会选择*分块分区*。
- en: In a nutshell, range partitioning is faster with long sequences for which every
    element takes a similar amount of CPU time to process. Otherwise, chunk partitioning
    is usually faster.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 简言之，对于每个元素处理时间相似且序列较长的情况下，范围分区更快。否则，通常分块分区更快。
- en: 'To force range partitioning:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 要强制执行范围分区：
- en: If the query starts with `Enumerable.Range`, replace that method with `ParallelEnumerable.Range`.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果查询以`Enumerable.Range`开始，请用`ParallelEnumerable.Range`替换该方法。
- en: Otherwise, simply call `ToList` or `ToArray` on the input sequence (obviously,
    this incurs a performance cost in itself, which you should take into account).
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，只需在输入序列上调用`ToList`或`ToArray`（显然，这本身会带来性能成本，需要考虑）。
- en: Warning
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: '`ParallelEnumerable.Range` is not simply a shortcut for calling `Enumerable.Range(`…`).AsParallel()`.
    It changes the performance of the query by activating range partitioning.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`ParallelEnumerable.Range`不仅仅是调用`Enumerable.Range(`…`)AsParallel()`的捷径。它通过激活范围分区来改变查询的性能。'
- en: 'To force chunk partitioning, wrap the input sequence in a call to `Partitioner.Create`
    (in `System.Collection.Concurrent`), as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要强制进行分块分区，请将输入序列封装在调用`Partitioner.Create`（在`System.Collection.Concurrent`中）中，如下所示：
- en: '[PRE17]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The second argument to `Partitioner.Create` indicates that you want to *load-balance*
    the query, which is another way of saying that you want chunk partitioning.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数`Partitioner.Create`指示您希望*负载均衡*查询，这也意味着您希望分块分区。
- en: 'Chunk partitioning works by having each worker thread periodically grab small
    “chunks” of elements from the input sequence to process (see [Figure 22-4](#chunk_versus_range_partitioning)).
    PLINQ starts by allocating very small chunks (one or two elements at a time).
    It then increases the chunk size as the query progresses: this ensures that small
    sequences are effectively parallelized and large sequences don’t cause excessive
    round-tripping. If a worker happens to get “easy” elements (that process quickly),
    it will end up getting more chunks. This system keeps every thread equally busy
    (and the cores “balanced”); the only downside is that fetching elements from the
    shared input sequence requires synchronization (typically an exclusive lock)—and
    this can result in some overhead and contention.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 块划分通过让每个工作线程定期从输入序列中抓取小的“块”元素来处理工作（见 [图 22-4](#chunk_versus_range_partitioning)）。PLINQ
    从分配非常小的块开始（每次一个或两个元素）。随着查询的进行，它会增加块的大小：这确保了小序列能够有效并行化处理，而大序列则不会导致过多的往返。如果一个工作线程处理起来“容易”的元素（即处理速度快），它最终会获取更多的块。这个系统保持了每个线程同样忙碌（和核心“平衡”）；唯一的缺点是从共享输入序列中获取元素需要同步（通常是独占锁定），这可能会导致一些开销和竞争。
- en: 'Range partitioning bypasses the normal input-side enumeration and preallocates
    an equal number of elements to each worker, avoiding contention on the input sequence.
    But if some threads happen to get easy elements and finish early, they sit idle
    while the remaining threads continue working. Our earlier prime number calculator
    might perform poorly with range partitioning. An example of when range partitioning
    would do well is in calculating the sum of the square roots of the first 10 million
    integers:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 范围划分绕过了正常的输入端枚举，并预先分配了相等数量的元素给每个工作线程，避免了在输入序列上的竞争。但是，如果一些线程碰巧获得简单的元素并且早早地完成，它们会空闲，而剩余的线程则继续工作。我们之前的素数计算器在使用范围划分时可能性能不佳。范围划分能很好地处理以下情况，即计算前
    1000 万个整数的平方根的和：
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![Chunk versus range partitioning](assets/cn10_2204.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![块划分与范围划分](assets/cn10_2204.png)'
- en: Figure 22-4\. Chunk versus range partitioning
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 22-4\. 块划分与范围划分
- en: '`ParallelEnumerable.Range` returns a `ParallelQuery<T>`, so you don’t need
    to subsequently call `AsParallel`.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`ParallelEnumerable.Range` 返回一个 `ParallelQuery<T>`，因此无需随后调用 `AsParallel`。'
- en: Note
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Range partitioning doesn’t necessarily allocate element ranges in *contiguous*
    blocks—it might instead choose a “striping” strategy. For instance, if there are
    two workers, one worker might process odd-numbered elements while the other processes
    even-numbered elements. The `TakeWhile` operator is almost certain to trigger
    a striping strategy to avoid unnecessarily processing elements later in the sequence.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 范围划分并不一定在*连续*块中分配元素范围，它可能选择“条带化”策略。例如，如果有两个工作线程，一个线程可能处理奇数编号的元素，而另一个线程则处理偶数编号的元素。`TakeWhile`
    操作符几乎肯定会触发条带化策略，以避免不必要地处理序列后面的元素。
- en: Optimizing custom aggregations
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化自定义聚合
- en: 'PLINQ parallelizes the `Sum`, `Average`, `Min`, and `Max` operators efficiently
    without additional intervention. The `Aggregate` operator, though, presents special
    challenges for PLINQ. As described in [Chapter 9](ch09.html#linq_operators), `Aggregate`
    performs custom aggregations. For example, the following sums a sequence of numbers,
    mimicking the `Sum` operator:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ 在不需要额外干预的情况下有效地并行化 `Sum`、`Average`、`Min` 和 `Max` 操作符。然而，`Aggregate` 操作符对于
    PLINQ 提出了特殊挑战。正如 [第 9 章](ch09.html#linq_operators) 中描述的那样，`Aggregate` 执行自定义聚合。例如，以下代码对数字序列求和，模仿
    `Sum` 操作符的功能：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We also saw in [Chapter 9](ch09.html#linq_operators) that for *unseeded* aggregations,
    the supplied delegate must be associative and commutative. PLINQ will give incorrect
    results if this rule is violated, because it draws *multiple seeds* from the input
    sequence in order to aggregate several partitions of the sequence simultaneously.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还在 [第 9 章](ch09.html#linq_operators) 中看到，对于*未种子*聚合，提供的委托必须是可结合和可交换的。如果违反了此规则，PLINQ
    将给出不正确的结果，因为它会从输入序列中提取多个种子以同时聚合多个分区的序列。
- en: Explicitly seeded aggregations might seem like a safe option with PLINQ, but
    unfortunately these ordinarily execute sequentially because of the reliance on
    a single seed. To mitigate this, PLINQ provides another overload of `Aggregate`
    that lets you specify multiple seeds—or rather, a *seed factory function*. For
    each thread, it executes this function to generate a separate seed, which becomes
    a *thread-local* accumulator into which it locally aggregates elements.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 显式种子聚合看起来像是使用 PLINQ 的安全选择，但不幸的是，这些通常由于依赖单一种子而顺序执行。为了缓解这个问题，PLINQ 提供了另一个`Aggregate`的重载，允许您指定多个种子或者*种子工厂函数*。对于每个线程，它执行此函数以生成一个单独的种子，这成为一个*线程本地*的累加器，用于局部聚合元素。
- en: 'You must also supply a function to indicate how to combine the local and main
    accumulators. Finally, this `Aggregate` overload (somewhat gratuitously) expects
    a delegate to perform any final transformation on the result (you can achieve
    this as easily by running some function on the result yourself afterward). So,
    here are the four delegates, in the order they are passed:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您还必须提供一个函数来指示如何结合本地和主累加器。最后，这个`Aggregate`重载（有些过分地）期望一个委托来执行结果的任何最终转换（您也可以在之后对结果运行某些函数来轻松实现这一点）。因此，这里是四个委托，按照它们被传递的顺序：
- en: '`seedFactory`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`seedFactory`'
- en: Returns a new local accumulator
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个新的本地累加器
- en: '`updateAccumulatorFunc`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`updateAccumulatorFunc`'
- en: Aggregates an element into a local accumulator
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个元素聚合到本地累加器中
- en: '`combineAccumulatorFunc`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`combineAccumulatorFunc`'
- en: Combines a local accumulator with the main accumulator
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 将本地累加器与主累加器结合起来
- en: '`resultSelector`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`resultSelector`'
- en: Applies any final transformation on the end result
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对最终结果应用任何最终转换
- en: Note
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In simple scenarios, you can specify a *seed value* instead of a seed factory.
    This tactic fails when the seed is a reference type that you want to mutate, because
    the same instance will then be shared by each thread.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单的情况下，您可以指定一个*种子值*而不是种子工厂。当种子是您想要改变的引用类型时，这种策略会失败，因为同一个实例会被每个线程共享。
- en: 'To give a very simple example, the following sums the values in a `numbers`
    array:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 举个非常简单的例子，下面的代码对`numbers`数组中的值进行求和：
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This example is contrived in that we could get the same answer just as efficiently
    using simpler approaches (such as an unseeded aggregate, or better, the `Sum`
    operator). To give a more realistic example, suppose that we want to calculate
    the frequency of each letter in the English alphabet in a given string. A simple
    sequential solution might look like this:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子有些刻意，因为我们可以使用更简单的方法得到相同的答案（比如未种子化的聚合，或者更好的是`Sum`运算符）。为了给出一个更现实的例子，假设我们想计算给定字符串中每个英文字母的频率。一个简单的顺序解决方案可能如下所示：
- en: '[PRE21]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: An example of when the input text might be very long is in gene sequencing.
    The “alphabet” would then consist of the letters *a*, *c*, *g*, and *t*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一个输入文本可能非常长的示例是在基因序列中。此时，“字母表”将由字母*a*、*c*、*g*和*t*组成。
- en: To parallelize this, we could replace the `foreach` statement with a call to
    `Parallel.ForEach` (which we cover in the following section), but this will leave
    us to deal with concurrency issues on the shared array. And locking around accessing
    that array would all but kill the potential for parallelization.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要并行化这个过程，我们可以将`foreach`语句替换为调用`Parallel.ForEach`（我们在下一节中介绍），但这将使我们需要处理共享数组的并发问题。而且，在访问该数组时进行锁定几乎会杀死并行化的潜力。
- en: '`Aggregate` offers a tidy solution. The accumulator, in this case, is an array
    just like the `letterFrequencies` array in our preceding example. Here’s a sequential
    version using `Aggregate`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`Aggregate`提供了一个整洁的解决方案。在这种情况下，累加器就像我们之前例子中的`letterFrequencies`数组一样。这里是使用`Aggregate`的顺序版本：'
- en: '[PRE22]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And now the parallel version, using PLINQ’s special overload:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是并行版本，使用 PLINQ 的特殊重载：
- en: '[PRE23]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Notice that the local accumulation function *mutates* the `localFrequencies`
    array. This ability to perform this optimization is important—and is legitimate
    because `localFrequencies` is local to each thread.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 注意本地累积函数*改变*了`localFrequencies`数组。执行这种优化的能力非常重要——因为`localFrequencies`是每个线程本地的，所以是合法的。
- en: The Parallel Class
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行类
- en: 'PFX provides a basic form of structured parallelism via three static methods
    in the `Parallel` class:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: PFX 通过`Parallel`类中的三个静态方法提供了一种基本的结构化并行处理：
- en: '`Parallel.Invoke`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.Invoke`'
- en: Executes an array of delegates in parallel
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 并行执行委托数组
- en: '`Parallel.For`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.For`'
- en: Performs the parallel equivalent of a C# `for` loop
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 C# `for` 循环的并行等效操作
- en: '`Parallel.ForEach`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.ForEach`'
- en: Performs the parallel equivalent of a C# `foreach` loop
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 执行与 C# `foreach` 循环的并行等价操作
- en: All three methods block until all work is complete. As with PLINQ, after an
    unhandled exception, remaining workers are stopped after their current iteration
    and the exception (or exceptions) are thrown back to the caller—wrapped in an
    `AggregateException` (see [“Working with AggregateException”](#working_with_aggregateexception)).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 所有三种方法都会阻塞，直到所有工作完成。与 PLINQ 类似，在未处理的异常后，剩余的工作者将在它们当前的迭代后停止，并将异常（或异常）抛回给调用者——封装在
    `AggregateException` 中（参见 [“处理 AggregateException”](#working_with_aggregateexception)）。
- en: Parallel.Invoke
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`Parallel.Invoke`'
- en: '`Parallel.Invoke` executes an array of `Action` delegates in parallel and then
    waits for them to complete. The simplest version of the method is defined as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.Invoke` 在并行执行一个 `Action` 委托数组后等待它们完成。该方法的最简单版本定义如下：'
- en: '[PRE24]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Just as with PLINQ, the `Parallel`.* methods are optimized for compute-bound
    and not I/O-bound work. However, downloading two web pages at once provides a
    simple way to demonstrate `Parallel.Invoke`:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 就像对待 PLINQ 一样，`Parallel`.* 方法被优化用于计算密集型而不是 I/O 密集型工作。然而，同时下载两个网页提供了演示 `Parallel.Invoke`
    的简单方法：
- en: '[PRE25]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'On the surface, this seems like a convenient shortcut for creating and waiting
    on two thread-bound `Task` objects. But there’s an important difference: `Parallel.Invoke`
    still works efficiently if you pass in an array of a million delegates. This is
    because it *partitions* large numbers of elements into batches that it assigns
    to a handful of underlying `Task`s rather than creating a separate `Task` for
    each delegate.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看，这似乎是创建和等待两个绑定线程的 `Task` 对象的便捷捷径。但是有一个重要的区别：如果你传入一个包含一百万委托的数组，`Parallel.Invoke`
    仍然能够高效工作。这是因为它将大量元素*分区*成几批，并分配给少数几个基础 `Task`，而不是为每个委托创建一个单独的 `Task`。
- en: 'As with all of `Parallel`’s methods, you’re on your own when it comes to collating
    the results. This means that you need to keep thread safety in mind. The following,
    for instance, is thread-unsafe:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有 `Parallel` 方法一样，在收集结果方面你是独立的。这意味着你需要考虑线程安全性。例如，以下代码是线程不安全的：
- en: '[PRE26]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Locking around adding to the list would resolve this, although locking would
    create a bottleneck if you had a much larger array of quickly executing delegates.
    A better solution is to use the thread-safe collections, which we cover in later
    sections—`ConcurrentBag` would be ideal in this case.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在向列表添加锁定的情况下，可以解决这个问题，尽管锁定会在有大量快速执行委托的情况下创建瓶颈。更好的解决方案是使用线程安全的集合，我们将在后面的章节中介绍——在这种情况下，`ConcurrentBag`
    是理想的选择。
- en: '`Parallel.Invoke` is also overloaded to accept a `ParallelOptions` object:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.Invoke` 还重载为接受 `ParallelOptions` 对象：'
- en: '[PRE27]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'With `ParallelOptions`, you can insert a cancellation token, limit the maximum
    concurrency, and specify a custom task scheduler. A cancellation token is relevant
    when you’re executing (roughly) more tasks than you have cores: upon cancellation,
    any unstarted delegates will be abandoned. Any already executing delegates will,
    however, continue to completion. See [“Cancellation”](#cancellation-id00006) for
    an example of how to use cancellation tokens.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `ParallelOptions`，你可以插入一个取消标记，限制最大并发数，并指定自定义任务调度程序。当你执行（大致）多个任务比你有的内核时，取消标记是相关的：在取消时，任何未启动的委托将被放弃。然而，任何已经执行的委托将继续完成。参见
    [“取消”](#cancellation-id00006) 以查看如何使用取消标记的示例。
- en: Parallel.For and Parallel.ForEach
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`Parallel.For` 和 `Parallel.ForEach`'
- en: '`Parallel.For` and `Parallel.ForEach` perform the equivalent of a C# `for`
    and `foreach` loop but with each iteration executing in parallel instead of sequentially.
    Here are their (simplest) signatures:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.For` 和 `Parallel.ForEach` 执行与 C# 的 `for` 和 `foreach` 循环等价的操作，但每次迭代都是并行执行而不是顺序执行。以下是它们的（最简单的）签名：'
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This sequential `for` loop:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个顺序 `for` 循环：
- en: '[PRE29]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'is parallelized like this:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 被并行化为这样：
- en: '[PRE30]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'or more simply:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 或者更简单地说：
- en: '[PRE31]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And this sequential `foreach`:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这个顺序 `foreach`：
- en: '[PRE32]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'is parallelized like this:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 被并行化为这样：
- en: '[PRE33]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To give a practical example, if we import the `System.Security.Cryptography`
    namespace, we can generate six public/private keypair strings in parallel, as
    follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 举个实际的例子，如果我们导入 `System.Security.Cryptography` 命名空间，我们可以并行生成六对公钥/私钥字符串，如下所示：
- en: '[PRE34]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As with `Parallel.Invoke`, we can feed `Parallel.For` and `Parallel.ForEach`
    a large number of work items and they’ll be efficiently partitioned onto a few
    tasks.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `Parallel.Invoke` 一样，我们可以将大量的工作项传递给 `Parallel.For` 和 `Parallel.ForEach`，它们将被有效地分区到少数几个任务中。
- en: Note
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The latter query could also be done with PLINQ:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 后一种查询也可以使用 PLINQ 完成：
- en: '[PRE35]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Outer versus inner loops
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 外部与内部循环
- en: '`Parallel.For` and `Parallel.ForEach` usually work best on outer rather than
    inner loops. This is because with the former, you’re offering larger chunks of
    work to parallelize, diluting the management overhead. Parallelizing both inner
    and outer loops is usually unnecessary.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.For`和`Parallel.ForEach`通常在外部循环上效果最佳，而不是内部循环。这是因为前者提供了更大的工作块来并行化，从而稀释了管理开销。通常情况下，并行化内外部循环都是不必要的。'
- en: 'In the following example, we’d typically need more than 100 cores to benefit
    from the inner parallelization:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们通常需要超过100个核心来从内部并行化中获益：
- en: '[PRE36]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Indexed Parallel.ForEach
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 索引化的Parallel.ForEach
- en: 'Sometimes, it’s useful to know the loop iteration index. With a sequential
    `foreach`, it’s easy:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，了解循环迭代索引是很有用的。使用顺序的`foreach`很容易实现：
- en: '[PRE37]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Incrementing a shared variable, however, is not thread-safe in a parallel context.
    You must instead use the following version of `ForEach`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在并行环境中，递增共享变量是不安全的。您必须使用以下版本的`ForEach`：
- en: '[PRE38]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We’ll ignore `ParallelLoopState` (which we cover in the following section).
    For now, we’re interested in `Action`’s third type parameter of type `long`, which
    indicates the loop index:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将忽略`ParallelLoopState`（我们将在下一节中讨论）。目前，我们对类型为`long`的`Action`的第三个类型参数感兴趣，它指示循环索引：
- en: '[PRE39]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To put this into a practical context, let’s revisit the spellchecker that we
    wrote with PLINQ. The following code loads up a dictionary along with an array
    of a million words to test:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为了把这一点放到实际背景中，让我们重新审视使用PLINQ编写的拼写检查器。以下代码加载了一个词典，以及一个用于测试的一百万个单词的数组：
- en: '[PRE40]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We can perform the spellcheck on our `wordsToTest` array using the indexed
    version of `Parallel.ForEach`, as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用索引版本的`Parallel.ForEach`对`wordsToTest`数组执行拼写检查，如下所示：
- en: '[PRE41]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Notice that we had to collate the results into a thread-safe collection: having
    to do this is the disadvantage when compared to using PLINQ. The advantage over
    PLINQ is that we avoid the cost of applying an indexed `Select` query operator—which
    is less efficient than an indexed `ForEach`.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们必须将结果整理到一个线程安全的集合中：与使用PLINQ相比，这样做的劣势在于成本较高。与PLINQ相比的优势在于，我们避免了应用索引化的`Select`查询运算符的成本，后者效率低于索引化的`ForEach`。
- en: 'ParallelLoopState: breaking early out of loops'
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ParallelLoopState：提前退出循环
- en: 'Because the loop body in a parallel `For` or `ForEach` is a delegate, you can’t
    exit the loop early with a `break` statement. Instead, you must call `Break` or
    `Stop` on a `ParallelLoopState` object:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 因为并行`For`或`ForEach`中的循环体是一个委托，所以您不能使用`break`语句提前退出循环。相反，您必须在`ParallelLoopState`对象上调用`Break`或`Stop`：
- en: '[PRE42]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Obtaining a `ParallelLoopState` is easy: all versions of `For` and `ForEach`
    are overloaded to accept loop bodies of type `Action<TSource,ParallelLoopState>`.
    So, to parallelize this:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 获取`ParallelLoopState`很容易：所有版本的`For`和`ForEach`都重载了接受类型为`Action<TSource, ParallelLoopState>`的循环体。因此，要并行化这个：
- en: '[PRE43]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'do this:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做：
- en: '[PRE44]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'You can see from the output that loop bodies can complete in a random order.
    Aside from this difference, calling `Break` yields *at least* the same elements
    as executing the loop sequentially: this example will always output *at least*
    the letters *H*, *e*, *l*, *l*, and *o* in some order. In contrast, calling `Stop`
    instead of `Break` forces all threads to finish immediately after their current
    iteration. In our example, calling `Stop` could give us a subset of the letters
    *H*, *e*, *l*, *l*, and *o* if another thread were lagging behind. Calling `Stop`
    is useful when you’ve found something that you’re looking for—or when something
    has gone wrong and you won’t be looking at the results.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从输出中看到，循环体可以以随机顺序完成。除了这个区别外，调用`Break`至少产生与顺序执行循环相同的元素：此示例将始终以某种顺序输出字母*H*、*e*、*l*、*l*和*o*。相反，调用`Stop`而不是`Break`会立即使所有线程在当前迭代后完成。在我们的示例中，如果另一个线程落后，调用`Stop`可以给我们字母*H*、*e*、*l*、*l*和*o*的一个子集。在找到所需内容时或发生错误并且您不希望查看结果时，调用`Stop`非常有用。
- en: Note
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `Parallel.For` and `Parallel.ForEach` methods return a `ParallelLoopResult`
    object that exposes properties called `IsCompleted` and `LowestBreakIteration`.
    These tell you whether the loop ran to completion; if it didn’t, it indicates
    at what cycle the loop was broken.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.For`和`Parallel.ForEach`方法返回一个`ParallelLoopResult`对象，该对象公开了名为`IsCompleted`和`LowestBreakIteration`的属性。这些属性告诉您循环是否已完成；如果没有完成，则指示循环在哪个周期中断。'
- en: If `LowestBreakIteration` returns null, it means that you called `Stop` (rather
    than `Break`) on the loop.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`LowestBreakIteration`返回null，则表示在循环中调用了`Stop`（而不是`Break`）。
- en: If your loop body is long, you might want other threads to break partway through
    the method body in case of an early `Break` or `Stop`. You can do this by polling
    the `ShouldExitCurrentIteration` property at various places in your code; this
    property becomes true immediately after a `Stop`—or soon after a `Break`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的循环主体很长，你可能希望其他线程在方法体中途因为早期的 `Break` 或 `Stop` 而中断。你可以在代码的各个地方轮询 `ShouldExitCurrentIteration`
    属性来做到这一点；该属性在 `Stop` 后立即变为 true，或者在 `Break` 后不久也会如此。
- en: Note
  id: totrans-252
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '`ShouldExitCurrentIteration` also becomes true after a cancellation request—or
    if an exception is thrown in the loop.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`ShouldExitCurrentIteration` 在取消请求后或循环中抛出异常后也会变为 true。'
- en: '`IsExceptional` lets you know whether an exception has occurred on another
    thread. Any unhandled exception will cause the loop to stop after each thread’s
    current iteration: to avoid this, you must explicitly handle exceptions in your
    code.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '`IsExceptional` 通知您其他线程是否发生异常。任何未处理的异常都会导致每个线程当前迭代后停止循环：为了避免这种情况，您必须在代码中显式处理异常。'
- en: Optimization with local values
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用本地值进行优化
- en: '`Parallel.For` and `Parallel.ForEach` each offer a set of overloads that feature
    a generic type argument called `TLocal`. These overloads are designed to help
    you optimize the collation of data with iteration-intensive loops. The simplest
    is this:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.For` 和 `Parallel.ForEach` 各自提供了一组重载，其中包含一个称为 `TLocal` 的泛型类型参数。这些重载旨在帮助您优化迭代密集型循环中数据的汇总。最简单的是这样：'
- en: '[PRE45]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: These methods are rarely needed in practice because their target scenarios are
    covered mostly by PLINQ (which is fortunate because these overloads are somewhat
    intimidating!).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上很少需要这些方法，因为它们的目标场景大多已被 PLINQ 覆盖（这是幸运的，因为这些重载有点令人生畏！）。
- en: 'Essentially, the problem is this: suppose that we want to sum the square roots
    of the numbers 1 through 10,000,000\. Calculating 10 million square roots is easily
    parallelizable, but summing their values is troublesome because we must lock around
    updating the total:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 问题本质上是这样的：假设我们想要对 1 到 1000 万的数字进行平方根求和。计算 1000 万个平方根很容易并行化，但计算它们的总和很麻烦，因为我们必须在更新总值时进行锁定：
- en: '[PRE46]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The gain from parallelization is more than offset by the cost of obtaining 10
    million locks—plus the resultant blocking.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化的收益超过了获取 1000 万个锁的成本和相应的阻塞。
- en: The reality, though, is that we don’t actually *need* 10 million locks. Imagine
    a team of volunteers picking up a large volume of litter. If all workers shared
    a single trash can, the travel and contention would make the process extremely
    inefficient. The obvious solution is for each worker to have a private or “local”
    trash can, which is occasionally emptied into the main bin.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 但现实是，我们实际上并不 *需要* 1000 万个锁。想象一个团队的志愿者清理大量垃圾。如果所有工作人员共用一个垃圾桶，旅行和争用将使过程极其低效。显而易见的解决方案是每个工作人员都有一个私人或“本地”垃圾桶，偶尔倒入主垃圾桶。
- en: 'The `TLocal` versions of `For` and `ForEach` work in exactly this way. The
    volunteers are internal worker threads, and the *local value* represents a local
    trash can. For `Parallel` to do this job, you must feed it two additional delegates
    that indicate the following:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`For` 和 `ForEach` 的 `TLocal` 版本确实是这样工作的。志愿者是内部工作线程，而 *本地值* 表示本地垃圾桶。为了让 `Parallel`
    执行这项工作，您必须提供两个额外的委托，指示以下情况：'
- en: How to initialize a new local value
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何初始化一个新的本地值
- en: How to combine a local aggregation with the master value
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将本地聚合与主值合并
- en: 'Additionally, instead of the body delegate returning `void`, it should return
    the new aggregate for the local value. Here’s our example refactored:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，代替主体委托返回 `void`，它应该返回本地值的新聚合。以下是我们的示例重构：
- en: '[PRE47]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We must still lock, but only around aggregating the local value to the grand
    total. This makes the process dramatically more efficient.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然必须锁定，但只是围绕将本地值聚合到总值的操作。这显著提高了流程的效率。
- en: Note
  id: totrans-269
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'As stated earlier, PLINQ is often a good fit in these scenarios. Our example
    could be parallelized with PLINQ like this:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，PLINQ 在这些场景中通常很合适。我们的示例可以像这样并行化使用 PLINQ：
- en: '[PRE48]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '(Notice that we used `ParallelEnumerable` to force *range partitioning*: this
    improves performance in this case because all numbers will take equally long to
    process.)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: （请注意，我们使用 `ParallelEnumerable` 来强制 *范围分区*：这在这种情况下提高了性能，因为所有数字的处理时间相同。）
- en: In more complex scenarios, you might use LINQ’s `Aggregate` operator instead
    of `Sum`. If you supplied a local seed factory, the situation would be somewhat
    analogous to providing a local value function with `Parallel.For`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在更复杂的场景中，您可能会使用 LINQ 的 `Aggregate` 操作符而不是 `Sum`。如果您提供了一个本地种子工厂，情况将有些类似于在 `Parallel.For`
    中提供本地值函数。
- en: Task Parallelism
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务并行性
- en: '*Task parallelism* is the lowest-level approach to parallelization with PFX.
    The classes for working at this level are defined in the `System.Threading.Tasks`
    namespace and comprise the following:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务并行性* 是使用PFX进行并行化的最低级别方法。在这个级别工作的类定义在 `System.Threading.Tasks` 命名空间中，包括以下内容：'
- en: '| Class | Purpose |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 目的 |'
- en: '| --- | --- |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Task` | For managing a unit for work |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| `Task` | 用于管理一个工作单元 |'
- en: '| `Task<TResult>` | For managing a unit for work with a return value |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| `Task<TResult>` | 用于管理带有返回值的工作单元 |'
- en: '| `TaskFactory` | For creating tasks |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| `TaskFactory` | 用于创建任务 |'
- en: '| `TaskFactory<TResult>` | For creating tasks and continuations with the same
    return type |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| `TaskFactory<TResult>` | 用于创建具有相同返回类型的任务和延续 |'
- en: '| `TaskScheduler` | For managing the scheduling of tasks |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| `TaskScheduler` | 用于管理任务的调度 |'
- en: '| `TaskCompletionSource` | For manually controlling a task’s workflow |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| `TaskCompletionSource` | 用于手动控制任务的工作流程 |'
- en: 'We covered the basics of tasks in [Chapter 14](ch14.html#concurrency_and_asynchron);
    in this section, we look at advanced features of tasks that are aimed at parallel
    programming:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第14章](ch14.html#concurrency_and_asynchron) 中介绍了任务的基础知识；在本节中，我们将介绍旨在并行编程的任务的高级特性：
- en: Tuning a task’s scheduling
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整任务的调度
- en: Establish a parent/child relationship when one task is started from another
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当从另一个任务启动一个任务时，建立父/子关系
- en: Advanced use of continuations
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级使用的延续
- en: '`TaskFactory`'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TaskFactory`'
- en: Warning
  id: totrans-289
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The Task Parallel Library lets you create hundreds (or even thousands) of tasks
    with minimal overhead. But if you want to create millions of tasks, you’ll need
    to partition those tasks into larger work units to maintain efficiency. The `Parallel`
    class and PLINQ do this automatically.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 任务并行库允许您以最小的开销创建数百（甚至数千）个任务。但是，如果您想要创建数百万个任务，您需要将这些任务分成更大的工作单元以保持效率。`Parallel`
    类和 PLINQ 自动执行此操作。
- en: Note
  id: totrans-291
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Visual Studio provides a window for monitoring tasks (Debug®Window®Parallel
    Tasks). This is equivalent to the Threads window, but for tasks. The Parallel
    Stacks window also has a special mode for tasks.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Studio 提供了一个用于监视任务的窗口（Debug®Window®Parallel Tasks）。这相当于线程窗口，但用于任务。并行堆栈窗口还有一个专门用于任务的特殊模式。
- en: Creating and Starting Tasks
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和启动任务
- en: As described in [Chapter 14](ch14.html#concurrency_and_asynchron), `Task.Run`
    creates and starts a `Task` or `Task<TResult>`. This method is actually a shortcut
    for calling `Task.Factory.StartNew`, which allows greater flexibility through
    additional overloads.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 如在 [第14章](ch14.html#concurrency_and_asynchron) 中描述的，`Task.Run` 创建并启动一个 `Task`
    或 `Task<TResult>`。该方法实际上是调用 `Task.Factory.StartNew` 的一种快捷方式，通过额外的重载提供了更大的灵活性。
- en: Specifying a state object
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指定状态对象
- en: '`Task.Factory.StartNew` lets you specify a *state* object that is passed to
    the target. The target method’s signature must then comprise a single object-type
    parameter:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '`Task.Factory.StartNew` 允许您指定传递给目标的 *状态* 对象。然后，目标方法的签名必须包括一个单一的对象类型参数：'
- en: '[PRE49]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This avoids the cost of the closure required for executing a lambda expression
    that calls `Greet`. This is a micro-optimization and is rarely necessary in practice,
    so we can put the *state* object to better use, which is to assign a meaningful
    name to the task. We can then use the `AsyncState` property to query its name:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这样可以避免执行调用 `Greet` 的 lambda 表达式所需的闭包成本。这是一种微小的优化，在实践中很少需要，所以我们可以更好地利用 *状态* 对象，为任务指定一个有意义的名称。然后，我们可以使用
    `AsyncState` 属性来查询它的名称：
- en: '[PRE50]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Note
  id: totrans-300
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Visual Studio displays each task’s `AsyncState` in the Parallel Tasks window,
    so having a meaningful name here can ease debugging considerably.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Studio 在并行任务窗口中显示每个任务的 `AsyncState`，因此在此处使用一个有意义的名称可以极大地简化调试。
- en: TaskCreationOptions
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TaskCreationOptions
- en: 'You can tune a task’s execution by specifying a `TaskCreationOptions` enum
    when calling `StartNew` (or instantiating a `Task`). `TaskCreationOptions` is
    a flags enum with the following (combinable) values:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在调用 `StartNew`（或实例化 `Task`）时指定 `TaskCreationOptions` 枚举来调整任务的执行。`TaskCreationOptions`
    是一个标志枚举，具有以下（可组合）值：
- en: '[PRE51]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '`LongRunning` suggests to the scheduler to dedicate a thread to the task, and
    as we described in [Chapter 14](ch14.html#concurrency_and_asynchron), this is
    beneficial for I/O-bound tasks and for long-running tasks that might otherwise
    force short-running tasks to wait an unreasonable amount of time before being
    scheduled.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '`LongRunning`建议调度程序为任务分配一个线程，正如我们在[第14章](ch14.html#concurrency_and_asynchron)中描述的那样，这对于I/O绑定任务和可能迫使短期运行任务等待不合理的时间以进行调度的长期运行任务非常有利。'
- en: '`PreferFairness` instructs the scheduler to try to ensure that tasks are scheduled
    in the order in which they were started. It might ordinarily do otherwise because
    it internally optimizes the scheduling of tasks using local work-stealing queues—an
    optimization that allows the creation of *child* tasks without incurring the contention
    overhead that would otherwise arise with a single work queue. A child task is
    created by specifying `AttachedToParent`.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '`PreferFairness`指示调度程序尝试确保按照启动顺序调度任务。通常情况下可能会有所不同，因为它在内部使用本地工作窃取队列优化任务的调度——这种优化允许创建*子*任务而不会产生单一工作队列所产生的争用开销。通过指定`AttachedToParent`来创建子任务。'
- en: Child tasks
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 子任务
- en: 'When one task starts another, you can optionally establish a parent-child relationship:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个任务启动另一个任务时，您可以选择建立父子关系：
- en: '[PRE52]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'A child task is special in that when you wait for the *parent* task to complete,
    it waits for any children, as well. At which point any child exceptions bubble
    up:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 子任务在等待*父*任务完成时是特殊的，它也会等待任何子任务完成。在这一点上，任何子异常都会冒泡上来：
- en: '[PRE53]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This can be particularly useful when a child task is a continuation, as you’ll
    see shortly.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个子任务是一个继续任务时，这尤其有用，您很快就会看到。
- en: Waiting on Multiple Tasks
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 等待多个任务
- en: We saw in [Chapter 14](ch14.html#concurrency_and_asynchron) that you can wait
    on a single task either by calling its `Wait` method or by accessing its `Result`
    property (if it’s a `Task<TResult>`). You can also wait on multiple tasks at once—via
    the static methods `Task.WaitAll` (waits for all the specified tasks to finish)
    and `Task.WaitAny` (waits for just one task to finish).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第14章](ch14.html#concurrency_and_asynchron)中看到，您可以通过调用其`Wait`方法或访问其`Result`属性（如果它是`Task<TResult>`）等待单个任务。您还可以同时等待多个任务——通过静态方法`Task.WaitAll`（等待所有指定任务完成）和`Task.WaitAny`（仅等待一个任务完成）。
- en: '`WaitAll` is similar to waiting out each task in turn, but is more efficient
    in that it requires (at most) just one context switch. Also, if one or more of
    the tasks throw an unhandled exception, `WaitAll` still waits out every task.
    It then rethrows an `AggregateException` that accumulates the exceptions from
    each faulted task (this is where `AggregateException` is genuinely useful). It’s
    equivalent to doing this:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '`WaitAll`类似于依次等待每个任务完成，但效率更高，因为它最多需要一个上下文切换。此外，如果一个或多个任务抛出未处理的异常，`WaitAll`仍然会等待每个任务完成。然后重新抛出一个累积了每个出错任务异常的`AggregateException`（这正是`AggregateException`真正有用的地方）。它相当于执行以下操作：'
- en: '[PRE54]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Calling `WaitAny` is equivalent to waiting on a `ManualResetEventSlim` that’s
    signaled by each task as it finishes.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`WaitAny`相当于等待每个任务完成时由`ManualResetEventSlim`发出的信号。
- en: 'As well as a timeout, you can also pass in a *cancellation token* to the `Wait`
    methods: this lets you cancel the wait—*not the task itself*.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 除了超时外，您还可以在`Wait`方法中传递*取消令牌*：这使您可以取消等待——*而不是任务本身*。
- en: Canceling Tasks
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 取消任务
- en: 'You can optionally pass in a cancellation token when starting a task. Then,
    if cancellation occurs via that token, the task itself enters the “Canceled” state:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择在启动任务时传递取消令牌。然后，如果通过该令牌发生取消，任务本身进入“已取消”状态：
- en: '[PRE55]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '`TaskCanceledException` is a subclass of `OperationCanceledException`. If you
    want to explicitly throw an `OperationCanceledException` (rather than calling
    `token.ThrowIfCancellationRequested`), you must pass the cancellation token into
    `OperationCanceledException`’s constructor. If you fail to do this, the task won’t
    end up with a `TaskStatus.Canceled` status and won’t trigger `OnlyOnCanceled`
    continuations.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '`TaskCanceledException`是`OperationCanceledException`的子类。如果您想明确抛出`OperationCanceledException`（而不是调用`token.ThrowIfCancellationRequested`），您必须将取消令牌传递给`OperationCanceledException`的构造函数。如果未能这样做，任务将不会以`TaskStatus.Canceled`状态结束，也不会触发`OnlyOnCanceled`继续执行。'
- en: If the task is canceled before it has started, it won’t get scheduled—an `OperationCanceledException`
    will instead be thrown on the task immediately.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任务在启动之前被取消，它将不会被调度——而是立即在任务上抛出`OperationCanceledException`。
- en: 'Because cancellation tokens are recognized by other APIs, you can pass them
    into other constructs and cancellations will propagate seamlessly:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其他 API 识别取消令牌，您可以将它们传递到其他结构中，并且取消将无缝传播：
- en: '[PRE56]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Calling `Cancel` on `cancelSource` in this example will cancel the PLINQ query,
    which will throw an `OperationCanceledException` on the task body, which will
    then cancel the task.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中调用 `cancelSource` 上的 `Cancel` 将取消 PLINQ 查询，这将在任务体上引发 `OperationCanceledException`，随后取消任务。
- en: Note
  id: totrans-327
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The cancellation tokens that you can pass into methods such as `Wait` and `CancelAndWait`
    allow you to cancel the *wait* operation and not the task itself.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将取消令牌传递到诸如 `Wait` 和 `CancelAndWait` 的方法中，以取消*等待*操作而不是任务本身。
- en: Continuations
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 续体
- en: 'The `ContinueWith` method executes a delegate immediately after a task ends:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '`ContinueWith` 方法在任务结束后立即执行委托：'
- en: '[PRE57]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: As soon as `task1` (the *antecedent*) completes, fails, or is canceled, `task2`
    (the *continuation*) starts. (If `task1` had completed before the second line
    of code ran, `task2` would be scheduled to execute immediately.) The `ant` argument
    passed to the continuation’s lambda expression is a reference to the antecedent
    task. `ContinueWith` itself returns a task, making it easy to add further continuations.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 `task1`（*前驱*）完成、失败或被取消，`task2`（*续体*）就开始执行。（如果 `task1` 在第二行代码运行之前完成，`task2`
    将立即被调度执行。）传递给续体 lambda 表达式的 `ant` 参数是对前驱任务的引用。`ContinueWith` 本身返回一个任务，使得可以轻松添加进一步的续体。
- en: 'By default, antecedent and continuation tasks may execute on different threads.
    You can force them to execute on the same thread by specifying `TaskContinuatio⁠n​Options.ExecuteSynchronously`
    when calling `ContinueWith`: this can improve performance in very fine-grained
    continuations by lessening indirection.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，前驱和续体任务可能在不同的线程上执行。通过在调用 `ContinueWith` 时指定 `TaskContinuationOptions.ExecuteSynchronously`
    可以强制它们在同一线程上执行：这可以通过减少间接性来提高非常精细的续体的性能。
- en: Continuations and Task<TResult>
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 续体和 Task<TResult>
- en: 'Just like ordinary tasks, continuations can be of type `Task<TResult>` and
    return data. In the following example, we calculate `Math.Sqrt(8*2)` using a series
    of chained tasks and then write out the result:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 就像普通任务一样，续体可以是 `Task<TResult>` 类型并返回数据。在以下示例中，我们使用一系列链式任务计算 `Math.Sqrt(8*2)`，然后输出结果：
- en: '[PRE58]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Our example is somewhat contrived for simplicity; in real life, these lambda
    expressions would call computationally intensive functions.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例有点刻意简化；在现实生活中，这些 lambda 表达式会调用计算密集型函数。
- en: Continuations and exceptions
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 续体和异常
- en: A continuation can know whether an antecedent faulted by querying the antecedent
    task’s `Exception` property—or simply by invoking `Result` / `Wait` and catching
    the resultant `AggregateException`. If an antecedent faults and the continuation
    does neither, the exception is considered *unobserved* and the static `TaskScheduler​.Unob⁠servedTaskException`
    event fires when the task is later garbage-collected.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 续体可以通过查询前驱任务的 `Exception` 属性来知道前驱是否故障，或者简单地调用 `Result` / `Wait` 并捕获生成的 `AggregateException`。如果前驱故障而续体两者都不做，异常被认为是*未观察到的*，当任务稍后被垃圾回收时，静态
    `TaskScheduler.UnobservedTaskException` 事件将触发。
- en: 'A safe pattern is to rethrow antecedent exceptions. As long as the continuation
    is `Wait`ed upon, the exception will be propagated and rethrown to the `Wait`er:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 安全的模式是重新抛出前驱异常。只要等待续体，异常将被传播并重新抛出给等待者：
- en: '[PRE59]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Another way to deal with exceptions is to specify different continuations for
    exceptional versus nonexceptional outcomes. This is done with `TaskContinuationOptions`:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 处理异常的另一种方式是为异常和非异常结果指定不同的续体。可以通过 `TaskContinuationOptions` 来实现：
- en: '[PRE60]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: This pattern is particularly useful in conjunction with child tasks, as you’ll
    see very soon.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 此模式在与子任务结合时尤为有用，您很快就会看到。
- en: 'The following extension method “swallows” a task’s unhandled exceptions:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 以下扩展方法“吞噬”了任务的未处理异常：
- en: '[PRE61]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '(This could be improved by adding code to log the exception.) Here’s how it
    would be used:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: （可以通过添加代码来记录异常以改进此功能。）以下是如何使用它的示例：
- en: '[PRE62]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Continuations and child tasks
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 续体和子任务
- en: A powerful feature of continuations is that they kick off only when all child
    tasks have completed (see [Figure 22-5](#continuations-id00059)). At that point,
    any exceptions thrown by the children are marshaled to the continuation.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 续体的一个强大特性是它们只有在所有子任务完成后才启动（参见[图 22-5](#continuations-id00059)）。在那时，由子任务抛出的任何异常都将传递给续体。
- en: 'In the following example, we start three child tasks, each throwing a `NullReferen⁠ce​Exception`.
    We then catch all of them in one fell swoop via a continuation on the parent:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们启动三个子任务，每个任务都会抛出 `NullReferen⁠ce​Exception`。然后，我们通过父任务上的后续操作一次性捕获所有这些异常：
- en: '[PRE63]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '![Continuations](assets/cn10_2205.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![后续操作](assets/cn10_2205.png)'
- en: Figure 22-5\. Continuations
  id: totrans-354
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 22-5\. 后续操作
- en: Conditional continuations
  id: totrans-355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条件性后续操作
- en: 'By default, a continuation is scheduled *unconditionally*, whether the antecedent
    completes, throws an exception, or is canceled. You can alter this behavior via
    a set of (combinable) flags included within the `TaskContinuationOptions` enum.
    Following are the three core flags that control conditional continuation:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，后续操作被*无条件*地调度，无论先决条件是否完成、抛出异常或取消。您可以通过 `TaskContinuationOptions` 枚举中包含的一组（可组合）标志来更改此行为。以下是控制条件后续操作的三个核心标志：
- en: '[PRE64]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'These flags are subtractive in the sense that the more you apply, the less
    likely the continuation is to execute. For convenience, there are also the following
    precombined values:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标志是减法的，即您应用得越多，后续操作执行的可能性就越小。为了方便起见，还有以下预组合值：
- en: '[PRE65]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: (Combining all the `Not*` flags [`NotOnRanToCompletion`, `NotOnFaulted`, `NotOn​Can⁠celed`]
    is nonsensical because it would result in the continuation always being canceled.)
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: （将所有 `Not*` 标志 [`NotOnRanToCompletion`, `NotOnFaulted`, `NotOn​Can⁠celed`] 组合在一起是毫无意义的，因为这将导致后续操作始终被取消。）
- en: “RanToCompletion” means that the antecedent succeeded without cancellation or
    unhandled exceptions.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: “RanToCompletion” 表示先决条件成功完成，没有取消或未处理的异常。
- en: “Faulted” means that an unhandled exception was thrown on the antecedent.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: “Faulted” 表示先决条件上抛出了未处理的异常。
- en: '“Canceled” means one of two things:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: “已取消”有两种含义：
- en: The antecedent was canceled via its cancellation token. In other words, an `OperationCanceledException`
    was thrown on the antecedent, whose `CancellationToken` property matched that
    passed to the antecedent when it was started.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先决条件是通过其取消令牌取消的。换句话说，当启动先决条件时，如果抛出 `OperationCanceledException`，则其 `CancellationToken`
    属性与传递给它的先决条件匹配。
- en: The antecedent was implicitly canceled because *it* didn’t satisfy a conditional
    continuation predicate.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先决条件由于未满足条件性后续操作断言而被隐式取消。
- en: 'It’s essential to grasp that when a continuation doesn’t execute by virtue
    of these flags, the continuation is not forgotten or abandoned—it’s canceled.
    This means that any continuations on the continuation itself *will then run* unless
    you predicate them with `NotOnCanceled`. For example, consider this:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，当一个后续操作由于这些标志而不执行时，并不意味着后续操作被遗忘或放弃，而是被取消了。这意味着后续操作本身上的任何后续操作都将运行，除非您使用
    `NotOnCanceled` 进行断言。例如，考虑以下情况：
- en: '[PRE66]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: As it stands, `t3` will always get scheduled—even if `t1` doesn’t throw an exception
    (see [Figure 22-6](#conditional_continuations-id00057)). This is because if `t1`
    succeeds, the `fault` task will be canceled, and with no continuation restrictions
    placed on `t3`, `t3` will then execute unconditionally.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 目前情况下，`t3` 将始终被安排执行——即使 `t1` 不抛出异常（参见 [图 22-6](#conditional_continuations-id00057)）。这是因为如果
    `t1` 成功，`fault` 任务将被取消，并且对 `t3` 没有施加任何后续操作限制，`t3` 将会无条件执行。
- en: 'If we want `t3` to execute only if `fault` actually runs, we must instead do
    this:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望 `t3` 只在实际运行 `fault` 时才执行，我们必须做如下处理：
- en: '[PRE67]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: (Alternatively, we could specify `OnlyOnRanToCompletion`; the difference is
    that `t3` would not then execute if an exception were thrown within `fault`.)
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: （或者，我们可以指定 `OnlyOnRanToCompletion`；区别在于，如果在 `fault` 内抛出异常，则 `t3` 将不会执行。）
- en: '![Conditional continuations](assets/cn10_2206.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![条件性后续操作](assets/cn10_2206.png)'
- en: Figure 22-6\. Conditional continuations
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 22-6\. 条件性后续操作
- en: Continuations with multiple antecedents
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多个先决条件的后续操作
- en: 'You can schedule continuation to execute based on the completion of multiple
    antecedents with the `ContinueWhenAll` and `ContinueWhenAny` methods in the `TaskFactory`
    class. These methods have become redundant, however, with the introduction of
    the task combinators discussed in [Chapter 14](ch14.html#concurrency_and_asynchron)
    (`WhenAll` and `WhenAny`). Specifically, given the following tasks:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `TaskFactory` 类中的 `ContinueWhenAll` 和 `ContinueWhenAny` 方法，根据多个先决条件的完成来调度后续操作。然而，随着讨论的任务组合器
    `WhenAll` 和 `WhenAny` 的引入，这些方法已经变得多余了。特别是，考虑以下任务：
- en: '[PRE68]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'we can schedule a continuation to execute when both complete as follows:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以安排一个后续操作，在两者都完成时执行如下：
- en: '[PRE69]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Here’s the same result with the `WhenAll` task combinator:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用 `WhenAll` 任务组合器得到相同结果的情况：
- en: '[PRE70]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Multiple continuations on a single antecedent
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单个前序任务的多个延续
- en: Calling `ContinueWith` more than once on the same task creates multiple continuations
    on a single antecedent. When the antecedent finishes, all continuations will start
    together (unless you specify `TaskContinuationOptions.ExecuteSynchronously`, in
    which case the continuations will execute sequentially).
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一任务上多次调用`ContinueWith`会创建单个前序任务的多个延续。当前序任务完成时，所有延续将同时开始（除非您指定`TaskContinuationOptions.ExecuteSynchronously`，在这种情况下，延续将按顺序执行）。
- en: 'The following waits for one second and then writes either `XY` or `YX`:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 以下等待一秒钟，然后写入`XY`或`YX`：
- en: '[PRE71]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Task Schedulers
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务调度器
- en: 'A *task scheduler* allocates tasks to threads and is represented by the abstract
    `TaskScheduler` class. .NET provides two concrete implementations: the *default
    scheduler* that works in tandem with the CLR thread pool, and the *synchronization
    context scheduler*. The latter is designed (primarily) to help you with the threading
    model of WPF and Windows Forms, which requires that user interface elements and
    controls are accessed only from the thread that created them (see [“Threading
    in Rich Client Applications”](ch14.html#threading_in_rich_client_applications)).
    By capturing it, we can instruct a task or a continuation to execute on this context:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务调度器*分配任务给线程，并由抽象的`TaskScheduler`类表示。.NET提供了两个具体的实现：与CLR线程池协同工作的*默认调度器*和*同步上下文调度器*。后者主要设计用于帮助您处理WPF和Windows
    Forms的线程模型，这要求用户界面元素和控件只能从创建它们的线程访问（见[“富客户端应用程序中的线程”](ch14.html#threading_in_rich_client_applications)）。通过捕获它，我们可以指示任务或延续在此上下文中执行：'
- en: '[PRE72]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Assuming `Foo` is a compute-bound method that returns a string and `lblResult`
    is a WPF or Windows Forms label, we could then safely update the label after the
    operation completes, as follows:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 假设`Foo`是一个计算密集型方法，返回一个字符串，而`lblResult`是一个WPF或Windows Forms标签，我们可以在操作完成后安全地更新标签，如下所示：
- en: '[PRE73]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Of course, C#’s asynchronous functions would more commonly be used for this
    kind of thing.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，C#的异步函数更常用于这种类型的操作。
- en: It’s also possible to write our own task scheduler (by subclassing `TaskScheduler`),
    although this is something you’d do only in very specialized scenarios. For custom
    scheduling, you’d more commonly use `TaskCompletionSource`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以编写自己的任务调度器（通过子类化`TaskScheduler`），尽管这只在非常专业的场景下才这样做。对于自定义调度，通常会使用`TaskCompletionSource`。
- en: TaskFactory
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TaskFactory
- en: 'When you call `Task.Factory`, you’re calling a static property on `Task` that
    returns a default `TaskFactory` object. The purpose of a task factory is to create
    tasks; specifically, three kinds of tasks:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用`Task.Factory`时，您实际上在`Task`上调用一个静态属性，该属性返回一个默认的`TaskFactory`对象。任务工厂的目的是创建任务；具体来说，是三种类型的任务：
- en: “Ordinary” tasks (via `StartNew`)
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “普通”任务（通过`StartNew`）
- en: Continuations with multiple antecedents (via `ContinueWhenAll` and `ContinueWhenAny`)
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个前序任务的延续（通过`ContinueWhenAll`和`ContinueWhenAny`）
- en: Tasks that wrap methods that follow the defunct APM (via `FromAsync`; see [“Obsolete
    Patterns”](ch14.html#obsolete_patterns))
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包装了遵循已废弃的APM（通过`FromAsync`；见[“过时的模式”](ch14.html#obsolete_patterns)）的方法的任务
- en: Another way to create tasks is to instantiate `Task` and call `Start`. However,
    this lets you create only “ordinary” tasks, not continuations.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种创建任务的方式是实例化`Task`并调用`Start`。然而，这只允许您创建“普通”的任务，而不是延续。
- en: Creating your own task factories
  id: totrans-398
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建自己的任务工厂
- en: '`TaskFactory` is not an *abstract* factory: you can actually instantiate the
    class, and this is useful when you want to repeatedly create tasks using the same
    (nonstandard) values for `TaskCreationOptions`, `TaskContinuationOptions`, or
    `TaskScheduler`. For example, if we want to repeatedly create long-running *parented*
    tasks, we could create a custom factory, as follows:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '`TaskFactory`不是一个*抽象*工厂：你实际上可以实例化这个类，在你想要使用相同（非标准）值为`TaskCreationOptions`、`TaskContinuationOptions`或`TaskScheduler`重复创建任务时非常有用。例如，如果我们想要重复创建长时间运行的*父级*任务，我们可以创建一个自定义工厂，如下所示：'
- en: '[PRE74]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Creating tasks is then simply a matter of calling `StartNew` on the factory:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 创建任务只是简单地在工厂上调用`StartNew`的问题：
- en: '[PRE75]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: The custom continuation options are applied when calling `ContinueWhenAll` and
    `ContinueWhenAny`.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用`ContinueWhenAll`和`ContinueWhenAny`时应用自定义的延续选项。
- en: Working with AggregateException
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AggregateException
- en: 'As we’ve seen, PLINQ, the `Parallel` class, and `Task`s automatically marshal
    exceptions to the consumer. To see why this is essential, consider the following
    LINQ query, which throws a `DivideByZeroException` on the first iteration:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，PLINQ、`Parallel` 类和 `Task` 会自动将异常传递给消费者。要理解这一点为何至关重要，请考虑以下 LINQ 查询，它在第一次迭代中抛出
    `DivideByZeroException`：
- en: '[PRE76]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: If we asked PLINQ to parallelize this query and it ignored the handling of exceptions,
    a `DivideByZeroException` would probably be thrown on a *separate thread*, bypassing
    our `catch` block and causing the application to die.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们让 PLINQ 并行化这个查询并且它忽略了异常处理，`DivideByZeroException` 可能会在*单独的线程*上被抛出，绕过我们的
    `catch` 块并导致应用程序崩溃。
- en: 'Hence, exceptions are automatically caught and rethrown to the caller. But
    unfortunately, it’s not quite as simple as catching a `DivideByZeroException`.
    Because these libraries utilize many threads, it’s actually possible for two or
    more exceptions to be thrown simultaneously. To ensure that all exceptions are
    reported, exceptions are therefore wrapped in an `AggregateException` container,
    which exposes an `InnerExceptions` property containing each of the caught exception(s):'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，异常会自动捕获并重新抛给调用方。但遗憾的是，要捕获 `DivideByZeroException` 并不像看起来那么简单。因为这些库利用了多线程，实际上可能会同时抛出两个或更多异常。为确保报告所有异常，因此将异常包装在一个
    `AggregateException` 容器中，其暴露了一个 `InnerExceptions` 属性，其中包含每个捕获的异常：
- en: '[PRE77]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Note
  id: totrans-410
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Both PLINQ and the `Parallel` class end the query or loop execution upon encountering
    the first exception—by not processing any further elements or loop bodies. More
    exceptions might be thrown, however, before the current cycle is complete. The
    first exception in `AggregateException` is visible in the `InnerException` property.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: PLINQ 和 `Parallel` 类在遇到第一个异常时结束查询或循环执行 —— 即不再处理任何后续元素或循环体。然而，在当前周期完成之前可能会抛出更多异常。在
    `AggregateException` 中的第一个异常可通过 `InnerException` 属性看到。
- en: Flatten and Handle
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Flatten 和 Handle
- en: 'The `AggregateException` class provides a couple of methods to simplify exception
    handling: `Flatten` and `Handle`.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '`AggregateException` 类提供了几种简化异常处理的方法：`Flatten` 和 `Handle`。'
- en: Flatten
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Flatten
- en: '`AggregateException`s will quite often contain other `AggregateException`s.
    An example of when this might happen is if a child task throws an exception. You
    can eliminate any level of nesting to simplify handling by calling `Flatten`.
    This method returns a new `AggregateException` with a simple flat list of inner
    exceptions:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '`AggregateException` 往往会包含其他 `AggregateException`。一个例子是如果子任务抛出异常。你可以通过调用 `Flatten`
    方法消除任意层级的嵌套以简化处理。该方法返回一个新的 `AggregateException`，其中包含一个简单的内部异常列表：'
- en: '[PRE78]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Handle
  id: totrans-417
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Handle
- en: 'Sometimes, it’s useful to catch only specific exception types, and have other
    types rethrown. The `Handle` method on `AggregateException` provides a shortcut
    for doing this. It accepts an exception predicate which it runs over every inner
    exception:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，捕获特定类型的异常并重新抛出其他类型的异常是很有用的。`AggregateException` 上的 `Handle` 方法为此提供了一种快捷方式。它接受一个异常谓词，该谓词运行在每个内部异常上：
- en: '[PRE79]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'If the predicate returns `true`, it considers that exception “handled.” After
    the delegate has run over every exception, the following happens:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 如果谓词返回 `true`，则认为该异常“已处理”。委托运行完所有异常后，将执行以下操作：
- en: If all exceptions were “handled” (the delegate returned `true`), the exception
    is not rethrown.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果所有异常都被“处理”（委托返回 `true`），则不会重新抛出异常。
- en: If there were any exceptions for which the delegate returned `false` (“unhandled”),
    a new `AggregateException` is built up containing those exceptions and is rethrown.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果委托返回 `false`（“未处理”）的任何异常，则会构建一个新的 `AggregateException` 包含这些异常并重新抛出。
- en: 'For instance, the following ends up rethrowing another `AggregateException`
    that contains a single `NullReferenceException`:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码最终会重新抛出包含单个 `NullReferenceException` 的另一个 `AggregateException`：
- en: '[PRE80]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Concurrent Collections
  id: totrans-425
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发集合
- en: '.NET offers thread-safe collections in the `System.Collections.Concurrent`
    namespace:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: .NET 在 `System.Collections.Concurrent` 命名空间中提供了线程安全的集合：
- en: '| Concurrent collection | Nonconcurrent equivalent |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 并发集合 | 非并发等效集合 |'
- en: '| --- | --- |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `ConcurrentStack<T>` | `Stack<T>` |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| `ConcurrentStack<T>` | `Stack<T>` |'
- en: '| `ConcurrentQueue<T>` | `Queue<T>` |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| `ConcurrentQueue<T>` | `Queue<T>` |'
- en: '| `ConcurrentBag<T>` | (none) |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| `ConcurrentBag<T>` | (无) |'
- en: '| `ConcurrentDictionary<TKey,TValue>` | `Dictionary<TKey,TValue>` |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| `ConcurrentDictionary<TKey,TValue>` | `Dictionary<TKey,TValue>` |'
- en: 'The concurrent collections are optimized for high-concurrency scenarios; however,
    they can also be useful whenever you need a thread-safe collection (as an alternative
    to locking around an ordinary collection). There are some caveats, though:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 并发集合针对高并发场景进行了优化；然而，在需要线程安全集合（作为普通集合的替代品进行锁定）的任何情况下，它们也很有用。然而，还有一些注意事项：
- en: The conventional collections outperform the concurrent collections in all but
    highly concurrent scenarios.
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有但高并发场景下，传统集合的性能优于并发集合。
- en: A thread-safe collection doesn’t guarantee that the code using it will be thread-safe
    (see [“Locking and Thread Safety”](ch21.html#locking_and_thread_safet)).
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程安全的集合并不保证使用它的代码是线程安全的（参见[“锁定和线程安全”](ch21.html#locking_and_thread_safet)）。
- en: If you enumerate over a concurrent collection while another thread is modifying
    it, no exception is thrown—instead, you get a mixture of old and new content.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在另一个线程修改并发集合时枚举它，不会抛出异常，而是会得到旧内容和新内容的混合。
- en: There’s no concurrent version of `List<T>`.
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有 `List<T>` 的并发版本。
- en: The concurrent stack, queue, and bag classes are implemented internally with
    linked lists. This makes them less memory-efficient than the nonconcurrent `Stack`
    and `Queue` classes, but better for concurrent access because linked lists are
    conducive to lock-free or low-lock implementations. (This is because inserting
    a node into a linked list requires updating just a couple of references, whereas
    inserting an element into a `List<T>`-like structure might require moving thousands
    of existing elements.)
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发的栈、队列和背包类在内部使用链表实现。这使它们在内存效率上不如非并发的 `Stack` 和 `Queue` 类，但在并发访问时更好，因为链表有利于无锁或低锁实现。这是因为将节点插入链表只需要更新几个引用，而将元素插入类似
    `List<T>` 的结构可能需要移动数千个现有元素。
- en: 'In other words, these collections are not merely shortcuts for using an ordinary
    collection with a lock. To demonstrate, if we execute the following code on a
    *single* thread:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，这些集合不仅仅是使用带锁的普通集合的捷径。举例来说，如果我们在*单个*线程上执行以下代码：
- en: '[PRE81]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'it runs three times more slowly than this:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 它的运行速度比这个慢三倍：
- en: '[PRE82]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: (*Reading* from a `ConcurrentDictionary`, however, is fast because reads are
    lock-free.)
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: （然而，从 `ConcurrentDictionary` *读取* 是快速的，因为读取是无锁的。）
- en: The concurrent collections also differ from conventional collections in that
    they expose special methods to perform atomic test-and-act operations, such as
    `TryPop`. Most of these methods are unified via the `IProducerConsumerCollection<T>`
    interface.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 并发集合还不同于传统集合，它们公开了特殊的方法来执行原子的测试和操作，比如 `TryPop`。大多数这些方法通过 `IProducerConsumerCollection<T>`
    接口统一。
- en: IProducerConsumerCollection<T>
  id: totrans-445
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IProducerConsumerCollection<T>
- en: 'A producer/consumer collection is one for which the two primary use cases are:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者/消费者集合的两个主要用例是：
- en: Adding an element (“producing”)
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加一个元素（“生产”）
- en: Retrieving an element while removing it (“consuming”)
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索元素同时将其移除（“消费”）
- en: The classic examples are stacks and queues. Producer/consumer collections are
    significant in parallel programming because they’re conducive to efficient lock-free
    implementations.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的例子是栈和队列。生产者/消费者集合在并行编程中很重要，因为它们有利于高效的无锁实现。
- en: 'The `IProducerConsumerCollection<T>` interface represents a thread-safe producer/consumer
    collection. The following classes implement this interface:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '`IProducerConsumerCollection<T>` 接口代表一个线程安全的生产者/消费者集合。以下类实现了这个接口：'
- en: '[PRE83]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '`IProducerConsumerCollection<T>` extends `ICollection`, adding the following
    methods:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '`IProducerConsumerCollection<T>` 扩展了 `ICollection`，增加了以下方法：'
- en: '[PRE84]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'The `TryAdd` and `TryTake` methods test whether an add/remove operation can
    be performed; if so, they perform the add/remove. The testing and acting are atomically
    performed, eliminating the need to lock as you would around a conventional collection:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '`TryAdd` 和 `TryTake` 方法测试是否可以执行添加/移除操作；如果可以，则执行添加/移除。测试和执行是原子性的，消除了像传统集合那样需要锁定的必要性：'
- en: '[PRE85]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '`TryTake` returns `false` if the collection is empty. `TryAdd` always succeeds
    and returns `true` in the three implementations provided. If you wrote your own
    concurrent collection that prohibited duplicates, however, you’d make `TryAdd`
    return `false` if the element already existed (an example would be if you wrote
    a concurrent *set*).'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '`TryTake` 如果集合为空则返回 `false`。`TryAdd` 在提供的三个实现中总是成功并返回 `true`。然而，如果你编写了自己的并发集合以禁止重复，那么如果元素已经存在，`TryAdd`
    将返回 `false`（例如，如果你编写了一个并发的*集合*）。'
- en: 'The particular element that `TryTake` removes is defined by the subclass:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '`TryTake`移除的特定元素由子类定义：'
- en: With a stack, `TryTake` removes the most recently added element.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用栈时，`TryTake`会删除最近添加的元素。
- en: With a queue, `TryTake` removes the least recently added element.
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用队列时，`TryTake`会移除最近添加的元素。
- en: With a bag, `TryTake` removes whatever element it can remove most efficiently.
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用袋子时，`TryTake`会以最高效的方式删除任何它可以删除的元素。
- en: The three concrete classes mostly implement the `TryTake` and `TryAdd` methods
    explicitly, exposing the same functionality through more specifically named public
    methods such as `TryDequeue` and `TryPop`.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 三个具体类大多会显式实现`TryTake`和`TryAdd`方法，并通过更具体命名的公共方法（如`TryDequeue`和`TryPop`）暴露相同的功能。
- en: ConcurrentBag<T>
  id: totrans-462
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConcurrentBag<T>
- en: '`ConcurrentBag<T>` stores an *unordered* collection of objects (with duplicates
    permitted). `ConcurrentBag<T>` is suitable in situations for which you *don’t
    care* which element you get when calling `Take` or `TryTake`.'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentBag<T>`存储一个*无序*的对象集合（允许重复）。在调用`Take`或`TryTake`时，`ConcurrentBag<T>`适用于您*不在乎*获取哪个元素的情况。'
- en: The benefit of `ConcurrentBag<T>` over a concurrent queue or stack is that a
    bag’s `Add` method suffers almost *no* contention when called by many threads
    at once. In contrast, calling `Add` in parallel on a queue or stack incurs *some*
    contention (although a lot less than locking around a *nonconcurrent* collection).
    Calling `Take` on a concurrent bag is also very efficient—as long as each thread
    doesn’t take more elements than it `Add`ed.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentBag<T>`相较于并发队列或栈的好处在于，当多个线程同时调用袋子的`Add`方法时，几乎没有*竞争*。相比之下，同时在队列或栈上并行调用`Add`会产生*一些*竞争（尽管比在*非并发*集合周围加锁要少得多）。在并发袋子上调用`Take`也非常高效，只要每个线程不取出比它`Add`的元素还多。'
- en: Inside a concurrent bag, each thread gets its own private linked list. Elements
    are added to the private list that belongs to the thread calling `Add`, eliminating
    contention. When you enumerate over the bag, the enumerator travels through each
    thread’s private list, yielding each of its elements in turn.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发袋子内部，每个线程都有自己的私有链表。元素被添加到调用`Add`的线程的私有列表中，从而消除了竞争。当你枚举袋子时，枚举器遍历每个线程的私有列表，依次生成每个元素。
- en: When you call `Take`, the bag first looks at the current thread’s private list.
    If there’s at least one element,^([1](ch22.html#ch12fn1)) it can complete the
    task easily and without contention. But if the list is empty, it must “steal”
    an element from another thread’s private list and incur the potential for contention.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用`Take`时，袋子首先查看当前线程的私有列表。如果至少有一个元素，^([1](ch22.html#ch12fn1))它可以轻松地完成任务，而且没有竞争。但是如果列表为空，则必须从另一个线程的私有列表“偷取”一个元素，并且可能会发生竞争。
- en: So, to be precise, calling `Take` gives you the element added most recently
    on that thread; if there are no elements on that thread, it gives you the element
    added most recently on another thread, chosen at random.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，准确地说，调用`Take`会给你在该线程上最近添加的元素；如果该线程上没有元素，它会随机选择另一个线程上最近添加的元素。
- en: 'Concurrent bags are ideal when the parallel operation on your collection mostly
    comprises `Add`ing elements—or when the `Add`s and `Take`s are balanced on a thread.
    We saw an example of the former previously, when using `Parallel.ForEach` to implement
    a parallel spellchecker:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的集合上的并行操作大部分由`Add`元素组成时，或者`Add`和`Take`在一个线程上是平衡的时候，并发袋子是理想的选择。我们之前看到了前一种情况的例子，即使用`Parallel.ForEach`来实现并行拼写检查器：
- en: '[PRE86]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: A concurrent bag would be a poor choice for a producer/consumer queue because
    elements are added and removed by *different* threads.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产者/消费者队列来说，并发袋子不是一个好选择，因为元素是由*不同*的线程添加和移除的。
- en: BlockingCollection<T>
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BlockingCollection<T>
- en: If you call `TryTake` on any of the producer/consumer collections we discussed
    in the previous section, `ConcurrentStack<T>`, `ConcurrentQueue<T>`, and `ConcurrentBag<T>`,
    and the collection is empty, the method returns `false`. Sometimes, it would be
    more useful in this scenario to *wait* until an element is available.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在我们之前讨论过的生产者/消费者集合中的任何一个上调用`TryTake`，如`ConcurrentStack<T>`、`ConcurrentQueue<T>`和`ConcurrentBag<T>`，而且集合为空，则该方法返回`false`。在这种情况下，有时*等待*直到有元素可用会更有用。
- en: Rather than overloading the `TryTake` methods with this functionality (which
    would have caused a blowout of members after allowing for cancellation tokens
    and timeouts), PFX’s designers encapsulated this functionality into a wrapper
    class called `BlockingCollection<T>`. A blocking collection wraps any collection
    that implements `IProducerConsumerCollection<T>` and lets you `Take` an element
    from the wrapped collection—blocking if no element is available.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: PFX的设计者们没有通过对`TryTake`方法进行过多的重载（这样做会导致在允许取消令牌和超时后成员数量爆炸），而是将这个功能封装到一个名为`BlockingCollection<T>`的包装类中。阻塞集合包装任何实现`IProducerConsumerCollection<T>`的集合，并允许你从包装集合中`Take`一个元素——如果没有可用元素则阻塞。
- en: A blocking collection also lets you limit the total size of the collection,
    blocking the *producer* if that size is exceeded. A collection limited in this
    manner is called a *bounded blocking collection*.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 阻塞集合还允许你限制集合的总大小，如果超出该大小则阻塞*生产者*。以这种方式限制的集合称为*有界阻塞集合*。
- en: 'To use `BlockingCollection<T>`:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`BlockingCollection<T>`：
- en: Instantiate the class, optionally specifying the `IProducerConsumerCollection<T>`
    to wrap and the maximum size (bound) of the collection.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化该类，可以选择包装`IProducerConsumerCollection<T>`和集合的最大大小（界限）。
- en: Call `Add` or `TryAdd` to add elements to the underlying collection.
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`Add`或`TryAdd`以向底层集合添加元素。
- en: Call `Take` or `TryTake` to remove (consume) elements from the underlying collection.
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`Take`或`TryTake`以从底层集合中移除（消费）元素。
- en: If you call the constructor without passing in a collection, the class will
    automatically instantiate a `ConcurrentQueue<T>`. The producing and consuming
    methods let you specify cancellation tokens and timeouts. `Add` and `TryAdd` may
    block if the collection size is bounded; `Take` and `TryTake` block while the
    collection is empty.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在不传递集合的情况下调用构造函数，该类将自动实例化一个`ConcurrentQueue<T>`。生产和消费方法允许你指定取消令牌和超时。`Add`和`TryAdd`可能会在集合大小有限时阻塞；`Take`和`TryTake`在集合为空时阻塞。
- en: 'Another way to consume elements is to call `GetConsumingEnumerable`. This returns
    a (potentially) infinite sequence that yields elements as they become available.
    You can force the sequence to end by calling `CompleteAdding`: this method also
    prevents further elements from being enqueued.'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种消费元素的方法是调用`GetConsumingEnumerable`。它返回一个（可能是）无限序列，随着元素变得可用而产生。你可以通过调用`CompleteAdding`强制结束序列：这个方法也阻止进一步的元素入列。
- en: '`BlockingCollection` also provides static methods called `AddToAny` and `TakeFro⁠m​Any`,
    which let you add or take an element while specifying several blocking collections.
    The action is then honored by the first collection able to service the request.'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '`BlockingCollection`还提供了名为`AddToAny`和`TakeFro⁠m​Any`的静态方法，让你在指定多个阻塞集合时添加或取出一个元素。动作将由能够服务请求的第一个集合执行。'
- en: Writing a Producer/Consumer Queue
  id: totrans-482
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写生产者/消费者队列
- en: 'A producer/consumer queue is a useful structure, both in parallel programming
    and general concurrency scenarios. Here’s how it works:'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者/消费者队列在并行编程和一般并发场景中非常有用。它的工作原理如下：
- en: A queue is set up to describe work items—or data upon which work is performed.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置队列以描述工作项——或对其进行处理的数据。
- en: When a task needs executing, it’s enqueued, and the caller gets on with other
    things.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当任务需要执行时，它被加入队列，调用者继续处理其他事务。
- en: One or more worker threads plug away in the background, picking off and executing
    queued items.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个工作线程在后台运行，从队列中取出并执行排队的项。
- en: A producer/consumer queue gives you precise control over how many worker threads
    execute at once, which is useful not only in limiting CPU consumption but other
    resources, as well. If the tasks perform intensive disk I/O, for instance, you
    can limit concurrency to avoid starving the operating system and other applications.
    You can also dynamically add and remove workers throughout the queue’s life. The
    CLR’s thread pool itself is a kind of producer/consumer queue, optimized for short-running
    compute-bound jobs.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者/消费者队列让你精确控制同时执行的工作线程数量，这不仅有助于限制CPU消耗，还包括其他资源。例如，如果任务执行密集的磁盘I/O操作，你可以限制并发以避免使操作系统和其他应用程序饥饿。你还可以在队列生命周期中动态添加和删除工作线程。CLR的线程池本身就是一种生产者/消费者队列，专门优化于短期运行的计算密集型任务。
- en: A producer/consumer queue typically holds items of data upon which (the same)
    task is performed. For example, the items of data may be filenames, and the task
    might be to encrypt those files. By making the item a delegate, however, you can
    write a more general-purpose producer/consumer queue where each item can do anything.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 一个生产者/消费者队列通常保存数据项，对这些数据项执行（相同的）任务。例如，数据项可以是文件名，任务可能是加密这些文件。然而，通过将数据项设为委托，你可以编写一个更通用的生产者/消费者队列，其中每个数据项都可以执行任何操作。
- en: 'At [*http://albahari.com/threading*](http://albahari.com/threading), we show
    how to write a producer/consumer queue from scratch using an `AutoResetEvent`
    (and later, using `Monitor`’s `Wait` and `Pulse`). However, writing a producer/consumer
    from scratch is unnecessary because most of the functionality is provided by `BlockingCollection<T>`.
    Here’s how to use it:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*http://albahari.com/threading*](http://albahari.com/threading)，我们展示如何使用`AutoResetEvent`（以及后来使用`Monitor`的`Wait`和`Pulse`）从头开始编写一个生产者/消费者队列。然而，从头开始编写一个生产者/消费者是不必要的，因为大部分功能已经被`BlockingCollection<T>`提供。以下是如何使用它：
- en: '[PRE87]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Because we didn’t pass anything into `BlockingCollection`’s constructor, it
    instantiated a concurrent queue automatically. Had we passed in a `ConcurrentStack`,
    we’d have ended up with a producer/consumer stack.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们没有向`BlockingCollection`的构造函数传递任何内容，它自动实例化了一个并发队列。如果我们传入了一个`ConcurrentStack`，我们将得到一个生产者/消费者栈。
- en: Using Tasks
  id: totrans-492
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用任务
- en: 'The producer/consumer that we just wrote is inflexible in that we can’t track
    work items after they’ve been enqueued. It would be nice if we could do the following:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚编写的生产者/消费者是不灵活的，因为我们无法在将工作项入队后跟踪它们。如果我们能做到以下几点就好了：
- en: Know when a work item has completed (and `await` it)
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知道何时一个工作项已经完成（并`await`它）
- en: Cancel a work item
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取消一个工作项
- en: Deal elegantly with any exceptions thrown by a work item
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优雅地处理工作项抛出的任何异常
- en: 'An ideal solution would be to have the `Enqueue` method return some object
    giving us the functionality just described. The good news is that a class already
    exists to do exactly this—the `Task` class, which we can generate either with
    a `TaskCompletionSource` or by instantiating directly (creating an unstarted or
    *cold* task):'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 一个理想的解决方案是让`Enqueue`方法返回一个对象，给我们刚才描述的功能。好消息是已经存在一个类来做到这一点——`Task`类，我们可以通过`TaskCompletionSource`生成或直接实例化（创建一个未启动或*冷*任务）：
- en: '[PRE88]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: In `Enqueue`, we enqueue and return to the caller a task that we create but
    don’t start.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Enqueue`中，我们入队并返回给调用者一个我们创建但不启动的任务。
- en: In `Consume`, we run the task synchronously on the consumer’s thread. We catch
    an `InvalidOperationException` to handle the unlikely event that the task is canceled
    in between checking whether it’s canceled and running it.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Consume`中，我们在消费者线程上同步运行任务。我们捕获`InvalidOperationException`以处理任务在检查是否取消和运行之间被取消的不太可能事件。
- en: 'Here’s how we can use this class:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用这个类：
- en: '[PRE89]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Hence, we have all the benefits of tasks—with exception propagation, return
    values, and cancellation—while taking complete control over scheduling.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们拥有任务的所有好处——异常传播、返回值和取消——同时完全控制调度。
- en: ^([1](ch22.html#ch12fn1-marker)) Due to an implementation detail, there actually
    needs to be at least two elements to avoid contention entirely.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch22.html#ch12fn1-marker)) 由于一个实现细节，实际上至少需要两个元素才能完全避免争用。
