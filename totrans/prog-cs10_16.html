<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 16. Multithreading" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch_multithreading">
<h1><span class="label">Chapter 16. </span>Multithreading</h1>
<p><a data-primary="multithreading" data-type="indexterm" id="ix_ch16-asciidoc0"/>Multithreading enables an application to execute several pieces of code simultaneously. There are two common reasons for doing this. One is to exploit the computer’s parallel processing capabilities—multicore CPUs are now more or less ubiquitous, and to realize their full performance potential, you’ll need to provide the CPU with multiple streams of work to give all of the cores something useful to do. The other usual reason for writing multithreaded code is to prevent progress from grinding to a halt when you do something slow, such as reading from disk.</p>
<p>Multithreading is not the only way to solve that second problem—asynchronous techniques can be preferable. C# has features for supporting asynchronous work. Asynchronous execution doesn’t necessarily mean multithreading, but the two are often related in practice, and I will be describing some of the asynchronous programming models in this chapter. However, this chapter focuses on the threading foundations. I will describe the language-level support for asynchronous code in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>.</p>
<section data-pdf-bookmark="Threads" data-type="sect1"><div class="sect1" id="threads">
<h1>Threads</h1>
<p><a data-primary="multithreading" data-secondary="threads" data-seealso="threads" data-type="indexterm" id="ix_ch16-asciidoc1"/><a data-primary="threads" data-type="indexterm" id="ix_ch16-asciidoc2"/>All the operating systems that .NET can run on allow each process to contain multiple threads (although if you build to Web Assembly and run code in the browser, that particular environment currently doesn’t support creation of new threads). Each thread has its own stack, and the OS presents the illusion that a thread gets a whole CPU <em>hardware thread</em> to itself. (See the next sidebar, <a href="#processors_comma_cores_comma_and_hardwar">“Processors, Cores, and Hardware Threads”</a>.) You can create far more OS threads than the number of hardware threads your computer provides, because the OS virtualizes the CPU, context switching from one thread to another. The computer I’m using as I write this has 16 hardware threads, which is a reasonably generous quantity but some way short of the 8,893 threads currently active across the various processes running on the machine.</p>
<aside class="pagebreak-before" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="processors_comma_cores_comma_and_hardwar">
<h5>Processors, Cores, and Hardware Threads</h5>
<p><a data-primary="hardware threads" data-type="indexterm" id="idm45884788973600"/><a data-primary="threads" data-secondary="hardware threads" data-type="indexterm" id="idm45884788972896"/>A <em>hardware thread</em> is one piece of hardware capable of executing code. Back in the early 2000s, one processor chip gave you one hardware thread, and you got multiple hardware threads only in computers that had multiple, physically separate CPUs plugged into separate sockets on the motherboard. However, two inventions have made the relationship between hardware and threads more complex: multicore CPUs and hyperthreading.</p>
<p>With a multicore CPU, you effectively get multiple processors on a single piece of silicon. This means that opening up your computer and counting the number of processor chips doesn’t necessarily tell you how many hardware threads you’ve got. But if you were to inspect the CPU’s silicon with a suitable microscope, you’d see two or more distinct processors next to each other on the chip.</p>
<p><a data-primary="hyperthreading" data-type="indexterm" id="idm45884788969872"/><a data-primary="simultaneous multithreading (SMT)" data-type="indexterm" id="idm45884788969168"/><a data-primary="SMT (simultaneous multithreading)" data-type="indexterm" id="idm45884788968528"/>Hyperthreading, also known as simultaneous multithreading (SMT), complicates matters further. A hyperthreaded core is a single processor that has two sets of certain parts. (It could be more than two, but doubling seems most common.) So, although there might be only a single part of the core capable of performing, say, floating-point division, there will be two sets of registers. Each set of registers includes an instruction pointer (IP) register that keeps track of where execution has reached. Registers also contain the immediate working state of the code, so by having two sets, a single core can run code from two places at once—in other words, hyperthreading enables a single core to provide two hardware threads. Since only certain parts of the CPU are doubled up, two execution contexts have to share some resources—they can’t both perform floating-point division operations simultaneously, because there’s only one piece of hardware in the core to do that. However, if one of the hardware threads wants to do some division while another multiplies two numbers together, they will typically be able to do so in parallel, because those operations are performed by different areas of the core. Hyperthreading enables more parts of a single CPU core to be kept busy simultaneously. It doesn’t give you quite the same throughput as two full cores (because if the two hardware threads both want to do the same kind of work at once, one of them will have to wait), but it can often provide better throughput from each core than would otherwise be possible.</p>
<p>In a hyperthreaded system, the total number of hardware threads available is the number of cores multiplied by the number of hyperthreaded execution units per core. For example, the Intel Core i9-9900K processor has 8 cores with two-way hyperthreading, giving a total of 16 hardware threads.</p>
</div></aside>
<p>The CLR presents its own threading abstraction on top of OS threads. In .NET Core and .NET, there will always be a direct relationship—each <code>Thread</code> object corresponds directly to some particular underlying OS thread. On .NET Framework, this relationship is not guaranteed to exist—applications that use the CLR’s unmanaged hosting API to customize the relationship between the CLR and its containing process can in theory cause a CLR thread to move between different OS threads. In practice, this capability was very rarely used, so even on .NET Framework, each CLR thread will correspond to one OS thread in practice.</p>
<p>I will get to the <code>Thread</code> class shortly, but before writing multithreaded code, you need to understand the ground rules for managing state<sup><a data-type="noteref" href="ch16.xhtml#CHP-17-FN-2" id="CHP-17-FN-2-marker">1</a></sup> when using multiple threads.</p>
<section data-pdf-bookmark="Threads, Variables, and Shared State" data-type="sect2"><div class="sect2" id="threads_comma_variables_comma_and_shared">
<h2>Threads, Variables, and Shared State</h2>
<p><a data-primary="threads" data-secondary="variables and shared state" data-type="indexterm" id="ix_ch16-asciidoc3"/>Each CLR thread gets various thread-specific resources, such as the call stack (which holds method arguments and some local variables). Because each thread has its own stack, the local variables that end up there will be local to the thread. Each time you invoke a method, you get a new set of its local variables. Recursion relies on this, but it’s also important in multithreaded code, because data that is accessible to multiple threads requires much more care, particularly if that data changes. Coordinating access to shared data is complex. I’ll be describing some of the techniques for that in the section <a data-type="xref" href="#synchronization">“Synchronization”</a>, but it’s better to avoid the problem entirely where possible, and the thread-local nature of the stack can be a great help.</p>
<p>For example, consider a web-based application. Busy sites have to handle requests from multiple users simultaneously, so you’re likely to end up in a situation where a particular piece of code (e.g., the code for your site’s home page) is being executed simultaneously on several different threads—ASP.NET Core uses multithreading to be able to serve the same logical page to multiple users. (Websites typically don’t just serve up the exact same content, because pages are often tailored to particular users, so if 1,000 users ask to see the home page, it will run the code that generates that page 1,000 times.) ASP.NET Core provides you with various objects that your code will need to use, but most of these are specific to a particular request. So, if your code is able to work entirely with those objects and with local variables, each thread can operate completely independently. If you need shared state (such as objects that are visible to multiple threads, perhaps through a static field or property), life will get more difficult, but local variables are usually straightforward.</p>
<p>Why only “usually”? Things get more complex if you use lambdas or anonymous functions, because they make it possible to declare a variable in a containing method and then use that in an inner method. This variable is now available to two or more methods, and with multithreading, it’s possible that these methods could execute concurrently. (As far as the CLR is concerned, it’s not really a local variable anymore—it’s a field in a compiler-generated class.) Sharing local variables across multiple methods removes the guarantee of complete locality, so you need to take the same sort of care with such variables as you would with more obviously shared items, like static properties and fields.</p>
<p>Another important point to remember in multithreaded environments is the distinction between a variable and the object it refers to. (This is an issue only with reference type variables.) Although a local variable is accessible only inside its declaring method, that variable may not be the only one that refers to a particular object. Sometimes it will be—if you create the object inside the method and never store it anywhere that would make it accessible to a wider audience, then you have nothing to worry about. <a data-primary="StringBuilder class" data-type="indexterm" id="idm45884788956432"/>The <code>StringBuilder</code> that <a data-type="xref" href="#an_object_visible_only_to_method">Example 16-1</a> creates is only ever used within the method that creates it.</p>
<div data-type="example" id="an_object_visible_only_to_method">
<h5><span class="label">Example 16-1. </span>Object visibility and methods</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">static</code> <code class="kt">string</code> <code class="n">FormatDictionary</code><code class="p">&lt;</code><code class="n">TKey</code><code class="p">,</code> <code class="n">TValue</code><code class="p">&gt;(</code>
    <code class="n">IDictionary</code><code class="p">&lt;</code><code class="n">TKey</code><code class="p">,</code> <code class="n">TValue</code><code class="p">&gt;</code> <code class="n">input</code><code class="p">)</code>
<code class="p">{</code>
    <code class="kt">var</code> <code class="n">sb</code> <code class="p">=</code> <code class="k">new</code> <code class="n">StringBuilder</code><code class="p">();</code>
    <code class="k">foreach</code> <code class="p">(</code><code class="kt">var</code> <code class="n">item</code> <code class="k">in</code> <code class="n">input</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">sb</code><code class="p">.</code><code class="n">AppendFormat</code><code class="p">(</code><code class="s">"{0}: {1}"</code><code class="p">,</code> <code class="n">item</code><code class="p">.</code><code class="n">Key</code><code class="p">,</code> <code class="n">item</code><code class="p">.</code><code class="n">Value</code><code class="p">);</code>
        <code class="n">sb</code><code class="p">.</code><code class="n">AppendLine</code><code class="p">();</code>
    <code class="p">}</code>

    <code class="k">return</code> <code class="n">sb</code><code class="p">.</code><code class="n">ToString</code><code class="p">();</code>
<code class="p">}</code></pre></div>
<p>This code does not need to worry about whether other threads might be trying to modify the <code>StringBuilder</code>. There are no nested methods here, so the <code>sb</code> variable is truly local, and that’s the only thing that contains a reference to the <code>StringBuilder</code>. (This relies on the fact that the <code>StringBuilder</code> doesn’t sneakily store copies of its <code>this</code> reference anywhere that other threads might be able to see.)</p>
<p>But what about the <code>input</code> argument? That’s also local to the method, but the object it refers to is not: the code that calls <code>FormatDictionary</code> gets to decide what <code>input</code> refers to. Looking at <a data-type="xref" href="#an_object_visible_only_to_method">Example 16-1</a> in isolation, it’s not possible to say whether the dictionary object to which it refers is currently in use by other threads. The calling code could create a single dictionary and then create two threads, and have one modify the dictionary while the other calls this <code>FormatDictionary</code> method. This would cause a problem: most dictionary implementations do not support being modified on one thread at the same time as being used on some other thread. And even if you were working with a collection that was designed to cope with concurrent use, you’re often not allowed to modify a collection while an enumeration of its contents is in progress (e.g., a <code>foreach</code> loop).</p>
<p>You might think that any collection designed to be used from multiple threads simultaneously (a <em>thread-safe</em> collection, you might say) should allow one thread to iterate over its contents while another modifies the contents. If it disallows this, then in what sense is it thread safe? In fact, the main difference between a thread-safe and a non-thread-safe collection in this scenario is predictability: whereas a thread-safe collection might throw an exception when it detects that this has happened, a non-thread-safe collection does not guarantee to do anything in particular. It might crash, or you might start getting perplexing results from the iteration, such as a single entry appearing multiple times. It could do more or less anything because you’re using it in an unsupported way. Sometimes, thread safety just means that failure happens in a well-defined and predictable manner.</p>
<p>As it happens, the various collections in the <code>System.Collection.Concurrent</code> namespace do in fact support changes while enumeration is in progress without throwing exceptions. However, for the most part they have a different API from the other collection classes specifically to support concurrency, so they are not always drop-in replacements.</p>
<p>There’s nothing <a data-type="xref" href="#an_object_visible_only_to_method">Example 16-1</a> can do to ensure that it uses its <code>input</code> argument safely in multithreaded environments, because it is at the mercy of its callers. Concurrency hazards need to be dealt with at a higher level. In fact, the term <em>thread safe</em> is potentially misleading, because it suggests something that is not, in general, possible. Inexperienced developers often fall into the trap of thinking that they are absolved of all responsibility for thinking about threading issues in their code by just making sure that all the objects they’re using are thread safe. This usually doesn’t work, because while individual thread-safe objects will maintain their own integrity, that’s no guarantee that your application’s state as a whole will be coherent.</p>
<p>To illustrate this, <a data-type="xref" href="#thread_safe_but_not">Example 16-2</a> uses the <code>ConcurrentDictionary&lt;TKey, TValue&gt;</code> class from the <code>System.Collections.Concurrent</code> namespace. Every operation this class defines is thread safe in the sense that each will leave the object in a consistent state and will produce the expected result given the collection’s state prior to the call. However, this example contrives to use it in a non-thread-safe fashion.</p>
<div data-type="example" id="thread_safe_but_not">
<h5><span class="label">Example 16-2. </span>Non-thread-safe use of a thread-safe collection</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">static</code> <code class="kt">string</code> <code class="nf">UseDictionary</code><code class="p">(</code><code class="n">ConcurrentDictionary</code><code class="p">&lt;</code><code class="kt">int</code><code class="p">,</code> <code class="kt">string</code><code class="p">&gt;</code> <code class="n">cd</code><code class="p">)</code>
<code class="p">{</code>
    <code class="n">cd</code><code class="p">[</code><code class="m">1</code><code class="p">]</code> <code class="p">=</code> <code class="s">"One"</code><code class="p">;</code>
    <code class="k">return</code> <code class="n">cd</code><code class="p">[</code><code class="m">1</code><code class="p">];</code>
<code class="p">}</code></pre></div>
<p>This seems like it could not fail. (It also seems pointless; that’s just to show how even a very simple piece of code can go wrong.) But if the dictionary instance is being used by multiple threads (which seems likely, given that we’ve chosen a type designed specifically for multithreaded use), it’s entirely possible that in between setting a value for key 1 and trying to retrieve it, some other thread will have removed that entry. If I put this code into a program that repeatedly runs this method on several threads, but that also has several other threads busily removing the very same entry, I eventually see a <code>KeyNotFoundException</code>.</p>
<p>Concurrent systems need a top-down strategy to ensure system-wide consistency. (This is why database management systems often use transactions, which group sets of operations together as atomic units of work that either succeed completely or have no effect at all. This atomic grouping is a critical part of how transactions help to ensure system-wide consistency of state.) Looking at <a data-type="xref" href="#an_object_visible_only_to_method">Example 16-1</a>, this means that it is the responsibility of code that calls <code>FormatDictionary</code> to ensure that the dictionary can be used freely for the duration of the method.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Although calling code should guarantee that whatever objects it passes are safe to use for the duration of a method call, you cannot in general assume that it’s OK to hold on to references to your arguments for future use. Anonymous functions and delegates make it easy to do this accidentally—if a nested method refers to its containing method’s arguments, and if that nested method runs after the containing method returns, it may no longer be safe to assume that you’re allowed to access the objects to which the arguments refer. If you need to do this, you will need to document the assumptions you’re making about when you can use objects, and inspect any code that calls the method to make sure that these assumptions are valid.</p>
</div>
</div></section>
<section data-pdf-bookmark="Thread-Local Storage" data-type="sect2"><div class="sect2" id="thread-local_storage">
<h2>Thread-Local Storage</h2>
<p><a data-primary="state, thread-local storage and" data-type="indexterm" id="ix_ch16-asciidoc4"/><a data-primary="storage, thread-local" data-type="indexterm" id="ix_ch16-asciidoc5"/><a data-primary="thread-local storage" data-type="indexterm" id="ix_ch16-asciidoc6"/><a data-primary="threads" data-secondary="thread-local storage" data-type="indexterm" id="ix_ch16-asciidoc7"/>Sometimes it can be useful to maintain thread-local state at a broader scope than a single method. Various parts of the runtime libraries do this. For example, the 
<span class="keep-together"><code>System.Transactions</code></span> namespace defines an API for using transactions with databases, message queues, and any other resource managers that support them. It provides an implicit model where you can start an <em>ambient transaction</em>, and any operations that support this will enlist in it without you needing to pass any explicit transaction-related arguments. (It also supports an explicit model, should you prefer that.) The <code>Transaction</code> class’s static <code>Current</code> property returns the ambient transaction for the current thread, or it returns <code>null</code> if the thread currently has no ambient transaction in progress.</p>
<p><a data-primary="ThreadLocal&lt;T&gt; class" data-type="indexterm" id="idm45884788814784"/>To support this sort of per-thread state, .NET offers the <code>ThreadLocal&lt;T&gt;</code> class. <a data-type="xref" href="#using_threadlocalltg">Example 16-3</a> uses this to provide a wrapper around a delegate that allows only a single call into the delegate to be in progress on any one thread at any time.</p>
<div data-type="example" id="using_threadlocalltg">
<h5><span class="label">Example 16-3. </span>Using <code>ThreadLocal&lt;T&gt;</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">class</code> <code class="nc">Notifier</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="n">Action</code> <code class="n">_callback</code><code class="p">;</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="n">ThreadLocal</code><code class="p">&lt;</code><code class="kt">bool</code><code class="p">&gt;</code> <code class="n">_isCallbackInProgress</code> <code class="p">=</code> <code class="k">new</code><code class="p">();</code>

    <code class="k">public</code> <code class="nf">Notifier</code><code class="p">(</code><code class="n">Action</code> <code class="n">callback</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">_callback</code> <code class="p">=</code> <code class="n">callback</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Notify</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">_isCallbackInProgress</code><code class="p">.</code><code class="n">Value</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="k">throw</code> <code class="k">new</code> <code class="nf">InvalidOperationException</code><code class="p">(</code>
                <code class="s">"Notification already in progress on this thread"</code><code class="p">);</code>
        <code class="p">}</code>

        <code class="k">try</code>
        <code class="p">{</code>
            <code class="n">_isCallbackInProgress</code><code class="p">.</code><code class="n">Value</code> <code class="p">=</code> <code class="k">true</code><code class="p">;</code>
            <code class="n">_callback</code><code class="p">();</code>
        <code class="p">}</code>
        <code class="k">finally</code>
        <code class="p">{</code>
            <code class="n">_isCallbackInProgress</code><code class="p">.</code><code class="n">Value</code> <code class="p">=</code> <code class="k">false</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>If the method that <code>Notify</code> calls back attempts to make another call to <code>Notify</code>, this will block that attempt at recursion by throwing an exception. However, because it uses a <code>ThreadLocal&lt;bool&gt;</code> to track whether a call is in progress, this will allow simultaneous calls as long as each call happens on a separate thread.</p>
<p>You get and set the value that <code>ThreadLocal&lt;T&gt;</code> holds for the current thread through the <code>Value</code> property. The constructor is overloaded, and you can pass a <code>Func&lt;T&gt;</code> that will be called back each time a new thread first tries to retrieve the value to create a default initial value. (The initialization is lazy—the callback won’t run every time a new thread starts. A <code>ThreadLocal&lt;T&gt;</code> invokes the callback only the first time a thread attempts to use the value.) There is no fixed limit to the number of <code>ThreadLocal&lt;T&gt;</code> objects you can create.</p>
<p><code>ThreadLocal&lt;T&gt;</code> also provides some support for cross-thread communication. If you pass an argument of <code>true</code> to one of the constructor overloads that accepts a <code>bool</code>, the object will maintain a collection reporting the latest value stored for every thread, which is available through its <code>Values</code> property. It provides this service only if you ask for it when constructing the object, because it requires some additional housekeeping work. Also, if you use a reference type as the type argument, enabling tracking may mean that objects will be kept alive longer. Normally, any reference that a thread stores in a <code>ThreadLocal&lt;T&gt;</code> will cease to exist when the thread terminates, and if that reference was the only one keeping an object reachable, the GC will then be able to reclaim its memory. But if you enable tracking, all such references will remain reachable for as long as the <code>ThreadLocal&lt;T&gt;</code> instance itself is reachable, because <code>Values</code> reports values even for threads that have terminated.</p>
<p>There’s one thing you need to be careful about with thread-local storage. If you create a new object for each thread, be aware that an application might create a large number of threads over its lifetime, especially if you use the thread pool (which is described in detail later). If the per-thread objects you create are expensive, this might cause problems. Furthermore, if there are any disposable per-thread resources, you will not necessarily know when a thread terminates; the thread pool regularly creates and destroys threads without telling you when it does so.</p>
<p><a data-primary="ThreadStatic attribute" data-type="indexterm" id="idm45884788646432"/>If you don’t need the automatic creation each time a new thread first uses thread-local storage, you can instead just annotate a static field with the <code>[ThreadStatic]</code> attribute. This is handled by the CLR: it effectively means that each thread that accesses this field gets its own distinct field. This can reduce the number of objects that need to be allocated. But be careful: it’s possible to define a field initializer for such fields, but that initializer will run only for the first thread to access the field. For other threads using the same <code>[ThreadStatic]</code>, the field will initially contain the default zero-like value for the field’s type.</p>
<p>One last note of caution: be wary of thread-local storage (and any mechanism based on it) if you plan to use the asynchronous language features described in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>, because those make it possible for a single invocation of a method to use multiple different threads as it progresses. This would make it a bad idea for that sort of method to use ambient transactions, or anything else that relies on thread-local state. Many .NET features that you might think would use thread-local storage (e.g., the ASP.NET Core framework’s static <code>HttpContext.Current</code> property, which returns an object relating to the HTTP request that the current thread is handling) turn out to associate information with something called the <em>execution context</em> instead. An execution context is more flexible, because it can hop across threads when required. I’ll be describing it later.</p>
<p>For the issues I’ve just discussed to be relevant, we’ll need to have multiple threads. There are four main ways to use multithreading. In one, the code runs in a framework that creates multiple threads on your behalf, such as ASP.NET Core. Another is to use certain kinds of callback-based APIs. A few common patterns for this are described in <a data-type="xref" href="#tasks">“Tasks”</a> and <a data-type="xref" href="#other_asynchronous_patterns">“Other Asynchronous Patterns”</a>. <span class="keep-together">But the two</span> most direct ways to use threads are to create new threads explicitly or to use the .NET thread pool<a data-startref="ix_ch16-asciidoc7" data-type="indexterm" id="idm45884788639184"/><a data-startref="ix_ch16-asciidoc6" data-type="indexterm" id="idm45884788638480"/><a data-startref="ix_ch16-asciidoc5" data-type="indexterm" id="idm45884788637808"/><a data-startref="ix_ch16-asciidoc4" data-type="indexterm" id="idm45884788637136"/>.<a data-startref="ix_ch16-asciidoc3" data-type="indexterm" id="idm45884788636336"/></p>
</div></section>
<section data-pdf-bookmark="The Thread Class" data-type="sect2"><div class="sect2" id="the_thread_class">
<h2>The Thread Class</h2>
<p><a data-primary="Thread class" data-type="indexterm" id="ix_ch16-asciidoc8"/><a data-primary="threads" data-secondary="Thread class" data-type="indexterm" id="ix_ch16-asciidoc9"/>As I mentioned earlier, the <code>Thread</code> class (defined in the <code>System.Threading</code> namespace) represents a CLR thread. You can obtain a reference to the <code>Thread</code> object representing the thread that’s executing your code with the <code>Thread.CurrentThread</code> property, but if you’re looking to introduce some multithreading, you can construct a new <code>Thread</code> object.</p>
<p>A new thread needs to know what code it should run when it starts, so you must provide a delegate, and the thread will invoke the method the delegate refers to when it starts. The thread will run until that method returns normally, or allows an exception to propagate all the way to the top of the stack (or the thread is forcibly terminated through any of the OS mechanisms for killing threads or their containing processes). <a data-type="xref" href="#creating_threads">Example 16-4</a> creates three threads to download the contents of three web pages simultaneously.<a data-primary="HttpClient class" data-type="indexterm" id="idm45884788628016"/></p>
<div data-type="example" id="creating_threads">
<h5><span class="label">Example 16-4. </span>Creating threads</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">internal</code> <code class="k">static</code> <code class="k">class</code> <code class="nc">Program</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">static</code> <code class="k">readonly</code> <code class="n">HttpClient</code> <code class="n">http</code> <code class="p">=</code> <code class="k">new</code><code class="p">();</code>

    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">Main</code><code class="p">(</code><code class="kt">string</code><code class="p">[]</code> <code class="n">args</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">Thread</code> <code class="n">t1</code> <code class="p">=</code> <code class="k">new</code><code class="p">(</code><code class="n">MyThreadEntryPoint</code><code class="p">);</code>
        <code class="n">Thread</code> <code class="n">t2</code> <code class="p">=</code> <code class="k">new</code><code class="p">(</code><code class="n">MyThreadEntryPoint</code><code class="p">);</code>
        <code class="n">Thread</code> <code class="n">t3</code> <code class="p">=</code> <code class="k">new</code><code class="p">(</code><code class="n">MyThreadEntryPoint</code><code class="p">);</code>

        <code class="n">t1</code><code class="p">.</code><code class="n">Start</code><code class="p">(</code><code class="s">"https://endjin.com/"</code><code class="p">);</code>
        <code class="n">t2</code><code class="p">.</code><code class="n">Start</code><code class="p">(</code><code class="s">"https://oreilly.com/"</code><code class="p">);</code>
        <code class="n">t3</code><code class="p">.</code><code class="n">Start</code><code class="p">(</code><code class="s">"https://dotnet.microsoft.com/"</code><code class="p">);</code>
    <code class="p">}</code>

    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">MyThreadEntryPoint</code><code class="p">(</code><code class="kt">object?</code> <code class="n">arg</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="kt">string</code> <code class="n">url</code> <code class="p">=</code> <code class="p">(</code><code class="kt">string</code><code class="p">)</code><code class="n">arg</code><code class="p">!;</code>

        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="err">$</code><code class="s">"Downloading {url}"</code><code class="p">);</code>
        <code class="kt">var</code> <code class="n">response</code> <code class="p">=</code> <code class="n">http</code><code class="p">.</code><code class="n">Send</code><code class="p">(</code><code class="k">new</code> <code class="n">HttpRequestMessage</code><code class="p">(</code><code class="n">HttpMethod</code><code class="p">.</code><code class="n">Get</code><code class="p">,</code> <code class="n">url</code><code class="p">));</code>
        <code class="k">using</code> <code class="nn">StreamReader</code> <code class="n">r</code> <code class="p">=</code> <code class="k">new</code><code class="p">(</code><code class="n">response</code><code class="p">.</code><code class="n">Content</code><code class="p">.</code><code class="n">ReadAsStream</code><code class="p">());</code>
        <code class="kt">string</code> <code class="n">page</code> <code class="p">=</code> <code class="n">r</code><code class="p">.</code><code class="n">ReadToEnd</code><code class="p">();</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="err">$</code><code class="s">"Downloaded {url}, length {page.Length}"</code><code class="p">);</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>The <code>Thread</code> constructor is overloaded and accepts two delegate types. The <code>ThreadStart</code> delegate requires a method that takes no arguments and returns no value, but in <a data-type="xref" href="#creating_threads">Example 16-4</a>, the <code>MyThreadEntryPoint</code> method takes a single <code>object</code> argument, which matches the other delegate type, <code>ParameterizedThreadStart</code>. This provides a way to pass an argument to each thread, which is useful if you’re invoking the same method on several different threads, as this example does. The thread will not run until you call <code>Start</code>, and if you’re using the <code>ParameterizedThreadStart</code> delegate type, you must call the overload that takes a single <code>object</code> argument. I’m using this to make each thread download from a different URL.</p>
<p>There are two more overloads of the <code>Thread</code> constructor, each adding an <code>int</code> argument after the delegate argument. This <code>int</code> specifies the size of stack for the thread. Current .NET implementations require stacks to be contiguous in memory, making it necessary to preallocate address space for the stack. If a thread exhausts this space, the CLR throws a <code>StackOverflowException</code>. (You normally see those only when a bug causes infinite recursion.) Without this argument, the CLR will use the default stack size for the process. (This varies by OS; on Windows it will usually be 1 MB. You can change it by setting the <code>DOTNET_DefaultStackSize</code> environment variable. Note that it interprets the value as a hexadecimal number.) It’s rare to need to change this but not unheard of. If you have recursive code that produces very deep stacks, you might need to run it on a thread with a larger stack. Conversely, if you’re creating huge numbers of threads, you might want to reduce the stack size to conserve resources, because the default of 1 MB is usually considerably more than is really required. However, it’s usually not a great idea to create such a large number of threads. So, in most cases, you will create only a moderate number of threads and just use the constructors that use the default stack size.</p>
<p>Notice that the <code>Main</code> method in <a data-type="xref" href="#creating_threads">Example 16-4</a> returns immediately after starting the three threads. Despite this, the application continues to run—it will run until all the threads finish. The CLR keeps the process alive until there are no <em>foreground threads</em> running, where a foreground thread is defined to be any thread that hasn’t explicitly been designated as a background thread. If you want to prevent a particular thread from keeping the process running, set its <code>IsBackground</code> property to <code>true</code>. (This means that background threads may be terminated while they’re in the middle of doing something, so you need to be careful about what kind of work you do on these threads.)</p>
<p>Creating threads directly is not the only option. The thread pool provides a commonly used alternative.<a data-startref="ix_ch16-asciidoc9" data-type="indexterm" id="idm45884788545104"/><a data-startref="ix_ch16-asciidoc8" data-type="indexterm" id="idm45884788544400"/></p>
</div></section>
<section data-pdf-bookmark="The Thread Pool" data-type="sect2"><div class="sect2" id="the_thread_pool">
<h2>The Thread Pool</h2>
<p><a data-primary="thread pool" data-type="indexterm" id="ix_ch16-asciidoc10"/><a data-primary="threads" data-secondary="thread pool" data-type="indexterm" id="ix_ch16-asciidoc11"/>On most operating systems, it is relatively expensive to create and shut down threads. If you need to perform a fairly short piece of work (such as serving up a web page or some similarly brief operation), it would be a bad idea to create a thread just for that job and to shut it down when the work completes. There are two serious problems with this strategy: first, you may end up expending more resources on the startup and shutdown costs than on useful work; second, if you keep creating new threads as more work comes in, the system may bog down under load—with heavy workloads, creating ever more threads will tend to reduce throughput. This is because, in addition to basic per-thread overheads such as the memory required for the stack, the OS needs to switch regularly between runnable threads to enable them all to make progress, and this switching has its own overheads.</p>
<p>To avoid these problems, .NET provides a thread pool. You can supply a delegate that the runtime will invoke on a thread from the pool. If necessary, it will create a new thread, but where possible, it will reuse one it created earlier, and it might make your work wait in a queue if all the threads created so far are busy. After your method runs, the CLR will not normally terminate the thread; instead, the thread will stay in the pool, waiting for other work items to amortize the cost of creating the thread over multiple work items. It will create new threads if necessary, but it tries to keep the thread count at a level that results in the number of runnable threads matching the hardware thread count, to minimize switching costs.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The thread pool always creates background threads, so if the thread pool is in the middle of doing something when the last foreground thread in your process exits, the work will not complete, because all background threads will be terminated at that point. If you need to ensure that work being done on the thread pool completes, you must wait for that to happen before allowing all foreground threads to finish.</p>
</div>
<section data-pdf-bookmark="Launching thread pool work with Task" data-type="sect3"><div class="sect3" id="launching_thread_pool_work_with_task">
<h3>Launching thread pool work with Task</h3>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="launching thread pool work with" data-type="indexterm" id="idm45884788415120"/><a data-primary="thread pool" data-secondary="launching with Task" data-type="indexterm" id="idm45884788414208"/>The usual way to use the thread pool is through the <code>Task</code> class. This is part of the Task Parallel Library (discussed in more detail in <a data-type="xref" href="#tasks">“Tasks”</a>), but its basic usage is pretty straightforward, as <a data-type="xref" href="#running_on_thread_pool_with_task">Example 16-5</a> shows.</p>
<div data-type="example" id="running_on_thread_pool_with_task">
<h5><span class="label">Example 16-5. </span>Running code on the thread pool with a <code>Task</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="n">Task</code><code class="p">.</code><code class="n">Run</code><code class="p">(()</code> <code class="p">=&gt;</code> <code class="n">MyThreadEntryPoint</code><code class="p">(</code><code class="s">"https://oreilly.com/"</code><code class="p">));</code></pre></div>
<p>This queues the lambda for execution on the thread pool (which, when it runs, just calls the <code>MyThreadEntryPoint</code> method from <a data-type="xref" href="#creating_threads">Example 16-4</a>). If a thread is available, it will start to run straightaway, but if not, it will wait in a queue until a thread becomes available (either because some other work item in progress completes or because the thread pool decides to add a new thread to the pool).</p>
<p>There are other ways to use the thread pool, the most obvious of which is through the <code>ThreadPool</code> class. Its <code>QueueUserWorkItem</code> method works in a similar way to <code>Start</code>—you pass it a delegate and it will queue the method for execution. This is a lower-level API—it does not provide any direct way to handle completion of the work, nor to chain operations together, so for most cases, the <code>Task</code> class is preferable.</p>
</div></section>
<section data-pdf-bookmark="Thread creation heuristics" data-type="sect3"><div class="sect3" id="thread_creation_heuristics">
<h3>Thread creation heuristics</h3>
<p><a data-primary="thread pool" data-secondary="thread creation heuristics" data-type="indexterm" id="idm45884788399008"/>The runtime adjusts the number of threads based on the workload you present. The heuristics it uses are not documented and have changed across releases of .NET, so you should not depend on the exact behavior I’m about to describe; however, it is useful to know roughly what to expect.</p>
<p>If you give the thread pool only CPU-bound work, in which every method you ask it to execute spends its entire time performing computations and never blocks waiting for I/O to complete, you might end up with one thread for each of the hardware threads in your system (although if the individual work items take long enough, the thread pool might decide to allocate more threads). For example, on the eight-core two-way hyperthreaded computer I’m using as I write this, queuing up a load of CPU-intensive work items initially causes the CLR to create 16 thread pool threads, and as long as the work items complete about once a second, the number of threads mostly stays at that level. (It occasionally goes over that because the runtime will try adding an extra thread from time to time to see what effect this has on throughput, and then it drops back down again.) But if the rate at which the program gets through items drops, the CLR gradually increases the thread count.</p>
<p>If thread pool threads get blocked (e.g., because they’re waiting for data from disk or for a response over the network from a server), the CLR increases the number of pool threads more quickly. Again, it starts off with one per hardware thread, but when slow work items consume very little processor time, it can add threads as frequently as twice a second.</p>
<p>In either case, the CLR will eventually stop adding threads. The exact default limit varies in 32-bit processes, depending on the version of .NET, although it’s typically on the order of 1,000 threads. In 64-bit mode, it appears to default to 32,767. You can change this limit—the <code>ThreadPool</code> class has a <code>SetMaxThreads</code> method that lets you configure different limits for your process. You may run into other limitations that place a lower practical limit. For example, each thread has its own stack that has to occupy a contiguous range of virtual address space. By default, each thread gets 1 MB of the process’s address space reserved for its stack, so by the time you have 1,000 threads, you’ll be using 1 GB of address space for stacks alone. Thirty-two-bit processes have only 4 GB of address, so you might not have space for the number of threads you request. In any case, 1,000 threads is usually more than is helpful, so if it gets that high, this may be a symptom of some underlying problem that you should investigate. For this reason, if you call <code>SetMaxThreads</code>, it will normally be to specify a lower limit—you may find that with some workloads, constraining the number of threads improves throughput by reducing the level of contention for system resources.</p>
<p><code>ThreadPool</code> also has a <code>SetMinThreads</code> method. This lets you ensure that the number of threads does not drop below a certain number. This can be useful in applications that work most efficiently with some minimum number of threads and that want to be able to operate at maximum speed instantly, without waiting for the thread pool’s heuristics to adjust the thread count.<a data-startref="ix_ch16-asciidoc11" data-type="indexterm" id="idm45884788367248"/><a data-startref="ix_ch16-asciidoc10" data-type="indexterm" id="idm45884788366640"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Thread Affinity and SynchronizationContext" data-type="sect2"><div class="sect2" id="thread_affinity_and_synchronizationconte">
<h2>Thread Affinity and SynchronizationContext</h2>
<p><a data-primary="thread affinity" data-type="indexterm" id="ix_ch16-asciidoc12"/><a data-primary="threads" data-secondary="thread affinity and SynchronizationContext" data-type="indexterm" id="ix_ch16-asciidoc13"/>Some objects demand that you use them only from certain threads. This is particularly common with UI code—the WPF and Windows Forms UI frameworks require that UI objects be used from the thread on which they were created. This is called <em>thread affinity</em>, and although it is most often a UI concern, it can also crop up in interoperability scenarios—some COM objects have thread affinity.</p>
<p>Thread affinity can make life awkward if you want to write multithreaded code. Suppose you’ve carefully implemented a multithreaded algorithm that can exploit all of the hardware threads in an end user’s computer, significantly improving performance when running on a multicore CPU compared to a single-threaded algorithm. Once the <span class="keep-together">algorithm</span> completes, you may want to present the results to the end user. The thread affinity of UI objects requires you to perform that final step on a particular thread, but your multithreaded code may well produce its final results on some other thread. (In fact, you will probably have avoided the UI thread entirely for the CPU-intensive work, to make sure that the UI remained responsive while the work was in progress.) If you try to update the UI from some random worker thread, the UI framework will throw an exception complaining that you’ve violated its thread affinity requirements. Somehow, you’ll need to pass a message back to the UI thread so that it can display the results.</p>
<p><a data-primary="SynchronizationContext class" data-secondary="about" data-type="indexterm" id="ix_ch16-asciidoc14"/>The runtime libraries provide the <code>SynchronizationContext</code> class to help in these scenarios. Its <code>Current</code> static property returns an instance of the <code>Synchronization​Con⁠text</code> class that represents the context in which your code is currently running. For example, in a WPF application, if you retrieve this property while running on a UI thread, it will return an object associated with that thread. You can store the object that <code>Current</code> returns and use it from any thread anytime you need to perform further work on the UI thread. <a data-type="xref" href="#task_then_synchronization_context">Example 16-6</a> does this so that it can perform some potentially slow work on a thread pool thread and then update the UI back on the 
<span class="keep-together">UI thread.</span></p>
<div data-type="example" id="task_then_synchronization_context">
<h5><span class="label">Example 16-6. </span>Using the thread pool and then <code>SynchronizationContext</code></h5>
<pre data-code-language="csharp" data-type="programlisting">
<code class="k">private</code><code> </code><code class="k">void</code><code> </code><code class="nf">findButton_Click</code><code class="p">(</code><code class="kt">object</code><code> </code><code class="n">sender</code><code class="p">,</code><code> </code><code class="n">RoutedEventArgs</code><code> </code><code class="n">e</code><code class="p">)</code><code>
</code><code class="p">{</code><code>
</code><code>    </code><strong><code class="n">SynchronizationContext</code><code> </code><code class="n">uiContext</code><code> </code><code class="p">=</code><code> </code><code class="n">SynchronizationContext</code><code class="p">.</code><code class="n">Current</code><code class="p">!</code><code class="p">;</code></strong><code>
</code><code>
</code><code>    </code><code class="n">Task</code><code class="p">.</code><code class="n">Run</code><code class="p">(</code><code class="p">(</code><code class="p">)</code><code> </code><code class="p">=</code><code class="p">&gt;</code><code>
</code><code>    </code><code class="p">{</code><code>
</code><code>        </code><code class="kt">string</code><code> </code><code class="n">pictures</code><code> </code><code class="p">=</code><code>
</code><code>            </code><code class="n">Environment</code><code class="p">.</code><code class="n">GetFolderPath</code><code class="p">(</code><code class="n">Environment</code><code class="p">.</code><code class="n">SpecialFolder</code><code class="p">.</code><code class="n">MyPictures</code><code class="p">)</code><code class="p">;</code><code>
</code><code>        </code><code class="kt">var</code><code> </code><code class="n">folder</code><code> </code><code class="p">=</code><code> </code><code class="k">new</code><code> </code><code class="n">DirectoryInfo</code><code class="p">(</code><code class="n">pictures</code><code class="p">)</code><code class="p">;</code><code>
</code><code>        </code><code class="n">FileInfo</code><code class="p">[</code><code class="p">]</code><code> </code><code class="n">allFiles</code><code> </code><code class="p">=</code><code>
</code><code>            </code><code class="n">folder</code><code class="p">.</code><code class="n">GetFiles</code><code class="p">(</code><code class="s">"*.jpg"</code><code class="p">,</code><code> </code><code class="n">SearchOption</code><code class="p">.</code><code class="n">AllDirectories</code><code class="p">)</code><code class="p">;</code><code>
</code><code>        </code><code class="n">FileInfo</code><code class="p">?</code><code> </code><code class="n">largest</code><code> </code><code class="p">=</code><code>
</code><code>            </code><code class="n">allFiles</code><code class="p">.</code><code class="n">OrderByDescending</code><code class="p">(</code><code class="n">f</code><code> </code><code class="p">=</code><code class="p">&gt;</code><code> </code><code class="n">f</code><code class="p">.</code><code class="n">Length</code><code class="p">)</code><code class="p">.</code><code class="n">FirstOrDefault</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>
</code><code>
</code><code>        </code><code class="k">if</code><code> </code><code class="p">(</code><code class="n">largest</code><code> </code><code class="k">is</code><code> </code><code class="n">not</code><code> </code><code class="k">null</code><code class="p">)</code><code>
</code><code>        </code><code class="p">{</code><code>
</code><code>            </code><strong><code class="n">uiContext</code><code class="p">.</code><code class="n">Post</code><code class="p">(</code><code class="n">_</code><code> </code><code class="p">=</code><code class="p">&gt;</code></strong><code>
</code><code>            </code><code class="p">{</code><code>
</code><code>                </code><code class="kt">long</code><code> </code><code class="n">sizeMB</code><code> </code><code class="p">=</code><code> </code><code class="n">largest</code><code class="p">.</code><code class="n">Length</code><code> </code><code class="p">/</code><code> </code><code class="p">(</code><code class="m">1024</code><code> </code><code class="p">*</code><code> </code><code class="m">1024</code><code class="p">)</code><code class="p">;</code><code>
</code><code>                </code><code class="n">outputTextBox</code><code class="p">.</code><code class="n">Text</code><code> </code><code class="p">=</code><code>
</code><code>                    </code><code class="err">$</code><code class="s">"Largest file ({sizeMB}MB) is {largest.FullName}"</code><code class="p">;</code><code>
</code><code>            </code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="k">null</code><code class="p">)</code><code class="p">;</code><code>
</code><code>        </code><code class="p">}</code><code>
</code><code>    </code><code class="p">}</code><code class="p">)</code><code class="p">;</code><code>
</code><code class="p">}</code></pre></div>
<p>This code handles a <code>Click</code> event for a button. (It happens to be a WPF application, but <code>SynchronizationContext</code> works in exactly the same way in other desktop UI frameworks, such as Windows Forms.) UI elements raise their events on the UI thread, so when the first line of the click handler retrieves the current 
<span class="keep-together"><code>SynchronizationContext</code>,</span> it will get the context for the UI thread. The code then runs some work on a thread pool thread via the <code>Task</code> class. The code looks at every picture in the user’s <em>Pictures</em> folder, searching for the largest file, so this could take a while. It’s a bad idea to perform slow work on a UI thread—UI elements that belong to that thread cannot respond to user input while the UI thread is busy doing something else. So pushing this into the thread pool is a good idea.</p>
<p>The problem with using the thread pool here is that once the work completes, we’re on the wrong thread to update the UI. This code updates the <code>Text</code> property of a text box, and we’d get an exception if we tried that from a thread pool thread. So, when the work completes, it uses the <code>SynchronizationContext</code> object it retrieved earlier and calls its <code>Post</code> method. That method accepts a delegate, and it will arrange to invoke that back on the UI thread. (Under the covers, it posts a custom message to the Windows message queue, and when the UI thread’s main message processing loop picks up that message, it will invoke the delegate.)</p>
<div data-type="tip"><h6>Tip</h6>
<p>The <code>Post</code> method does not wait for the work to complete. There is a method that will wait, called <code>Send</code>, but I would recommend not using it. Making a worker thread block while it waits for the UI thread to do something can be risky, because if the UI thread is currently blocked waiting for the worker thread to do something, the application will deadlock. <code>Post</code> avoids this problem by enabling the worker thread to proceed concurrently with the UI thread.</p>
</div>
<p><a data-type="xref" href="#task_then_synchronization_context">Example 16-6</a> retrieves <code>SynchronizationContext.Current</code> while it’s still on the UI thread, before it starts the thread pool work. This is important because this static property is context sensitive—it returns the context for the UI thread only while you’re on the UI thread. (In fact, it’s possible for each window to have its own UI thread in WPF, so it wouldn’t be possible to have an API that returns <em>the</em> UI thread—there might be several.) If you read this property from a thread pool thread, the context object it returns will not post work to the UI thread.</p>
<p>The <code>SynchronizationContext</code> mechanism is extensible, so you can derive your own type from it if you want, and you can call its static <code>SetSynchronizationContext</code> method to make your context the current context for the thread. This can be useful in unit testing scenarios—it enables you to write tests to verify that objects interact with the <code>SynchronizationContext</code> correctly without needing to create a real UI.<a data-startref="ix_ch16-asciidoc14" data-type="indexterm" id="idm45884788130416"/></p>
</div></section>
<section data-pdf-bookmark="ExecutionContext" data-type="sect2"><div class="sect2" id="executioncontext">
<h2>ExecutionContext</h2>
<p><a data-primary="execution context" data-type="indexterm" id="ix_ch16-asciidoc15"/><a data-primary="ExecutionContext class" data-type="indexterm" id="ix_ch16-asciidoc16"/><a data-primary="SynchronizationContext class" data-secondary="ExecutionContext class and" data-type="indexterm" id="ix_ch16-asciidoc17"/>The <code>SynchronizationContext</code> class has a cousin, <code>ExecutionContext</code>. This provides a similar service, allowing you to capture the current context and then use it to run a delegate sometime later in the same context, but it differs in two ways. First, it captures different things. Second, it uses a different approach for reestablishing the context. A <code>SynchronizationContext</code> will often run your work on some particular thread, whereas <code>ExecutionContext</code> will always use your thread, and it just makes sure that all of the contextual information it has captured is available on that thread. One way to think of the difference is that <code>SynchronizationContext</code> does the work in an existing context, whereas <code>ExecutionContext</code> brings the contextual information 
<span class="keep-together">to you.</span></p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Slightly confusingly, the implementation of <code>ExecutionContext</code> on .NET Framework captures the current <code>SynchonizationContext</code>, so there’s a sense in which the <code>ExecutionContext</code> is a superset of the <code>SynchronizationContext</code>. However, <code>ExecutionContext</code> doesn’t use the captured <code>SynchronizationContext</code> when it invokes your delegate. All it does is ensure that if code executed via an 
<span class="keep-together"><code>ExecutionContext</code></span> reads the <code>SynchonizationContext.Current</code> property, it will get the <code>SynchronizationContext</code> property that was current at the point when the <code>ExecutionContext</code> was captured. This will not necessarily be the <code>SynchonizationContext</code> that the thread is currently running in! This design flaw was fixed in .NET Core.</p>
</div>
<p>You retrieve the current context by calling the <code>ExecutionContext.Capture</code> method. The execution context does not capture thread-local storage, but it does include any information in the current <em>logical call context</em>. You can access this through the <code>CallContext</code> class, which provides <code>LogicalSetData</code> and <code>LogicalGetData</code> methods to store and retrieve name/value pairs, or through the higher-level wrapper <code>Async​Lo⁠cal&lt;T&gt;</code>. This information is usually associated with the current thread, but if you run code in a captured execution context, it will make information from the logical context available, even if that code runs on some other thread entirely.</p>
<p>.NET uses the <code>ExecutionContext</code> class internally whenever long-running work that starts on one thread later ends up continuing on a different thread (as happens with some of the asynchronous patterns described later in this chapter). You may want to use the execution context in a similar way if you write any code that accepts a callback that it will invoke later, perhaps from some other thread. To do this, you call <code>Capture</code> to grab the current context, which you can later pass to the <code>Run</code> method to invoke a delegate. <a data-type="xref" href="#using_executioncontext">Example 16-7</a> shows <code>ExecutionContext</code> at work.</p>
<div data-type="example" id="using_executioncontext">
<h5><span class="label">Example 16-7. </span>Using <code>ExecutionContext</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">Defer</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="n">Action</code> <code class="n">_callback</code><code class="p">;</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="n">ExecutionContext</code><code class="p">?</code> <code class="n">_context</code><code class="p">;</code>

    <code class="k">public</code> <code class="nf">Defer</code><code class="p">(</code><code class="n">Action</code> <code class="n">callback</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">_callback</code> <code class="p">=</code> <code class="n">callback</code><code class="p">;</code>
        <code class="n">_context</code> <code class="p">=</code> <code class="n">ExecutionContext</code><code class="p">.</code><code class="n">Capture</code><code class="p">()!;</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Run</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">_context</code> <code class="k">is</code> <code class="k">null</code><code class="p">)</code> <code class="p">{</code> <code class="n">_callback</code><code class="p">();</code> <code class="k">return</code><code class="p">;</code> <code class="p">}</code>
        <code class="c1">// When ExecutionContext.Run invokes the lambda we supply as the 2nd</code>
        <code class="c1">// argument, it passes that lambda the value we supplied as the 3rd</code>
        <code class="c1">// argument to Run. Here we're passing _callback, so the lambda has</code>
        <code class="c1">// access to the Action we want to invoke. It would have been simpler</code>
        <code class="c1">// to write "_ =&gt; _callback()", but the lambda would then need to</code>
        <code class="c1">// capture 'this' to be able to access _callback, and that capture</code>
        <code class="c1">// would cause an additional allocation.</code>
        <code class="n">ExecutionContext</code><code class="p">.</code><code class="n">Run</code><code class="p">(</code><code class="n">_context</code><code class="p">,</code> <code class="p">(</code><code class="n">cb</code><code class="p">)</code> <code class="p">=&gt;</code> <code class="p">((</code><code class="n">Action</code><code class="p">)</code><code class="n">cb</code><code class="p">!)(),</code> <code class="n">_callback</code><code class="p">);</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>In .NET Framework, a single captured <code>ExecutionContext</code> cannot be used on multiple threads simultaneously. Sometimes you might need to invoke multiple different methods in a particular context, and in a multithreaded environment, you might not be able to guarantee that the previous method has returned before calling the next. For this scenario, <code>ExecutionContext</code> provides a <code>CreateCopy</code> method that generates a copy of the context, enabling you to make multiple simultaneous calls through equivalent contexts. In .NET Core and .NET, <code>ExecutionContext</code> is immutable, meaning this restriction no longer applies, and <code>CreateCopy</code> just returns its <code>this</code><a data-startref="ix_ch16-asciidoc17" data-type="indexterm" id="idm45884788010928"/><a data-startref="ix_ch16-asciidoc16" data-type="indexterm" id="idm45884788010224"/><a data-startref="ix_ch16-asciidoc15" data-type="indexterm" id="idm45884788009552"/> reference<a data-startref="ix_ch16-asciidoc13" data-type="indexterm" id="idm45884788008752"/><a data-startref="ix_ch16-asciidoc12" data-type="indexterm" id="idm45884788008048"/>.<a data-startref="ix_ch16-asciidoc2" data-type="indexterm" id="idm45884788007248"/><a data-startref="ix_ch16-asciidoc1" data-type="indexterm" id="idm45884787975168"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Synchronization" data-type="sect1"><div class="sect1" id="synchronization">
<h1>Synchronization</h1>
<p><a data-primary="multithreading" data-secondary="synchronization" data-seealso="synchronization, multithreading and" data-type="indexterm" id="ix_ch16-asciidoc18"/><a data-primary="synchronization, multithreading and" data-type="indexterm" id="ix_ch16-asciidoc19"/>Sometimes you will want to write multithreaded code in which multiple threads have access to the same state. For example, in <a data-type="xref" href="ch05.xhtml#ch_collections">Chapter 5</a>, I suggested that a server could use a <code>Dictionary&lt;TKey, TValue&gt;</code> as part of a cache to avoid duplicating work when it receives multiple similar requests. While this sort of caching can offer significant performance benefits in some scenarios, it presents a challenge in a multithreaded environment. (And if you’re working on server code with demanding performance requirements, you will most likely need more than one thread to handle requests.) The Thread Safety section of the documentation for the <code>Dictionary&lt;TKey, TValue&gt;</code> class says this:</p>
<blockquote>
<p>A <code>Dictionary&lt;TKey, TValue&gt;</code> can support multiple readers concurrently, as long as the collection is not modified. Even so, enumerating through a collection is intrinsically not a thread-safe procedure. In the rare case where an enumeration contends with write accesses, the collection must be locked during the entire enumeration. To allow the collection to be accessed by multiple threads for reading and writing, you must implement your own synchronization.</p></blockquote>
<p>This is better than we might hope for—the vast majority of types in the runtime libraries simply don’t support multithreaded use of instances at all. Most types support multithreaded use at the class level, but individual instances must be used one thread at a time. <code>Dictionary&lt;TKey, TValue&gt;</code> is more generous: it explicitly supports multiple concurrent readers, which sounds good for our caching scenario. However, when modifying a collection, not only must we ensure that we do not try to change it from multiple threads simultaneously, but also we must not have any read operations in progress while we do so.</p>
<p>The other generic collection classes make similar guarantees (unlike most other classes in the library). For example, <code>List&lt;T&gt;</code>, <code>Queue&lt;T&gt;</code>, <code>Stack&lt;T&gt;</code>, <code>SortedDiction⁠ary​&lt;TKey, TValue&gt;</code>, <code>HashSet&lt;T&gt;</code>, and <code>SortedSet&lt;T&gt;</code> all support concurrent read-only use. (Again, if you <span class="keep-together">modify</span> any instance of these collections, you must make sure that no other threads are either modifying or reading from the same instance at the same time.) Of course, you should always check the documentation before attempting multithreaded use of any type.<sup><a data-type="noteref" href="ch16.xhtml#CHP-17-FN-3" id="CHP-17-FN-3-marker">2</a></sup> Be aware that the generic collection interface types make no thread safety guarantees—although <code>List&lt;T&gt;</code> supports concurrent readers, not all implementations of <code>IList&lt;T&gt;</code> will. (For example, imagine an implementation that wraps something potentially slow, such as the contents of a file. It might make sense for this wrapper to cache data to make read operations faster. Reading an item from such a list could change its internal state, so reads could fail when performed simultaneously from multiple threads if the code did not take steps to protect itself.)</p>
<p>If you can arrange never to have to modify a data structure while it is in use from multithreaded code, the support for concurrent access offered by many of the collection classes may be all you need. But if some threads will need to modify shared state, you will need to coordinate access to that state. To enable this, .NET provides various synchronization mechanisms that you can use to ensure that your threads take it in turns to access shared objects when necessary. In this section, I’ll describe the most commonly used ones.</p>
<section data-pdf-bookmark="Monitors and the lock Keyword" data-type="sect2"><div class="sect2" id="monitors_and_the_lock_keyword">
<h2>Monitors and the lock Keyword</h2>
<p><a data-primary="lock keyword" data-type="indexterm" id="ix_ch16-asciidoc20"/><a data-primary="Monitor class" data-secondary="synchronizing multithreaded use of shared state" data-type="indexterm" id="ix_ch16-asciidoc21"/><a data-primary="synchronization, multithreading and" data-secondary="monitors and the lock keyword" data-type="indexterm" id="ix_ch16-asciidoc22"/>The first option to consider for synchronizing multithreaded use of shared state is the <code>Monitor</code> class. This is popular because it is efficient, it offers a straightforward model, and C# provides direct language support, making it very easy to use. <a data-type="xref" href="#protecting_state_with_lock">Example 16-8</a> shows a class that uses the <code>lock</code> keyword (which in turn uses the <code>Monitor</code> class) anytime it either reads or modifies its internal state. This ensures that only one thread will be accessing that state at any one time.</p>
<div data-type="example" id="protecting_state_with_lock">
<h5><span class="label">Example 16-8. </span>Protecting state with <code>lock</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">SaleLog</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="kt">object</code> <code class="n">_sync</code> <code class="p">=</code> <code class="k">new</code><code class="p">();</code>

    <code class="k">private</code> <code class="kt">decimal</code> <code class="n">_total</code><code class="p">;</code>

    <code class="k">private</code> <code class="k">readonly</code> <code class="n">List</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">&gt;</code> <code class="n">_saleDetails</code> <code class="p">=</code> <code class="k">new</code><code class="p">();</code>

    <code class="k">public</code> <code class="kt">decimal</code> <code class="n">Total</code>
    <code class="p">{</code>
        <code class="k">get</code>
        <code class="p">{</code>
            <code class="k">lock</code> <code class="p">(</code><code class="n">_sync</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="k">return</code> <code class="n">_total</code><code class="p">;</code>
            <code class="p">}</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">AddSale</code><code class="p">(</code><code class="kt">string</code> <code class="n">item</code><code class="p">,</code> <code class="kt">decimal</code> <code class="n">price</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="kt">string</code> <code class="n">details</code> <code class="p">=</code> <code class="err">$</code><code class="s">"{item} sold at {price}"</code><code class="p">;</code>
        <code class="k">lock</code> <code class="p">(</code><code class="n">_sync</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="n">_total</code> <code class="p">+=</code> <code class="n">price</code><code class="p">;</code>
            <code class="n">_saleDetails</code><code class="p">.</code><code class="n">Add</code><code class="p">(</code><code class="n">details</code><code class="p">);</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="kt">string</code><code class="p">[]</code> <code class="nf">GetDetails</code><code class="p">(</code><code class="k">out</code> <code class="kt">decimal</code> <code class="n">total</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="k">lock</code> <code class="p">(</code><code class="n">_sync</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="n">total</code> <code class="p">=</code> <code class="n">_total</code><code class="p">;</code>
            <code class="k">return</code> <code class="n">_saleDetails</code><code class="p">.</code><code class="n">ToArray</code><code class="p">();</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>To use the <code>lock</code> keyword, you provide a reference to an object and a block of code. The C# compiler generates code that will cause the CLR to ensure that no more than one thread is inside a <code>lock</code> block for that object at any one time. Suppose you created a single instance of this <code>SaleLog</code> class, and on one thread you called the <code>AddSale</code> method, while on another thread you called <code>GetDetails</code> at the same time. Both threads will reach <code>lock</code> statements, passing in the same <code>_sync</code> field. Whichever thread happens to get there first will be allowed to run the block following the <code>lock</code>. The other thread will be made to wait—it won’t be allowed to enter its <code>lock</code> block until the first thread leaves its <code>lock</code> block.</p>
<p>The <code>SaleLog</code> class only ever uses any of its fields from inside a <code>lock</code> block using the <code>_sync</code> argument. This ensures that all access to fields is serialized (in the concurrency sense—that is, threads get to access fields one at a time, rather than all piling in simultaneously). When the <code>GetDetails</code> method reads from both the <code>_total</code> and <code>_saleDetails</code> fields, it can be confident that it’s getting a coherent view—the total will be consistent with the current contents of the list of sales details, because the code that modifies these two pieces of data does so within a single <code>lock</code> block. This means that updates will appear to be atomic from the point of view of any other <code>lock</code> block using <code>_sync</code>.</p>
<p>It may look excessive to use a <code>lock</code> block even for the <code>get</code> accessor that returns the total. However, <code>decimal</code> is a 128-bit value, so access to data of this type is not intrinsically atomic—without that <code>lock</code>, it would be possible for the returned value to be made up of a mixture of two or more values that <code>_total</code> had at different times. (For example, the bottom 64 bits might be from an older value than the top 64 bits.) This is often described as a <em>torn read</em>. The CLR guarantees atomic reads and writes only for data types whose size is no larger than 4 bytes, and also for references, even on a platform where they are larger than 4 bytes. (It guarantees this only for naturally aligned fields, but in C#, fields will always be aligned unless you have deliberately misaligned them for interop purposes.)</p>
<p>A subtle but important detail of <a data-type="xref" href="#protecting_state_with_lock">Example 16-8</a> is that whenever it returns information about its internal state, it returns a copy. The <code>Total</code> property’s type is <code>decimal</code>, which is a value type, and values are always returned as copies. But when it comes to the list of entries, the <code>GetDetails</code> method calls <code>ToArray</code>, which will build a new array containing a copy of the list’s current contents. It would be a mistake to return the reference in <code>_saleDetails</code> directly, because that would enable code outside of the <code>SalesLog</code> class to access and modify the collection without using <code>lock</code>. We need to ensure that all access to that collection is synchronized, and we lose the ability to do that if our class hands out references to its internal state.</p>
<div data-type="tip"><h6>Tip</h6>
<p>If you write code that performs some multithreaded work that eventually comes to a halt, it’s OK to share references to the state after the work has stopped. But if multithreaded modifications to an object are ongoing, you need to ensure that all use of that object’s state is protected.</p>
</div>
<p><a data-primary="this reference" data-type="indexterm" id="idm45884787769968"/>The <code>lock</code> keyword accepts any object reference, so you might wonder why I’ve created an object specially—couldn’t I have passed <code>this</code> instead? That would have worked, but the problem is that your <code>this</code> reference is not private—it’s the same reference by which external code uses your object. Using a publicly visible feature of your object to synchronize access to private state is imprudent; some other code could decide that it’s convenient to use a reference to your object as the argument to some completely unrelated <code>lock</code> blocks. In this case, it probably wouldn’t cause a problem, but with more complex code, it could tie conceptually unrelated pieces of concurrent behavior together in a way that might cause performance problems or even deadlocks. Thus, it’s usually better to code defensively and use something that only your code has access to as the <code>lock</code> argument. Of course, I could have used the <code>_saleDetails</code> field because that refers to an object that only my class has access to. However, even if you code defensively, you should not assume that other developers will, so in general, it’s safer to avoid using an instance of a class you didn’t write as the argument for a <code>lock</code>, because you can never be certain that it isn’t using its <code>this</code> reference for its own locking purposes.</p>
<p>The fact that you can use any object reference is a bit of an oddity in any case. Most of .NET’s synchronization mechanisms use an instance of some distinct type as the point of reference for synchronization. (For example, if you want reader/writer locking semantics, you use an instance of the <code>ReaderWriterLockSlim</code> class, not just any old object.) The <code>Monitor</code> class (which is what <code>lock</code> uses) is an exception that dates back to an old requirement for a degree of compatibility with Java (which has a similar locking primitive). This is not relevant to modern .NET development, so this feature is now just a historical peculiarity. Using a distinct object whose only job is to act as a <code>lock</code> argument adds minimal overhead (compared to the costs of locking in the first place) and tends to make it easier to see how synchronization is being managed.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You cannot use a value type as an argument for <code>lock</code>—C# prevents this, and with good reason. <a data-primary="conversions" data-secondary="implicit" data-type="indexterm" id="idm45884787760288"/><a data-primary="implicit conversions" data-type="indexterm" id="idm45884787759312"/>The compiler performs an implicit conversion to <code>object</code> on the <code>lock</code> argument, which for reference types doesn’t require the CLR to do anything at runtime. But when you convert a value type to a reference of type <code>object</code>, a box needs to be created. That box would be the argument to <code>lock</code>, and that would be a problem, because you get a new box every time you convert a value to an <code>object</code> reference. So, each time you ran a <code>lock</code>, it would get a different object, meaning there would be no synchronization in practice. This is why the compiler prevents you from trying.</p>
</div>
<section data-pdf-bookmark="How the lock keyword expands" data-type="sect3"><div class="sect3" id="how_the_lock_keyword_expands">
<h3>How the lock keyword expands</h3>
<p><a data-primary="lock keyword" data-secondary="expansion of" data-type="indexterm" id="idm45884787753136"/><a data-primary="synchronization, multithreading and" data-secondary="lock keyword expansion" data-type="indexterm" id="idm45884787752160"/>Each <code>lock</code> block turns into code that does three things: first, it calls <code>Monitor.Enter</code>, passing the argument you provided to <code>lock</code>. Then it attempts to run the code in the block. Finally, it will usually call <code>Monitor.Exit</code> once the block finishes. But it’s not entirely straightforward, thanks to exceptions. The code will still call <code>Monitor.Exit</code> if the code you put in the block throws an exception, but it needs to handle the possibility that <code>Monitor.Enter</code> itself threw, which would mean that the thread does not own the lock and should therefore not call <code>Monitor.Exit</code>. <a data-type="xref" href="#how_lock_blocks_expand">Example 16-9</a> shows what the compiler makes of the <code>lock</code> block in the <code>GetDetails</code> method in <a data-type="xref" href="#protecting_state_with_lock">Example 16-8</a>.</p>
<div data-type="example" id="how_lock_blocks_expand">
<h5><span class="label">Example 16-9. </span>How <code>lock</code> blocks expand</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="kt">bool</code> <code class="n">lockWasTaken</code> <code class="p">=</code> <code class="k">false</code><code class="p">;</code>
<code class="kt">object</code> <code class="n">temp</code> <code class="p">=</code> <code class="n">_sync</code><code class="p">;</code>
<code class="k">try</code>
<code class="p">{</code>
    <code class="n">Monitor</code><code class="p">.</code><code class="n">Enter</code><code class="p">(</code><code class="n">temp</code><code class="p">,</code> <code class="k">ref</code> <code class="n">lockWasTaken</code><code class="p">);</code>
    <code class="p">{</code>
        <code class="n">total</code> <code class="p">=</code> <code class="n">_total</code><code class="p">;</code>
        <code class="k">return</code> <code class="n">_saleDetails</code><code class="p">.</code><code class="n">ToArray</code><code class="p">();</code>
    <code class="p">}</code>
<code class="p">}</code>
<code class="k">finally</code>
<code class="p">{</code>
    <code class="k">if</code> <code class="p">(</code><code class="n">lockWasTaken</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">Monitor</code><code class="p">.</code><code class="n">Exit</code><code class="p">(</code><code class="n">temp</code><code class="p">);</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p><code>Monitor.Enter</code> is the API that does the work of discovering whether some other thread already has the lock, and if so, making the current thread wait. If this returns at all, it normally succeeds. (It might deadlock, in which case it will never return.) There is a small possibility of failure caused by an exception, e.g., due to running out of memory. That would be fairly unusual, but the generated code takes it into account nonetheless—this is the purpose of the slightly roundabout-looking code for the <code>lockWasTaken</code> variable. (In practice, the compiler will make that a hidden variable without an accessible name, by the way. I’ve named it to show what’s happening here.) The <code>Monitor.Enter</code> method guarantees that acquisition of the lock will be atomic with updating the flag indicating whether the lock was taken, ensuring that the <code>finally</code> block will attempt to call <code>Exit</code> if and only if the lock was acquired.</p>
<p><code>Monitor.Exit</code> tells the CLR that we no longer need exclusive access to whatever resources we’re synchronizing access to, and if any other threads are waiting inside <code>Monitor.Enter</code> for the object in question, this will enable one of them to proceed. The compiler puts this inside a <code>finally</code> block to ensure that whether you exit from the block by running to the end, returning from the middle, or throwing an exception, the lock will be released.</p>
<p>The fact that the <code>lock</code> block calls <code>Monitor.Exit</code> on an exception is a double-edged sword. On the one hand, it reduces the chances of deadlock by ensuring that locks are released on failure. On the other hand, if an exception occurs while you’re in the middle of modifying some shared state, the system may be in an inconsistent state; releasing locks will allow other threads access to that state, possibly causing further problems. In some situations, it might have been better to leave locks locked in the case of an exception—a deadlocked process might do less damage than one that plows on with corrupt state. A more robust strategy is to write code that guarantees consistency in the face of exceptions, either by rolling back any changes it has made if an exception prevents a complete set of updates or by arranging to change state in an atomic way (e.g., by putting the new state into a whole new object and substituting that for the previous one only once the updated object is fully initialized). But that’s beyond what the compiler can automate for you.</p>
</div></section>
<section data-pdf-bookmark="Waiting and notification" data-type="sect3"><div class="sect3" id="waiting_and_notification">
<h3>Waiting and notification</h3>
<p><a data-primary="Monitor class" data-secondary="waiting and notification" data-type="indexterm" id="idm45884787701120"/><a data-primary="synchronization, multithreading and" data-secondary="waiting and notification" data-type="indexterm" id="idm45884787650352"/>The <code>Monitor</code> class can do more than just ensure that threads take it in turns. It provides a way for threads to sit and wait for a notification from some other thread. If a thread has acquired the monitor for a particular object, it can call <code>Monitor.Wait</code>, passing in that object. This has two effects: it releases the monitor and causes the thread to block. It will block until some other thread calls <code>Monitor.Pulse</code> or <code>PulseAll</code> for the same object; a thread must have the monitor to be able to call either of these methods. (<code>Wait</code>, <code>Pulse</code>, and <code>PulseAll</code> all throw an exception if you call them while not holding the relevant monitor.)</p>
<p>If a thread calls <code>Pulse</code>, this enables one thread waiting in <code>Wait</code> to wake up. Calling <code>PulseAll</code> enables all of the threads waiting on that object’s monitor to run. In either case, <code>Monitor.Wait</code> reacquires the monitor before returning, so even if you call <span class="keep-together"><code>PulseAll</code></span>, the threads will wake up one at a time—a second thread cannot emerge from <code>Wait</code> until the first thread to do so relinquishes the monitor. In fact, no threads can return from <code>Wait</code> until the thread that called <code>Pulse</code> or <code>PulseAll</code> relinquishes the lock.</p>
<p><a data-type="xref" href="#wait_and_pulse">Example 16-10</a> uses <code>Wait</code> and <code>Pulse</code> to provide a wrapper around a <code>Queue&lt;T&gt;</code> that causes the thread that retrieves items from the queue to wait if the queue is empty. (This is for illustration only—if you want this sort of queue, you don’t have to write your own. Use the built-in <code>BlockingCollection&lt;T&gt;</code> or the types in <code>System.Thread⁠ing​.Channels</code>.)</p>
<div data-type="example" id="wait_and_pulse">
<h5><span class="label">Example 16-10. </span><code>Wait</code> and <code>Pulse</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">MessageQueue</code><code class="p">&lt;</code><code class="n">T</code><code class="p">&gt;</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="kt">object</code> <code class="n">_sync</code> <code class="p">=</code> <code class="k">new</code><code class="p">();</code>

    <code class="k">private</code> <code class="k">readonly</code> <code class="n">Queue</code><code class="p">&lt;</code><code class="n">T</code><code class="p">&gt;</code> <code class="n">_queue</code> <code class="p">=</code> <code class="k">new</code><code class="p">();</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Post</code><code class="p">(</code><code class="n">T</code> <code class="n">message</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="k">lock</code> <code class="p">(</code><code class="n">_sync</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="kt">bool</code> <code class="n">wasEmpty</code> <code class="p">=</code> <code class="n">_queue</code><code class="p">.</code><code class="n">Count</code> <code class="p">==</code> <code class="m">0</code><code class="p">;</code>
            <code class="n">_queue</code><code class="p">.</code><code class="n">Enqueue</code><code class="p">(</code><code class="n">message</code><code class="p">);</code>
            <code class="k">if</code> <code class="p">(</code><code class="n">wasEmpty</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">Monitor</code><code class="p">.</code><code class="n">Pulse</code><code class="p">(</code><code class="n">_sync</code><code class="p">);</code>
            <code class="p">}</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="n">T</code> <code class="nf">Get</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="k">lock</code> <code class="p">(</code><code class="n">_sync</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="k">while</code> <code class="p">(</code><code class="n">_queue</code><code class="p">.</code><code class="n">Count</code> <code class="p">==</code> <code class="m">0</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">Monitor</code><code class="p">.</code><code class="n">Wait</code><code class="p">(</code><code class="n">_sync</code><code class="p">);</code>
            <code class="p">}</code>
            <code class="k">return</code> <code class="n">_queue</code><code class="p">.</code><code class="n">Dequeue</code><code class="p">();</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>This example uses the monitor in two ways. It uses it through the <code>lock</code> keyword to ensure that only one thread at a time uses the <code>Queue&lt;T&gt;</code> that holds queued items. But it also uses waiting and notification to enable the thread that consumes items to block efficiently when the queue is empty, and for any thread that adds new items to the queue to wake up the blocked reader thread.</p>
</div></section>
<section data-pdf-bookmark="Timeouts" data-type="sect3"><div class="sect3" id="timeouts">
<h3>Timeouts</h3>
<p><a data-primary="lock keyword" data-secondary="timeouts" data-type="indexterm" id="idm45884787481104"/><a data-primary="synchronization, multithreading and" data-secondary="timeouts" data-type="indexterm" id="idm45884787479904"/><a data-primary="timeouts" data-type="indexterm" id="idm45884787478992"/>Whether you are waiting for a notification or just attempting to acquire the lock, it’s possible to specify a timeout, indicating that if the operation doesn’t succeed within the specified time, you would like to give up. For lock acquisition, you use a different method, <code>TryEnter</code>, but when waiting for notification, you just use a different overload. (There’s no compiler support for this, so you won’t be able to use the <code>lock</code> keyword.) In both cases, you can pass either an <code>int</code> representing the maximum time to wait, in milliseconds, or a <code>TimeSpan</code> value. Both return a <code>bool</code> indicating whether the operation succeeded.</p>
<p>You could use this to avoid deadlocking the process, but if your code does fail to acquire a lock within the timeout, this leaves you with the problem of deciding what to do about that. If your application is unable to acquire a lock it needs, then it can’t just do whatever work it was going to do regardless. Termination of the process may be the only realistic option, because deadlock is usually a symptom of a bug, so if it occurs, your process may already be in a compromised state. That said, some developers take a less-than-rigorous approach to lock acquisition and may regard deadlock as being normal. In this case, it might be viable to abort whatever operation you were trying and either retry the work later or just log a failure, abandon this particular operation, and carry on with whatever else the process was doing. But that may be a risky strategy.<a data-startref="ix_ch16-asciidoc22" data-type="indexterm" id="idm45884787475408"/><a data-startref="ix_ch16-asciidoc21" data-type="indexterm" id="idm45884787474672"/><a data-startref="ix_ch16-asciidoc20" data-type="indexterm" id="idm45884787474000"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="SpinLock" data-type="sect2"><div class="sect2" id="spinlock">
<h2>SpinLock</h2>
<p><a data-primary="SpinLock struct" data-type="indexterm" id="ix_ch16-asciidoc23"/><a data-primary="synchronization, multithreading and" data-secondary="SpinLock struct" data-type="indexterm" id="ix_ch16-asciidoc24"/><code>SpinLock</code> presents a similar logical model to the <code>Monitor</code> class’s <code>Enter</code> and <code>Exit</code> methods. (It does not support waiting and notification.) It is a value type, so in some circumstances, it can reduce the number of objects that need to be allocated to support locking—<code>Monitor</code> requires a heap-based object. However, it is also simpler: it only uses a single strategy for handling contention, whereas <code>Monitor</code> starts with the same strategy as <code>SpinLock</code>, then after a while it will switch to one with higher initial overhead, but that is more efficient if long waits are involved.</p>
<p>When you call either <code>Enter</code> method (<code>Monitor</code> or <code>SpinLock</code>), if the lock is available, it will be acquired very quickly—the cost is typically a handful of CPU instructions. If the lock is already held by another thread, the CLR sits in a loop that polls the lock (i.e., it <em>spins</em>), waiting for it to be released. If the lock is only ever held for a very short length of time, this can be a very efficient strategy, because it avoids getting the OS involved and is extremely fast in the case where the lock is available. Even when there is contention, spinning can be the most effective strategy on a multicore or multi-CPU system, because if the lock is only ever held for a very short duration (e.g., only for as long as it takes to add two <code>decimals</code> together), the thread will not have to spin for long before the lock becomes available again.</p>
<p><a data-primary="Monitor class" data-secondary="SpinLock versus" data-type="indexterm" id="idm45884787463392"/>Where <code>Monitor</code> and <code>SpinLock</code> differ is that <code>Monitor</code> will eventually give up on spinning, falling back to using the OS scheduler. This will have a cost equivalent to executing many thousands (possibly even hundreds of thousands) of CPU instructions, which is why <code>Monitor</code> starts off using much the same approach as <code>SpinLock</code>. However, if the lock remains unavailable for long, spinning is inefficient—even spinning for just a few milliseconds will involve spinning millions of times on modern CPUs, at which point running thousands of instructions to be able to suspend the thread efficiently looks like a better bet. (Spinning is also problematic on single-core systems, because spinning relies on the thread holding the lock to be making 
<span class="keep-together">progress</span>.<sup><a data-type="noteref" href="ch16.xhtml#CHP-17-FN-4" id="CHP-17-FN-4-marker">3</a></sup>)</p>
<p><code>SpinLock</code> doesn’t have a fallback strategy. Unlike <code>Monitor</code>, it will spin until either it successfully acquires the lock or the timeout (if you specified one) elapses. For this reason, the documentation recommends that you should not use a <code>SpinLock</code> if you do certain things while holding the lock, including doing anything else that might block (e.g., waiting for I/O to complete) or calling other code that might do the same. It also recommends against calling a method through a mechanism where you can’t be certain which code will run (e.g., through an interface, a virtual method, or a delegate), or even allocating memory. If you’re doing anything remotely nontrivial, it is better to stick with <code>Monitor</code>. However, access to a <code>decimal</code> is sufficiently simple that it might be suitable for protecting with a <code>SpinLock</code>, as <a data-type="xref" href="#protecting_access_to_a_decimal_with_spin">Example 16-11</a> does.</p>
<div data-type="example" id="protecting_access_to_a_decimal_with_spin">
<h5><span class="label">Example 16-11. </span>Protecting access to a <code>decimal</code> with <code>SpinLock</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">DecimalTotal</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="kt">decimal</code> <code class="n">_total</code><code class="p">;</code>

    <code class="k">private</code> <code class="n">SpinLock</code> <code class="n">_lock</code><code class="p">;</code>

    <code class="k">public</code> <code class="kt">decimal</code> <code class="n">Total</code>
    <code class="p">{</code>
        <code class="k">get</code>
        <code class="p">{</code>
            <code class="kt">bool</code> <code class="n">acquiredLock</code> <code class="p">=</code> <code class="k">false</code><code class="p">;</code>
            <code class="k">try</code>
            <code class="p">{</code>
                <code class="n">_lock</code><code class="p">.</code><code class="n">Enter</code><code class="p">(</code><code class="k">ref</code> <code class="n">acquiredLock</code><code class="p">);</code>
                <code class="k">return</code> <code class="n">_total</code><code class="p">;</code>
            <code class="p">}</code>
            <code class="k">finally</code>
            <code class="p">{</code>
                <code class="k">if</code> <code class="p">(</code><code class="n">acquiredLock</code><code class="p">)</code>
                <code class="p">{</code>
                    <code class="n">_lock</code><code class="p">.</code><code class="n">Exit</code><code class="p">();</code>
                <code class="p">}</code>
            <code class="p">}</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Add</code><code class="p">(</code><code class="kt">decimal</code> <code class="k">value</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="kt">bool</code> <code class="n">acquiredLock</code> <code class="p">=</code> <code class="k">false</code><code class="p">;</code>
        <code class="k">try</code>
        <code class="p">{</code>
            <code class="n">_lock</code><code class="p">.</code><code class="n">Enter</code><code class="p">(</code><code class="k">ref</code> <code class="n">acquiredLock</code><code class="p">);</code>
            <code class="n">_total</code> <code class="p">+=</code> <code class="k">value</code><code class="p">;</code>
        <code class="p">}</code>
        <code class="k">finally</code>
        <code class="p">{</code>
            <code class="k">if</code> <code class="p">(</code><code class="n">acquiredLock</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">_lock</code><code class="p">.</code><code class="n">Exit</code><code class="p">();</code>
            <code class="p">}</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>We have to write considerably more code than with <code>lock</code> due to the lack of compiler support. It might not be worth the effort—since <code>Monitor</code> spins to start with, it is likely to have similar performance, so the only benefit here is that we’ve avoided allocating an extra heap object to perform locking with. (<code>SpinLock</code> is a <code>struct</code>, so it lives inside the <code>DecimalTotal</code> object’s heap block.) You should use a <code>SpinLock</code> only if you can demonstrate through profiling that under realistic workloads it performs better than a monitor.<a data-startref="ix_ch16-asciidoc24" data-type="indexterm" id="idm45884787300304"/><a data-startref="ix_ch16-asciidoc23" data-type="indexterm" id="idm45884787299696"/></p>
</div></section>
<section data-pdf-bookmark="Reader/Writer Locks" data-type="sect2"><div class="sect2" id="reader_writer_locks">
<h2>Reader/Writer Locks</h2>
<p><a data-primary="ReaderWriterLockSlim class" data-type="indexterm" id="idm45884787297600"/><a data-primary="synchronization, multithreading and" data-secondary="reader/writer locks" data-type="indexterm" id="idm45884787296768"/>The <code>ReaderWriterLockSlim</code> class provides a different locking model than the one that <code>Monitor</code> and <code>SpinLock</code> present. With <code>ReaderWriterLockSlim</code>, when acquiring a lock, you specify whether you are a reader or a writer. The lock allows multiple threads to become readers simultaneously. However, when a thread asks to acquire the lock as a writer, the lock will temporarily block any further threads that try to read, and it waits for all threads that were already reading to release their locks before granting access to the thread that wants to write. Once the writer releases its lock, any threads that were waiting to read are allowed back in. This enables the writer thread to get exclusive access but means that when no writing is occurring, readers can all proceed in parallel.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p><a data-primary="ReaderWriterLock class" data-type="indexterm" id="idm45884787293344"/>There is also a <code>ReaderWriterLock</code> class. You should not use this, because it has performance issues even when there is no contention for the lock, and it also makes suboptimal choices when both reader and writer threads are waiting to acquire the lock. The newer <code>ReaderWriterLockSlim</code> class has been around for a very long time (since .NET 3.5) and is recommended over the older class in all scenarios. The old class remains purely for backward compatibility.</p>
</div>
<p>This may sound like a good fit with many of the collection classes built into .NET. As I described earlier, they often support multiple concurrent reader threads but require that modification be done exclusively by one thread at a time and that no readers be active while modifications are made. However, you should not necessarily make this lock your first choice when you happen to have a mixture of readers and writers.</p>
<p>Despite the performance improvements that the “slim” lock made over its predecessor, it still takes longer to acquire this lock than it does to enter a monitor. If you plan to hold the lock only for a very short duration, it may be better just to use a monitor—the theoretical improvement offered by greater concurrency may be outweighed by the extra work required to acquire the lock in the first place. Even if you are holding the lock for a significant length of time, reader/writer locks offer benefits only if updates just happen occasionally. If you have a more or less constant stream of threads all wanting to modify the data, you are unlikely to see any performance improvement.</p>
<p>As with all performance-motivated choices, if you are considering using a <code>Reader​Wri⁠terLockSlim</code> instead of the simpler alternative of an ordinary monitor, you should measure performance under a realistic workload with both alternatives to see what impact, if any, the change has.</p>
</div></section>
<section data-pdf-bookmark="Event Objects" data-type="sect2"><div class="sect2" id="event_objects">
<h2>Event Objects</h2>
<p><a data-primary="event objects" data-type="indexterm" id="ix_ch16-asciidoc25"/><a data-primary="synchronization, multithreading and" data-secondary="event objects" data-type="indexterm" id="ix_ch16-asciidoc26"/>The native API for Windows, Win32, has always offered a synchronization primitive called an <em>event</em>. From a .NET perspective, this name is a bit unfortunate, because it defines the term to mean something else entirely, as <a data-type="xref" href="ch09.xhtml#ch_delegates_lambdas_events">Chapter 9</a> discussed. In this section, when I refer to an event, I mean the synchronization primitive, unless I explicitly qualify it as a .NET event.</p>
<p><a data-primary="ManualResetEvent class" data-type="indexterm" id="idm45884787283152"/>The <code>ManualResetEvent</code> class provides a mechanism where one thread can wait for a notification from another thread. This works differently than the <code>Monitor</code> class’s <code>Wait</code> and <code>Pulse</code>. For one thing, you do not need to be in possession of a monitor or other lock to be able to wait for or signal an event. Second, the <code>Monitor</code> class’s pulse methods <span class="keep-together">only do anything</span> if at least one other thread is blocked in <code>Monitor.Wait</code> for that <span class="keep-together">object—</span>if nothing was waiting, then it’s as though the pulse never occurred. But a <span class="keep-together"><code>ManualResetEvent</code></span> remembers its state—once signaled, it won’t return to its unsignaled state unless you manually reset it by calling <code>Reset</code> (hence the name). This makes it useful for scenarios where some thread A cannot proceed until some other thread B has done some work that will take an unpredictable amount of time to complete. Thread A might have to wait, but it’s possible that thread B will have finished the work by the time A checks. <a data-type="xref" href="#waiting_for_work_to_complete_with_manual">Example 16-12</a> uses this technique to perform some overlapping work.</p>
<div data-type="example" id="waiting_for_work_to_complete_with_manual">
<h5><span class="label">Example 16-12. </span>Waiting for work to complete with <code>ManualResetEvent</code></h5>
<pre data-code-language="csharp" data-type="programlisting">
<code class="k">static</code><code> </code><code class="k">void</code><code> </code><code class="nf">LogFailure</code><code class="p">(</code><code class="kt">string</code><code> </code><code class="n">message</code><code class="p">,</code><code> </code><code class="kt">string</code><code> </code><code class="n">mailServer</code><code class="p">)</code><code>
</code><code class="p">{</code><code>
</code><code>    </code><code class="kt">var</code><code> </code><code class="n">email</code><code> </code><code class="p">=</code><code> </code><code class="k">new</code><code> </code><code class="n">SmtpClient</code><code class="p">(</code><code class="n">mailServer</code><code class="p">)</code><code class="p">;</code><code>
</code><code>
</code><code>    </code><strong><code class="k">using</code><code> </code><code class="p">(</code><code class="kt">var</code><code> </code><code class="n">emailSent</code><code> </code><code class="p">=</code><code> </code><code class="k">new</code><code> </code><code class="n">ManualResetEvent</code><code class="p">(</code><code class="k">false</code><code class="p">)</code><code class="p">)</code></strong><code>
</code><code>    </code><code class="p">{</code><code>
</code><code>        </code><code class="kt">object</code><code> </code><code class="n">sync</code><code> </code><code class="p">=</code><code> </code><code class="k">new</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>
</code><code>        </code><code class="kt">bool</code><code> </code><code class="n">tooLate</code><code> </code><code class="p">=</code><code> </code><code class="k">false</code><code class="p">;</code><code> </code><code class="c1">// Prevent call to Set after a timeout
</code><code>        </code><strong><code class="n">email</code><code class="p">.</code><code class="n">SendCompleted</code><code> </code><code class="p">+</code><code class="p">=</code><code> </code><code class="p">(</code><code class="n">_</code><code class="p">,</code><code> </code><code class="n">_</code><code class="p">)</code><code> </code><code class="p">=</code><code class="p">&gt;</code><code> </code><code class="c1">// (Event arguments unused here)
</code><code>        </code><code class="p">{</code><code>
</code><code>            </code><code class="k">lock</code><code class="p">(</code><code class="n">sync</code><code class="p">)</code><code>
</code><code>            </code><code class="p">{</code><code>
</code><code>                </code><code class="k">if</code><code> </code><code class="p">(</code><code class="p">!</code><code class="n">tooLate</code><code class="p">)</code><code> </code><code class="p">{</code><code> </code><code class="n">emailSent</code><code class="p">.</code><code class="n">Set</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code> </code><code class="p">}</code><code>
</code><code>            </code><code class="p">}</code><code>
</code><code>        </code><code class="p">}</code><code class="p">;</code></strong><code>
</code><code>        </code><code class="n">email</code><code class="p">.</code><code class="n">SendAsync</code><code class="p">(</code><code class="s">"logger@example.com"</code><code class="p">,</code><code> </code><code class="s">"sysadmin@example.com"</code><code class="p">,</code><code>
</code><code>            </code><code class="s">"Failure Report"</code><code class="p">,</code><code> </code><code class="s">"An error occurred: "</code><code> </code><code class="p">+</code><code> </code><code class="n">message</code><code class="p">,</code><code> </code><code class="k">null</code><code class="p">)</code><code class="p">;</code><code>
</code><code>
</code><code>        </code><code class="n">LogPersistently</code><code class="p">(</code><code class="n">message</code><code class="p">)</code><code class="p">;</code><code>
</code><code>
</code><code>        </code><strong><code class="k">if</code><code> </code><code class="p">(</code><code class="p">!</code><code class="n">emailSent</code><code class="p">.</code><code class="n">WaitOne</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromMinutes</code><code class="p">(</code><code class="m">1</code><code class="p">)</code><code class="p">)</code><code class="p">)</code></strong><code>
</code><code>        </code><code class="p">{</code><code>
</code><code>            </code><code class="n">LogPersistently</code><code class="p">(</code><code class="s">"Timeout sending email for error: "</code><code> </code><code class="p">+</code><code> </code><code class="n">message</code><code class="p">)</code><code class="p">;</code><code>
</code><code>        </code><code class="p">}</code><code>
</code><code>
</code><code>        </code><code class="k">lock</code><code> </code><code class="p">(</code><code class="n">sync</code><code class="p">)</code><code>
</code><code>        </code><code class="p">{</code><code>
</code><code>            </code><code class="n">tooLate</code><code> </code><code class="p">=</code><code> </code><code class="k">true</code><code class="p">;</code><code>
</code><code>        </code><code class="p">}</code><code>
</code><code>    </code><code class="p">}</code><code>
</code><code class="p">}</code></pre></div>
<p>This method sends an error report to a system administrator by email using the <code>SmtpClient</code> class from the <code>System.Net.Mail</code> namespace. It also calls an internal method (not shown here) called <code>LogPersistently</code> to record the failure in a local logging mechanism. Since these are both operations that could take some time, the code sends the email asynchronously—the <code>SendAsync</code> method returns immediately, and the class raises a .NET event once the email has been sent. This enables the code to get on with the call to <code>LogPersistently</code> while the email is being sent.</p>
<p>Having logged the message, the method waits for the email to go out before returning, which is where the <code>ManualResetEvent</code> comes in. By passing <code>false</code> to the constructor, I’ve put the event into an initial unsignaled state. But in the handler for the email <code>SendCompleted</code> .NET event, I call the synchronization event’s <code>Set</code> method, which will put it into the signaled state. (In production code, I’d also check the .NET event handler’s argument to see if there was an error, but I’ve omitted that here because it’s not relevant to the point I’m illustrating.)</p>
<p>Finally, I call <code>WaitOne</code>, which will block until the event is signaled. The <code>SmtpClient</code> might do its job so quickly that the email has already gone by the time my call to <code>LogPersistently</code> returns. But that’s OK—in that case, <code>WaitOne</code> returns immediately, because the <code>ManualResetEvent</code> stays signaled once you call <code>Set</code>. So it doesn’t matter which piece of work finishes first—the persistent logging or sending the <span class="keep-together">email.</span> In either case, <code>WaitOne</code> will let the thread continue when the email has been sent. (For the background on this method’s curious name, see the next sidebar, <a data-type="xref" href="#waithandle">“WaitHandle”</a>.)</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="waithandle">
<h5>WaitHandle</h5>
<p><a data-primary="WaitHandle class" data-type="indexterm" id="idm45884787098400"/>In Windows implementations of .NET, <code>ManualResetEvent</code> is a wrapper around a Win32 event object. There are several other synchronization classes that are also wrappers around underlying OS synchronization primitives: <code>AutoResetEvent</code>, <code>Mutex</code>, and <code>Sempahore</code>. These all derive from a common base class, <code>WaitHandle</code>. (On non-Windows .NET implementations, the runtime libraries just implement equivalent behavior where directly analogous OS primitives are not available.)</p>
<p>A <code>WaitHandle</code> can be in one of two states: signaled or not signaled. The exact meaning of this varies from one primitive to the next. A <code>ManualReset</code> event becomes signaled when you call <code>Set</code> (and it stays in the signaled state until explicitly unset). A <code>Mutex</code> is in the signaled state only if no thread currently possesses it. Despite the variations in interpretation, waiting for a <code>WaitHandle</code> will always block if it is not signaled and will not block if it is signaled.</p>
<p>With Win32 synchronization objects, you can either wait for a single item to become signaled or you can wait on multiple objects, either until any of them is signaled or until all of them are. The <code>WaitHandle</code> class defines <code>WaitOne</code>, <code>WaitAny</code>, and <code>WaitAll</code> methods corresponding to these three ways of waiting. With primitives where a successful wait has the side effect of acquiring ownership (exclusively in the case of <code>Mutex</code>, or partially with <code>Semaphore</code>), there can be a problem with attempting to wait on multiple objects—if two threads both attempt to acquire the same objects but do so in a different order, deadlock will ensue if these attempts overlap. But <code>WaitAll</code> deals with that—the order in which you specify the items does not matter, because it acquires them atomically—it will not allow any of the waits to succeed until they can all succeed simultaneously. (Of course, if a single thread makes a second call to <code>WaitAll</code> without first releasing all objects acquired in an earlier call, the door will still be open to deadlock. <code>WaitAll</code> helps only if you can acquire everything you need in a single step.)</p>
<p><code>WaitAll</code> does not work on a thread that is using COM’s STA mode because of a limitation in the underlying Windows API that it depends on. As I described in <a data-type="xref" href="ch14.xhtml#ch_attributes">Chapter 14</a>, if your program’s entry point is annotated with <code>[STAThread]</code>, it will be using this mode, as will any thread that hosts UI elements.</p>
<p>You can also use a <code>WaitHandle</code> in conjunction with the thread pool. The <code>ThreadPool</code> class has a <code>RegisterWaitForSingleObject</code> method that accepts any <code>WaitHandle</code> and invokes the callback you supply when the handle becomes signaled. As I’ll discuss later, this can be a bad idea for certain kinds of <code>WaitHandle</code>-derived types, such as <code>Mutex</code>.</p>
</div></aside>
<p><a data-primary="AutoResetEvent class" data-type="indexterm" id="idm45884787024304"/>There’s also an <code>AutoResetEvent</code>. As soon as a single thread has returned from waiting for such an event, it automatically reverts to the unsignaled state. Thus, calling <code>Set</code> on this event will allow at most one thread through. If you call <code>Set</code> once while no threads are waiting, the event will remain set, so unlike <code>Monitor.Pulse</code>, the notification will not be lost. However, the event does not maintain a count of the number of outstanding sets—if you call <code>Set</code> twice while no threads are waiting for the event, it will still allow only the first thread through, resetting immediately.</p>
<p>Both of these event types derive only indirectly from <code>WaitHandle</code>, through the <span class="keep-together"><code>EventWaitHandle</code></span> base class. You can use this directly, and it lets you specify manual or automatic resetting with a constructor argument. But what’s more interesting about <code>EventWaitHandle</code> is that it lets you work across process boundaries (on Windows only). The underlying Win32 event objects can be given names, and if you know the name of an event created by another process, you can open it by passing the name when constructing an <span class="keep-together"><code>EventWaitHandle</code></span>. (If no event with the name you specify exists yet, your process will be the one that creates it.) No equivalent to named events exist on Unix, so you will get a <code>PlatformNotSupportedException</code> if you try to create one in those environments, although single-process use <em>is</em> supported, so you are free to use these types as long as you don’t attempt to specify a name.</p>
<p><a data-primary="ManualResetEventSlim class" data-type="indexterm" id="idm45884787016384"/>There is also a <code>ManualResetEventSlim</code> class. However, unlike the nonslim reader/<span class="keep-together">writer, <code>ManualResetEvent</code> has</span> not been superseded by its slim successor because only the older type supports cross-process use. The <span class="keep-together"><code>ManualResetEventSlim</code></span> class’s main benefit is that if your code needs to wait only for a very short time, it can be more efficient because it will poll (much like a <code>SpinLock</code>) for a while. This saves it from having to use relatively expensive OS scheduler services. However, it will eventually give up and fall back to a more heavyweight mechanism. (Even in this case, it’s marginally more efficient, because it doesn’t need to support cross-process operation, so it uses a more lightweight mechanism.) There is no slim version of the automatic event, because automatic reset events are not all that widely used.<a data-startref="ix_ch16-asciidoc26" data-type="indexterm" id="idm45884787012528"/><a data-startref="ix_ch16-asciidoc25" data-type="indexterm" id="idm45884787011824"/></p>
</div></section>
<section data-pdf-bookmark="Barrier" data-type="sect2"><div class="sect2" id="barrier">
<h2>Barrier</h2>
<p><a data-primary="Barrier class" data-type="indexterm" id="idm45884787009760"/><a data-primary="synchronization, multithreading and" data-secondary="Barrier class" data-type="indexterm" id="idm45884787008832"/>In the preceding section, I showed how you can use an event to coordinate concurrent work, enabling one thread to wait until something else has happened before proceeding. The runtime libraries offer a class that can handle similar kinds of coordination but with slightly different semantics. The <code>Barrier</code> class can handle multiple participants and can also support multiple <em>phases</em>, meaning that threads can wait for one another several times as work progresses. <code>Barrier</code> is symmetric—whereas in <a data-type="xref" href="#waiting_for_work_to_complete_with_manual">Example 16-12</a>, the event handler calls <code>Set</code> while another thread calls <code>WaitOne</code>, with a <code>Barrier</code>, all participants call the <code>SignalAndWait</code> method, which effectively combines the set and wait into one operation.</p>
<p>When a participant calls <code>SignalAndWait</code>, the method will block until all of the participants have called it, at which point they will all be unblocked and free to continue. The <code>Barrier</code> knows how many participants to expect, because you pass the count as a constructor argument.</p>
<p>Multiphase operation simply involves going around again. Once the final participant calls <code>SignalAndWait</code>, releasing the rest, if any thread calls <code>SignalAndWait</code> a second time, it will block just like before, until all the others call it a second time. The <span class="keep-together"><code>CurrentPhaseNumber</code></span> tells you how many times this has occurred so far.</p>
<p>The symmetry makes <code>Barrier</code> a less suitable solution than <code>ManualResetEvent</code> in <a data-type="xref" href="#waiting_for_work_to_complete_with_manual">Example 16-12</a>, because in that case, only one of the threads really needs to wait. There’s no benefit in making the <code>SendComplete</code> event handler wait for the persistent log update to finish—only one of the participants cares when work is complete. <span class="keep-together"><code>ManualResetEvent</code></span> supports only a single participant, but that’s not necessarily a reason to use <code>Barrier</code>. If you want event-style asymmetry with multiple participants, there’s another approach: countdowns.</p>
</div></section>
<section data-pdf-bookmark="CountdownEvent" data-type="sect2"><div class="sect2" id="countdownevent">
<h2>CountdownEvent</h2>
<p><a data-primary="CountdownEvent class" data-type="indexterm" id="idm45884786994640"/><a data-primary="synchronization, multithreading and" data-secondary="CountdownEvent class" data-type="indexterm" id="idm45884786993936"/>The <code>CountdownEvent</code> class is similar to an event, but it allows you to specify that it must be signaled some particular number of times before it allows waiting threads through. The constructor takes an initial count argument, and you can increase the count at any time by calling <code>AddCount</code>. You call the <code>Signal</code> method to reduce the count; by default, it will reduce it by one, but there’s an overload that lets you reduce it by a specified number.</p>
<p>The <code>Wait</code> method blocks until the count reaches zero. If you want to inspect the current count to see how far there is to go, you can read the <code>CurrentCount</code> property.</p>
</div></section>
<section data-pdf-bookmark="Semaphores" data-type="sect2"><div class="sect2" id="semaphores">
<h2>Semaphores</h2>
<p><a data-primary="Semaphore class" data-type="indexterm" id="idm45884786987728"/><a data-primary="semaphores" data-type="indexterm" id="idm45884786986800"/><a data-primary="synchronization, multithreading and" data-secondary="semaphores" data-type="indexterm" id="idm45884786986128"/>Another count-based system that is widely used in concurrent systems is known as a <em>semaphore</em>. Windows has native support for this, and .NET’s <code>Semaphore</code> class was originally designed as a wrapper for it. Like the event wrappers, <code>Semaphore</code> derives from <code>WaitHandle</code>, and on non-Windows platforms, the behavior is emulated. Whereas a <code>CountdownEvent</code> lets through waiting threads only once the count gets to zero, a <code>Semaphore</code> starts blocking threads only when the count gets to zero. You could use this if you wanted to ensure that no more than a particular number of threads were performing certain work simultaneously.</p>
<p>Because <code>Semaphore</code> derives from <code>WaitHandle</code>, you call the <code>WaitOne</code> method to wait. This blocks only if the count is already zero. It decrements the count by one when it returns. You increment the count by calling <code>Release</code>. You specify the initial count as a constructor argument, and you must also supply a maximum count—if a call to <code>Release</code> attempts to set the count above the maximum, it will throw an exception.</p>
<p>As with events, Windows supports the cross-process use of semaphores, so you can optionally pass a semaphore name as a constructor argument. This will open an existing semaphore or create a new one if a semaphore with the specified name does not yet exist.</p>
<p><a data-primary="SemaphoreSlim class" data-type="indexterm" id="idm45884786978560"/>There’s also a <code>SemaphoreSlim</code> class. Like <code>ManualResetEventSlim</code>, this offers a performance benefit in scenarios where threads will not normally have to block for long. <code>SemaphoreSlim</code> offers two ways to decrement the count. Its <code>Wait</code> method works much like the <code>Semaphore</code> class’s <code>WaitOne</code>, but it also offers <code>WaitAsync</code>, which returns a <code>Task</code> that completes once the count is nonzero (and it decrements the count as it completes the task). This means you do not need to block a thread while you wait for the semaphore to become available. Moreover, it means you can use the <code>await</code> keyword described in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a> to decrement a semaphore.</p>
</div></section>
<section data-pdf-bookmark="Mutex" data-type="sect2"><div class="sect2" id="mutex">
<h2>Mutex</h2>
<p><a data-primary="mutex" data-type="indexterm" id="idm45884786970848"/><a data-primary="Mutex class" data-type="indexterm" id="idm45884786969920"/><a data-primary="synchronization, multithreading and" data-secondary="mutex" data-type="indexterm" id="idm45884786969248"/>Windows defines a <em>mutex</em> synchronization primitive for which .NET provides a wrapper class, <code>Mutex</code>. The name is short for “mutually exclusive,” because only one thread at a time can be in possession of a mutex—if thread A owns the mutex, thread B cannot, and vice versa, for example. This is also exactly what the <code>lock</code> keyword does for us through the <code>Monitor</code> class, but <code>Mutex</code> offers two advantages. It offers cross-process support: as with other cross-process synchronization primitives, you can pass in a name when you construct a mutex. (And unlike all the others, this type supports naming even on Unix-based platforms.) And with <code>Mutex</code> you can wait for multiple objects in a single operation.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The <code>ThreadPool.RegisterWaitForSingleObject</code> method does not work for a mutex, because Win32 requires mutex ownership to be tied to a particular thread, and the inner workings of the thread pool mean that <code>RegisterWaitForSingleObject</code> is unable to determine which thread pool thread handles the callback with the mutex.</p>
</div>
<p>You acquire a mutex by calling <code>WaitOne</code>, and if some other thread owns the mutex at the time, <code>WaitOne</code> will block until that thread calls <code>ReleaseMutex</code>. Once <code>WaitOne</code> returns successfully, you own the mutex. You must release the mutex from the same thread on which you acquired it.</p>
<p>There is no “slim” version of the <code>Mutex</code> class. We already have a low-overhead equivalent, because all .NET objects have the innate ability to provide lightweight mutual exclusion, thanks to <code>Monitor</code> and the <code>lock</code> keyword.</p>
</div></section>
<section data-pdf-bookmark="Interlocked" data-type="sect2"><div class="sect2" id="interlocked">
<h2>Interlocked</h2>
<p><a data-primary="Interlocked class" data-type="indexterm" id="ix_ch16-asciidoc28"/><a data-primary="synchronization, multithreading and" data-secondary="Interlocked class" data-type="indexterm" id="ix_ch16-asciidoc29"/>The <code>Interlocked</code> class is a little different than the other types I’ve described so far in this section. It supports concurrent access to shared data, but it is not a synchronization primitive. Instead, it defines static methods that provide atomic forms of various simple operations.</p>
<p>For example, it provides <code>Increment</code>, <code>Decrement</code>, and <code>Add</code> methods, with overloads supporting <code>int</code> and <code>long</code> values. (These are all similar—incrementing or decrementing are just addition by 1 or −1.) Addition involves reading a value from some storage location, calculating a modified value, and storing that back in the same storage location, and if you use normal C# operators to do this, things can go wrong if multiple threads try to modify the same location simultaneously. If the value is initially <code>0</code>, and some thread reads that value and then another thread also reads the value, if both then add 1 and store the result back, they will both end up writing back <code>1</code>—two threads attempted to increment the value, but it went up only by one. The <code>Interlocked</code> form of these operations prevents this sort of overlap.</p>
<p><code>Interlocked</code> also offers various methods for swapping values. <a data-primary="Exchange method" data-type="indexterm" id="idm45884786948016"/>The <code>Exchange</code> method takes two arguments: a reference to a value and a value. This returns the value currently in the location referred to by the first argument and also overwrites that location with the value supplied as a second argument, and it performs these two steps as a single atomic operation. There are overloads supporting <code>int</code>, <code>uint</code>, <code>long</code>, <code>ulong</code>, <code>object</code>, <code>float</code>, <code>double</code>, and a type called <code>IntPtr</code>, which represents an unmanaged pointer. There is also a generic <code>Exchange&lt;T&gt;</code>, where <code>T</code> can be any reference type.</p>
<p><a data-primary="CompareExchange method" data-type="indexterm" id="idm45884786941984"/>There is also support for conditional exchange, with the <code>CompareExchange</code> method. This takes three values—as with <code>Exchange</code>, it takes a reference to some variable you wish to modify, and the value you want to replace it with, but it also takes a third argument: the value you think is already in the storage location. If the value in the storage location does not match the expected value, this method will not change the storage location. (It still returns whatever value was in that storage location, whether it modifies it or not.) It’s actually possible to implement the other <code>Interlocked</code> operations I’ve described in terms of this one. <a data-type="xref" href="#using_compareexchange">Example 16-13</a> uses it to implement an interlocked increment operation.</p>
<div data-type="example" id="using_compareexchange">
<h5><span class="label">Example 16-13. </span>Using <code>CompareExchange</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">static</code> <code class="kt">int</code> <code class="nf">InterlockedIncrement</code><code class="p">(</code><code class="k">ref</code> <code class="kt">int</code> <code class="n">target</code><code class="p">)</code>
<code class="p">{</code>
    <code class="kt">int</code> <code class="n">current</code><code class="p">,</code> <code class="n">newValue</code><code class="p">;</code>
    <code class="k">do</code>
    <code class="p">{</code>
        <code class="n">current</code> <code class="p">=</code> <code class="n">target</code><code class="p">;</code>
        <code class="n">newValue</code> <code class="p">=</code> <code class="n">current</code> <code class="p">+</code> <code class="m">1</code><code class="p">;</code>
    <code class="p">}</code>
    <code class="k">while</code> <code class="p">(</code><code class="n">Interlocked</code><code class="p">.</code><code class="n">CompareExchange</code><code class="p">(</code><code class="k">ref</code> <code class="n">target</code><code class="p">,</code> <code class="n">newValue</code><code class="p">,</code> <code class="n">current</code><code class="p">)</code>
            <code class="p">!=</code> <code class="n">current</code><code class="p">);</code>
    <code class="k">return</code> <code class="n">newValue</code><code class="p">;</code>
<code class="p">}</code></pre></div>
<p>The pattern would be the same for other operations: read the current value, calculate the value with which to replace it, and then replace it only if the value doesn’t appear to have changed in the meantime. If the value changes in between fetching the current value and replacing it, go around again. You need to be a little bit careful here—even if the <code>CompareExchange</code> succeeds, it’s possible that other threads modified the value twice between your reading the value and updating it, with the second update putting things back how they were before the first. With addition and subtraction, that doesn’t really matter, because it doesn’t affect the outcome, but in general, you should not presume too much about what a successful update signifies. If you’re in doubt, it’s often better to stick with one of the more heavyweight synchronization mechanisms.</p>
<p><a data-primary="Read method" data-type="indexterm" id="idm45884786870304"/>The simplest <code>Interlocked</code> operation is the <code>Read</code> method. This takes a <code>ref long</code> and reads the value atomically with respect to any other operations on the same variable that you perform through <code>Interlocked</code>. This enables you to read 64-bit values safely—in general, the CLR does not guarantee that 64-bit reads will be atomic. (In a 64-bit process, they normally will be, but if you want atomicity on 32-bit architectures, you need to use <code>Interlocked.Read</code>.) There are no overloads for 32-bit values, because reading and writing those is always atomic.</p>
<p>The operations supported by <code>Interlocked</code> correspond to the atomic operations that most CPUs can support more or less directly. (Some CPU architectures support all the operations innately, while others support only the compare and exchange, building everything else up out of that. But in any case, these operations are at most a few instructions.) This means they are reasonably efficient. They are considerably more costly than performing equivalent noninterlocked operations with ordinary code, because atomic CPU instructions need to coordinate across all CPU cores (and across all CPU chips in computers that have multiple physically separate CPUs installed) to guarantee atomicity. Nonetheless, they incur a fraction of the cost you pay when a <code>lock</code> statement ends up blocking the thread at the OS level.</p>
<p><a data-primary="lock free operations" data-type="indexterm" id="idm45884786865328"/>These sorts of operations are sometimes described as <em>lock free</em>. This is not entirely accurate—the computer does acquire locks very briefly at a fairly low level in the hardware. Atomic read-modify-write operations effectively acquire an exclusive lock on the computer’s memory for two bus cycles. However, no OS locks are acquired, the scheduler does not need to get involved, and the locks are held for an extremely short duration—often for just one machine code instruction. More significantly, the highly specialized and low-level form of locking used here does not permit holding onto one lock while waiting to acquire another—code can lock only one thing at a time. This means that this sort of operation will not deadlock. However, the simplicity that rules out deadlocks cuts both ways.</p>
<p>The downside of interlocked operations is that the atomicity applies only to extremely simple operations. It’s very hard to build more complex logic in a way that works correctly in a multithreaded environment using just <code>Interlocked</code>. It’s easier and considerably less risky to use the higher-level synchronization primitives, because those make it fairly easy to protect more complex operations rather than just individual calculations. You would typically use <code>Interlocked</code> only in extremely performance-sensitive work, and even then, you should measure carefully to verify that it’s having the effect you hope—code such as <a data-type="xref" href="#using_compareexchange">Example 16-13</a> could in theory loop any number of times before eventually completing, so it could end up costing you more than you expect.</p>
<p>One of the biggest challenges with writing correct code when using low-level atomic operations is that you may encounter problems caused by the way CPU caches work. Work done by one thread may not become visible instantly to other threads, and in some cases, memory access may not necessarily occur in the order that your code specifies. Using higher-level synchronization primitives sidesteps these issues by enforcing certain ordering constraints, but if you decide instead to use <code>Interlocked</code> to build your own synchronization mechanisms, you will need to understand the memory model that .NET defines for when multiple threads access the same memory simultaneously, and you will typically need to use either the <code>MemoryBarrier</code> method defined by the <code>Interlocked</code> class or the various methods defined by the <code>Volatile</code> class to ensure correctness. This is beyond the scope of this book, and it’s also a really good way to write code that looks like it works but turns out to go wrong under heavy load (i.e., when it probably matters most), so these sorts of techniques are rarely worth the cost. Stick with the other mechanisms I’ve discussed in this chapter unless you really have no alternative.<a data-startref="ix_ch16-asciidoc29" data-type="indexterm" id="idm45884786839248"/><a data-startref="ix_ch16-asciidoc28" data-type="indexterm" id="idm45884786838576"/></p>
</div></section>
<section data-pdf-bookmark="Lazy Initialization" data-type="sect2"><div class="sect2" id="lazy_initialization">
<h2>Lazy Initialization</h2>
<p><a data-primary="initialization" data-secondary="lazy" data-type="indexterm" id="ix_ch16-asciidoc30"/><a data-primary="lazy initialization" data-type="indexterm" id="ix_ch16-asciidoc31"/><a data-primary="synchronization, multithreading and" data-secondary="lazy initialization" data-type="indexterm" id="ix_ch16-asciidoc32"/>When you need an object to be accessible from multiple threads, if it’s possible for that object to be immutable (i.e., its fields never change after construction), you can often avoid the need for synchronization. It is always safe for multiple threads to read from the same location simultaneously—trouble sets in only if the data needs to change. However, there is one challenge: when and how do you initialize the shared object? One solution might be to store a reference to the object in a static field initialized from a static constructor or a field initializer—the CLR guarantees to run the static initialization for any class just once. However, this might cause the object to be created earlier than you want. If you perform too much work in static initialization, this can have an adverse effect on how long it takes your application to start running.</p>
<p>You might want to wait until the object is first needed before initializing it. This is called <em>lazy initialization</em>. This is not particularly hard to achieve—you can just check a field to see if it’s <code>null</code> and initialize it if not, using <code>lock</code> to ensure that only one thread gets to construct the value. However, this is an area in which developers seem to have a remarkable appetite for showing how clever they are, with the potentially undesirable corollary of demonstrating that they’re not as clever as they think they are.</p>
<p>The <code>lock</code> keyword works fairly efficiently, but it’s possible to do better by using <code>Interlocked</code>. However, the subtleties of memory access reordering on multiprocessor systems make it easy to write code that runs quickly, looks clever, and doesn’t always work. To try to avert this recurring problem, .NET provides two classes to perform lazy initialization without using <code>lock</code> or other potentially expensive synchronization primitives. The easiest to use is <code>Lazy&lt;T&gt;</code>.</p>
<section data-pdf-bookmark="Lazy&lt;T&gt;" data-type="sect3"><div class="sect3" id="lazy_of_t">
<h3>Lazy&lt;T&gt;</h3>
<p><a data-primary="Lazy&lt;T&gt; class" data-type="indexterm" id="idm45884786826912"/><a data-primary="synchronization, multithreading and" data-secondary="Lazy&lt;T&gt; class" data-type="indexterm" id="idm45884786825984"/>The <code>Lazy&lt;T&gt;</code> class provides a <code>Value</code> property of type <code>T</code>, and it will not create the instance that <code>Value</code> returns until the first time something reads the property. By default, <span class="keep-together"><code>Lazy&lt;T&gt;</code></span> will use the no-arguments constructor for <code>T</code>, but you can supply your own method for creating the instance.</p>
<p><code>Lazy&lt;T&gt;</code> is able to handle race conditions for you. In fact, you can configure the level of multithreaded protection you require. Since lazy initialization can also be useful in single-threaded environments, you can disable multithreaded support entirely (by passing either <code>false</code> or <code>LazyThreadSafetyMode.None</code> as a constructor argument). But for multithreaded environments, you can choose between the other two modes in the <code>LazyThreadSafetyMode</code> enumeration.</p>
<p>These determine what happens if multiple threads all try to read the <code>Value</code> property for the first time more or less simultaneously. <code>PublicationOnly</code> does not attempt to ensure that only one thread creates an object—it only applies any synchronization at the point at which a thread finishes creating an object. The first thread to complete construction or initialization gets to supply the object, and the ones produced by any other threads that had started initialization are all discarded. Once a value is available, all further attempts to read <code>Value</code> will just return that.</p>
<p>If you choose <code>ExecutionAndPublication</code>, only a single thread will be allowed to attempt construction. That may seem less wasteful, but 
<span class="keep-together"><code>PublicationOnly</code></span> offers a potential advantage: because it avoids holding any locks during initialization, you are less likely to introduce deadlock bugs if the initialization code itself attempts to acquire any locks. <code>PublicationOnly</code> also handles errors differently. If the first initialization attempt throws an exception, other threads that had begun a construction attempt are given a chance to complete, whereas with 
<span class="keep-together"><code>ExecutionAndPublication</code>,</span> if the one and only attempt to initialize fails, the exception is retained and will be thrown each time any code reads <code>Value</code>.</p>
</div></section>
<section data-pdf-bookmark="LazyInitializer" data-type="sect3"><div class="sect3" id="lazyinitializer">
<h3>LazyInitializer</h3>
<p><a data-primary="LazyInitializer class" data-type="indexterm" id="idm45884786811696"/><a data-primary="synchronization, multithreading and" data-secondary="LazyInitializer class" data-type="indexterm" id="idm45884786810992"/>The other class supporting lazy initialization is <code>LazyInitializer</code>. This is a static class, and you use it entirely through its static generic methods. It is marginally more complex to use than <code>Lazy&lt;T&gt;</code>, but it avoids the need to allocate an extra object in addition to the lazily allocated instance you require. <a data-type="xref" href="#using_lazyinitializer">Example 16-14</a> shows how to 
<span class="keep-together">use it.</span></p>
<div data-type="example" id="using_lazyinitializer">
<h5><span class="label">Example 16-14. </span>Using <code>LazyInitializer</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">Cache</code><code class="p">&lt;</code><code class="n">T</code><code class="p">&gt;</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">static</code> <code class="n">Dictionary</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">,</code> <code class="n">T</code><code class="p">&gt;?</code> <code class="n">_d</code><code class="p">;</code>

    <code class="k">public</code> <code class="k">static</code> <code class="n">IDictionary</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">,</code> <code class="n">T</code><code class="p">&gt;</code> <code class="n">Dictionary</code> <code class="p">=&gt;</code>
        <code class="n">LazyInitializer</code><code class="p">.</code><code class="n">EnsureInitialized</code><code class="p">(</code><code class="k">ref</code> <code class="n">_d</code><code class="p">);</code>
<code class="p">}</code></pre></div>
<p>If the field is null, the <code>EnsureInitialized</code> method constructs an instance of the argument type—<code>Dictionary&lt;string, T&gt;</code>, in this case. Otherwise, it will return the value already in the field. There are some other overloads. You can pass a callback, much as you can to <code>Lazy&lt;T&gt;</code>. You can also pass a <code>ref bool</code> argument, which it will inspect to discover whether initialization has already occurred (and it sets this to <code>true</code> when it performs initialization).</p>
<p>A static field initializer would have given us the same once-and-once-only initialization but might have ended up running far earlier in the process’s lifetime. In a more complex class with multiple fields, static initialization might even cause unnecessary work, because it happens for the entire class, so you might end up constructing objects that don’t get used. This could increase the amount of time it takes for an application to start up. <code>LazyInitializer</code> lets you initialize individual fields as and when they are first used, ensuring that you do only work that is needed.<a data-startref="ix_ch16-asciidoc32" data-type="indexterm" id="idm45884786751360"/><a data-startref="ix_ch16-asciidoc31" data-type="indexterm" id="idm45884786750656"/><a data-startref="ix_ch16-asciidoc30" data-type="indexterm" id="idm45884786749984"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Other Class Library Concurrency Support" data-type="sect2"><div class="sect2" id="other_class_library_concurrency_support">
<h2>Other Class Library Concurrency Support</h2>
<p><a data-primary="synchronization, multithreading and" data-secondary="runtime library concurrency support" data-type="indexterm" id="idm45884786747376"/><a data-primary="System.Collections.Concurrent namespace" data-type="indexterm" id="idm45884786746464"/>The <code>System.Collections.Concurrent</code> namespace defines various collections that make more generous guarantees in the face of multithreading than the usual collections, meaning you may be able to use them without needing any other synchronization primitives. Take care, though—as always, even though individual operations may have well-defined behavior in a multithreaded world, that doesn’t necessarily help you if the operation you need to perform involves multiple steps. You may still need coordination at a broader scope to guarantee consistency. But in some situations, the concurrent collections may be all you need.</p>
<p>Unlike the nonconcurrent collections, <code>ConcurrentDictionary</code>, <code>ConcurrentBag</code>, 
<span class="keep-together"><code>ConcurrentStack</code>,</span> and <code>ConcurrentQueue</code> all support modification of their contents even while enumeration (e.g., with a <code>foreach</code> loop) of those contents is in progress. The dictionary provides a live enumerator, in the sense that if values are added or removed while you’re in the middle of enumerating, the enumerator might show you some of the added items and it might not show you the removed items. It makes no firm guarantees, not least because with multithreaded code, when two things happen on two different threads, it’s not always entirely clear which happened first—the laws of relativity mean that it may depend on your point of view.</p>
<p>This means that it’s possible for an enumerator to seem to return an item after that item was removed from the dictionary. The bag, stack, and queue take a different approach: their enumerators all take a snapshot and iterate over that, so a <code>foreach</code> loop will see a set of contents that is consistent with what was in the collection at some point in the past, even though it may since have changed.</p>
<p>As I already mentioned in <a data-type="xref" href="ch05.xhtml#ch_collections">Chapter 5</a>, the concurrent collections present APIs that have similarities to their nonconcurrent counterparts but with some additional members to support atomic addition and removal of items. For example, <code>Concurrent​Dic⁠tionary</code> offers a <code>GetOrAdd</code> method that returns an existing entry if one exists and adds a new entry otherwise.</p>
<p>Another part of the runtime libraries that can help you deal with concurrency without needing to make explicit use of synchronization primitives is Rx (the subject of <a data-type="xref" href="ch11.xhtml#ch_reactive_extensions">Chapter 11</a>). It offers various operators that can combine multiple asynchronous streams together into a single stream. These manage concurrency issues for you—remember that any single observable will provide observers with items one at a time.</p>
<p>Rx takes the necessary steps to ensure that it stays within these rules even when it combines inputs from numerous individual streams that are all producing items concurrently. As long as all the sources stick to the rules, Rx will never ask an observer to deal with more than one thing at a time.</p>
<p>The <code>System.Threading.Channels</code> NuGet package offers types that support 
<span class="keep-together">producer/consumer</span> patterns, in which one or more threads generate data, while other threads consume that data. You can choose whether channels are buffered, enabling producers to get ahead of consumers, and if so, by how much. (The <code>Blocking​Col⁠lection&lt;T&gt;</code> in <code>System.Collections.Concurrent</code> also offers this kind of service. However, it is less flexible, and it does not support the <code>await</code> keyword described in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>.)</p>
<p>Finally, in multithreaded scenarios it is worth considering the immutable collection classes, which I described in <a data-type="xref" href="ch05.xhtml#ch_collections">Chapter 5</a>. These support concurrent access from any number of threads, and because they are immutable, the question of how to handle concurrent write access never arises. Obviously, immutability imposes considerable constraints, but if you can find a way to work with these types (and remember, the built-in <code>string</code> type is immutable, so you already have some experience of working with immutable data), they can be very useful in some concurrent scenarios.<a data-startref="ix_ch16-asciidoc19" data-type="indexterm" id="idm45884786714688"/><a data-startref="ix_ch16-asciidoc18" data-type="indexterm" id="idm45884786713984"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Tasks" data-type="sect1"><div class="sect1" id="tasks">
<h1>Tasks</h1>
<p><a data-primary="multithreading" data-secondary="tasks" data-seealso="Task and Task&lt;T&gt; classes" data-type="indexterm" id="ix_ch16-asciidoc33"/><a data-primary="Task and Task&lt;T&gt; classes" data-type="indexterm" id="ix_ch16-asciidoc34"/>Earlier in this chapter, I showed how to use the <code>Task</code> class to launch work in the thread pool. This class is more than just a wrapper for the thread pool. <code>Task</code> and the related types that form the Task Parallel Library (TPL) can handle a wider range of scenarios. Tasks are particularly important because C#’s asynchronous language features (which are the topic of <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>) are able to work with these directly. A great many APIs in the runtime libraries offer task-based asynchronous operation.</p>
<p>Although tasks are the preferred way to use the thread pool, they are not just about multithreading. The basic abstractions are more flexible than that.</p>
<section data-pdf-bookmark="The Task and Task&lt;T&gt; Classes" data-type="sect2"><div class="sect2" id="the_task_and_taskltg_classes">
<h2>The Task and Task&lt;T&gt; Classes</h2>
<p>There are two classes at the heart of the TPL: <code>Task</code> and a class that derives from it, <code>Task&lt;T&gt;</code>. The <code>Task</code> base class represents some work that may take some time to complete. <code>Task&lt;T&gt;</code> extends this to represent work that produces a result (of type <code>T</code>) when it completes. (The nongeneric <code>Task</code> does not produce any result. It’s the asynchronous equivalent of a <code>void</code> return type.) Notice that these are not concepts that necessarily involve threads.</p>
<p>Most I/O operations can take a while to complete, and in most cases, the runtime libraries provide task-based APIs for them. <a data-type="xref" href="#task-based_web_download">Example 16-15</a> uses an asynchronous method to fetch the content of a web page as a string. Since it cannot return the string immediately—it might take a while to download the page—it returns a task instead.</p>
<div data-type="example" id="task-based_web_download">
<h5><span class="label">Example 16-15. </span>Task-based web download</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="kt">var</code> <code class="n">w</code> <code class="p">=</code> <code class="k">new</code> <code class="n">HttpClient</code><code class="p">();</code>
<code class="kt">string</code> <code class="n">url</code> <code class="p">=</code> <code class="s">"https://endjin.com/"</code><code class="p">;</code>
<code class="n">Task</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">&gt;</code> <code class="n">webGetTask</code> <code class="p">=</code> <code class="n">w</code><code class="p">.</code><code class="n">GetStringAsync</code><code class="p">(</code><code class="n">url</code><code class="p">);</code></pre></div>
<div class="note2" data-type="note" epub:type="note"><h6>Note</h6>
<p>Most task-based APIs follow a naming convention in which they end in <code>Async</code>, and if there’s a corresponding synchronous API, it will have the same name but without the <code>Async</code> suffix. For example, the <code>Stream</code> class in <code>System.IO</code>, which provides access to streams of bytes, has a <code>Write</code> method to write bytes to a stream, and that method is synchronous (i.e., it waits until it finishes its work before returning). It also offers a <code>WriteAsync</code> method. This does the same as <code>Write</code>, but because it’s asynchronous, it returns without waiting for its work to complete. It returns a <code>Task</code> to represent the work; this convention is called the <em>Task-based Asynchronous Pattern</em> (TAP).</p>
</div>
<p>That <code>GetStringAsync</code> method does not wait for the download to complete, so it returns almost immediately. To perform the download, the computer has to send a message to the relevant server, and then it must wait for a response. Once the request is on its way, there’s no work for the CPU to do until the response comes in, meaning that this operation does not need to involve a thread for the majority of the time that the request is in progress. So this method does not wrap some underlying synchronous version of the API in a call to <code>Task.Run</code>. <a data-primary="HttpClient class" data-type="indexterm" id="idm45884786673024"/>In fact, <code>HttpClient</code> doesn’t even have synchronous equivalents of most of its operations. And with classes that offer I/O APIs in both forms, such as <code>Stream</code>, the synchronous versions are often wrappers around a fundamentally asynchronous implementation: when you call a blocking API to perform I/O, it will typically perform an asynchronous operation under the covers and then just block the calling thread until that work completes. And even in cases where it’s nonasynchronous all the way down to the OS—e.g., the <code>FileStream</code> can use nonasynchronous operating system file APIs to implement <code>Read</code> and <code>Write</code>—I/O in the OS kernel is typically asynchronous in nature.</p>
<p>So, although the <code>Task</code> and <code>Task&lt;T&gt;</code> classes make it very easy to produce tasks that work by running methods on thread pool threads, they are also able to represent fundamentally asynchronous operations that do not require the use of a thread for most of their duration. Although it’s not part of the official terminology, I describe this kind of operation as a <em>threadless task</em>, to distinguish it from tasks that run entirely on thread pool threads.</p>
<section data-pdf-bookmark="ValueTask and ValueTask&lt;T&gt;" data-type="sect3"><div class="sect3" id="value_tasks">
<h3>ValueTask and ValueTask&lt;T&gt;</h3>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="ValueTask and ValueTask&lt;T&gt;" data-type="indexterm" id="idm45884786666640"/><a data-primary="ValueTask and ValueTask&lt;T&gt; types" data-type="indexterm" id="idm45884786665728"/><code>Task</code> and <code>Task&lt;T&gt;</code> are pretty flexible, and not just because they can represent both thread-based and threadless operations. As you’ll see, they offer several mechanisms for discovering when the work they represent completes, including the ability to combine multiple tasks into one. Multiple threads can all wait on the same task simultaneously. You can write caching mechanisms that repeatedly hand out the same task, even long after the task completes. This is all very convenient, but it means that these task types also have some overheads. For more constrained cases, .NET defines less flexible <code>ValueTask</code> and <code>ValueTask&lt;T&gt;</code> types that are more efficient in certain circumstances.</p>
<p>The most important difference between these types and their ordinary counterparts is that <code>ValueTask</code> and <code>ValueTask&lt;T&gt;</code> are value types. This is significant in performance-sensitive code because it can reduce the number of objects that code allocates, reducing the amount of time an application spends performing garbage collection work. You might be thinking that the context switching costs typically involved with concurrent work are likely to be high enough that the cost of an object allocation will be the least of your concerns when dealing with asynchronous operations. And while this is often true, there’s one very important scenario where the GC overhead of <code>Task&lt;T&gt;</code> can be problematic: operations that sometimes run slowly but usually don’t.</p>
<p>It is very common for I/O APIs to perform buffering to reduce the number of calls into the OS. If you write a few bytes into a <code>Stream</code>, it will typically put those into a buffer and wait until either you’ve written enough data to make it worth sending it to the OS or you’ve explicitly called <code>Flush</code>. And it’s also common for reads to be buffered—if you read a single byte from a file, the OS will typically have to read an entire sector from the drive (usually at least 4 KB), and that data usually gets saved somewhere in memory so that when you ask for the second byte, no more I/O needs to happen. The practical upshot is that if you write a loop that reads data from a file in relatively small chunks (e.g., one line of text at a time), the majority of read operations will complete straightaway because the data being read has already been fetched.</p>
<p>In these cases where the overwhelming majority of calls into asynchronous APIs complete immediately, the GC overheads of creating task objects can become significant. This is why <code>ValueTask</code> and <code>ValueTask&lt;T&gt;</code> were introduced. (These are built into .NET Core, .NET, and .NET Standard 2.1. On .NET Framework, you can get them via the <code>System.Threading.Tasks.Extensions</code> NuGet package.) These make it possible for potentially asynchronous operations to complete immediately without needing to allocate any objects. In cases where immediate completion is not possible, these types end up being wrappers for <code>Task</code> or <code>Task&lt;T&gt;</code> objects, at which point the overheads return, but in cases where only a small fraction of calls need to do that, these types can offer significant performance boosts, particularly in code that uses the low-allocation techniques described in <a data-type="xref" href="ch18.xhtml#ch_memory_efficiency">Chapter 18</a>.</p>
<p>The nongeneric <code>ValueTask</code> is rarely used, because asynchronous operations that produce no result can just return the <code>Task.CompletedTask</code> static property, which provides a reusable task that is already in the completed state, avoiding any GC overhead. But tasks that need to produce a result generally can’t reuse existing tasks. (There are some exceptions: the runtime libraries will often use cached precompleted tasks for <code>Task&lt;bool&gt;</code>, because there are only two possible outcomes. But for <code>Task&lt;int&gt;</code>, there’s no practical way to maintain a list of precompleted tasks for every possible result.)</p>
<p>These value task types have some constraints. They are single use: unlike <code>Task</code> and <code>Task&lt;T&gt;</code>, you must not store these types in a dictionary or a <code>Lazy&lt;T&gt;</code> to provide a cached asynchronous value. It is an error to attempt to retrieve the <code>Result</code> of a <code>ValueTask&lt;T&gt;</code> before it has completed. It is also an error to retrieve the <code>Result</code> more than once. In general, you should use a <code>ValueTask</code> or <code>ValueTask&lt;T&gt;</code> with exactly one <code>await</code> operation (as described in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>) and then never use it again. (Alternatively, if necessary, you can escape these restrictions by calling its <code>AsTask</code> method to obtain a full <code>Task</code>, or <code>Task&lt;T&gt;</code> with all the corresponding overheads, at which point you should not do anything more with the value task.)</p>
<p>Because the value type tasks were introduced many years after the TPL first appeared, class libraries often use <code>Task&lt;T&gt;</code> where you might expect to see a <code>ValueTask&lt;T&gt;</code>. For example, the <code>Stream</code> class’s <code>ReadAsync</code> methods are all prime candidates, but because most of those were defined long before <code>ValueTask&lt;T&gt;</code> existed, they mostly return <code>Task&lt;T&gt;</code>. The recently added overload that accepts a <code>Memory&lt;byte&gt;</code> instead of a <code>byte[]</code> does return a <code>ValueTask&lt;T&gt;</code>, though, and more generally, where APIs have been augmented to add support for the new memory-efficient techniques described in <a data-type="xref" href="ch18.xhtml#ch_memory_efficiency">Chapter 18</a>, these will usually return <code>ValueTask&lt;T&gt;</code>. And if you’re in a performance-sensitive world where the GC overhead of a task is significant, you will likely want to be using those techniques in any case.</p>
</div></section>
<section data-pdf-bookmark="Task creation options" data-type="sect3"><div class="sect3" id="task_creation_options">
<h3>Task creation options</h3>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="creation options" data-type="indexterm" id="idm45884786607872"/>Instead of using <code>Task.Run</code>, you can get more control over certain aspects of a new thread-based task by creating it with the <code>StartNew</code> method of either <code>Task.Factory</code> or <code>Task&lt;T&gt;.Factory</code>, depending on whether your task needs to return a result. Some overloads of <code>StartNew</code> take an argument of the <code>enum</code> type <code>TaskCreationOptions</code>, which provides some control over how the TPL schedules the task.</p>
<p>The <code>PreferFairness</code> flag asks to run the task after any tasks that have already been scheduled. By default, the thread pool normally runs the most recently added tasks first (a last-in, first-out, or LIFO, policy) because this tends to make more efficient use of the CPU cache.</p>
<p>The <code>LongRunning</code> flag warns the TPL that the task may run for a long time. By default, the TPL’s scheduler optimizes for relatively short work items—anything up to a few seconds. This flag indicates that the work might take longer than that, in which case the TPL may modify its scheduling. If there are too many long-running tasks, they might use up all the threads, and even though some of the queued work items might be for much shorter pieces of work, those will still take a long time to finish, because they’ll have to wait in line behind the slow work before they can even start. But if the TPL knows which items are likely to run quickly and which are likely to be slower, it can prioritize them differently to avoid such problems.</p>
<p>The other <code>TaskCreationOptions</code> settings relate to parent/child task relationships and schedulers, which I’ll describe later.</p>
</div></section>
<section data-pdf-bookmark="Task status" data-type="sect3"><div class="sect3" id="task_status">
<h3>Task status</h3>
<p><a data-primary="Status property" data-type="indexterm" id="idm45884786598592"/><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="Status property" data-type="indexterm" id="idm45884786597664"/>A task goes through a number of states in its lifetime, and you can use the <code>Task</code> class’s <code>Status</code> property to discover where it has gotten to. This returns a value of the <code>enum</code> type <code>TaskStatus</code>. If a task completes successfully, the property will return the enumeration’s <code>RanToCompletion</code> value. If the task fails, it will be <code>Faulted</code>. If you cancel a task using the technique shown in <a data-type="xref" href="#cancellation">“Cancellation”</a>, the status will then be <code>Canceled</code>.</p>
<p>There are several variations on a theme of “in progress,” of which <code>Running</code> is the most obvious—it means that some thread is currently executing the task. A task representing I/O doesn’t typically require a thread while it is in progress, so it never enters that state—it starts in the <code>WaitingForActivation</code> state and then typically transitions directly to one of the three final states (<code>RanToCompletion</code>, <code>Faulted</code>, or <code>Canceled</code>). A thread-based task can also be in this <code>WaitingForActivation</code> state but only if something is preventing it from running, which would typically happen if you set it up to run only when some other task completes (which I’ll show how to do shortly). A thread-based task may also be in the <code>WaitingToRun</code> state, which means that it’s in a queue waiting for a thread pool thread to become available. It’s possible to establish parent/child relationships between tasks, and a parent that has already finished but that created some child tasks that are not yet complete will be in the <code>WaitingForChildrenToComplete</code> state.</p>
<p>Finally, there’s the <code>Created</code> state. You don’t see this very often, because it represents a thread-based task that you have created but have not yet asked to run. You’ll never see this with a task created using the task factory’s <code>StartNew</code> method, or with <code>Task.Run</code>, but you will see this if you construct a new <code>Task</code> directly.</p>
<p>The level of detail in the <code>TaskStatus</code> property may be too much most of the time, so the <code>Task</code> class defines various simpler <code>bool</code> properties. If you want to know only whether the task has no more work to do (and don’t care whether it succeeded, failed, or was canceled), there’s the <code>IsCompleted</code> property. If you want to check for failure or cancellation, use <code>IsFaulted</code> or <code>IsCanceled</code>.</p>
</div></section>
<section data-pdf-bookmark="Retrieving the result" data-type="sect3"><div class="sect3" id="retrieving_the_result">
<h3>Retrieving the result</h3>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="retrieving the result" data-type="indexterm" id="idm45884786580224"/>Suppose you’ve got a <code>Task&lt;T&gt;</code>, either from an API that provides one or by creating a thread-based task that returns a value. If the task completes successfully, you are likely to want to retrieve its result, which you can get from the <code>Result</code> property. So the task created by <a data-type="xref" href="#task-based_web_download">Example 16-15</a> makes the web page content available in <code>webGetTask.Result</code>.</p>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="Result property" data-type="indexterm" id="idm45884786576384"/><a data-primary="Result property" data-type="indexterm" id="idm45884786575216"/>If you try to read the <code>Result</code> property before the task completes, it will block your thread until the result is available. (If you have a plain <code>Task</code>, which does not return a result, and you would like to wait for that to finish, you can just call <code>Wait</code> instead.) If the operation then fails, <code>Result</code> throws an exception (as does <code>Wait</code>), although that is not as straightforward as you might expect, as I will discuss in <a data-type="xref" href="#error_handling">“Error Handling”</a>.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>You should avoid using <code>Result</code> on an uncompleted task. In some scenarios, it risks deadlock. This is particularly common in desktop applications, because certain work needs to happen on particular threads, and if you block a thread by reading the <code>Result</code> of an incomplete task, you might prevent the task from completing. Even if you don’t deadlock, blocking on <code>Result</code> can cause performance issues by hogging thread pool threads that might otherwise have been able to get on with useful work. And reading <code>Result</code> in an uncompleted <code>ValueTask&lt;T&gt;</code> is not permitted.</p>
</div>
<p>In most cases, it is far better to use C#’s asynchronous language features to retrieve the result. These are the subject of the next chapter, but as a preview, <a data-type="xref" href="#getting_a_task_result_with_await">Example 16-16</a> shows how you could use this to get the result of the task that fetches a web page. (You’ll need to apply the <code>async</code> keyword in front of the method declaration to be able to use the <code>await</code> keyword.)</p>
<div data-type="example" id="getting_a_task_result_with_await">
<h5><span class="label">Example 16-16. </span>Getting a task’s results with <code>await</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="kt">string</code> <code class="n">pageContent</code> <code class="p">=</code> <code class="k">await</code> <code class="n">webGetTask</code><code class="p">;</code></pre></div>
<p>This may not look like an exciting improvement on simply writing <code>webGetTask.Result</code>, but as I’ll show in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>, this code is not quite what it seems—the C# compiler restructures this statement into a callback-driven state machine that enables you to get the result without blocking the calling thread. (If the operation hasn’t finished, the thread returns to the caller, and the remainder of the method runs later when the operation completes.)</p>
<p>But how are the asynchronous language features able to make this work—how can code discover when a task has completed? <code>Result</code> or <code>Wait</code> let you just sit and wait for that to happen, blocking the thread, but that rather defeats the purpose of using an asynchronous API in the first place. You will normally want to be notified when the task completes, and you can do this with a <em>continuation</em>.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Continuations" data-type="sect2"><div class="sect2" id="continuations">
<h2>Continuations</h2>
<p><a data-primary="continuation task" data-type="indexterm" id="ix_ch16-asciidoc37"/><a data-primary="ContinueWith method" data-type="indexterm" id="ix_ch16-asciidoc38"/><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="continuations" data-type="indexterm" id="ix_ch16-asciidoc39"/>Tasks provide various overloads of a method called <code>ContinueWith</code>. This creates a new thread-based task that will execute when the task on which you called <code>Contin⁠ue​With</code> finishes (whether it does so successfully or with failure or cancellation). <a data-type="xref" href="#a_continuation">Example 16-17</a> uses this on the task created in <a data-type="xref" href="#task-based_web_download">Example 16-15</a>.</p>
<div data-type="example" id="a_continuation">
<h5><span class="label">Example 16-17. </span>A continuation</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="n">webGetTask</code><code class="p">.</code><code class="n">ContinueWith</code><code class="p">(</code><code class="n">t</code> <code class="p">=&gt;</code>
<code class="p">{</code>
    <code class="kt">string</code> <code class="n">webContent</code> <code class="p">=</code> <code class="n">t</code><code class="p">.</code><code class="n">Result</code><code class="p">;</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Web page length: "</code> <code class="p">+</code> <code class="n">webContent</code><code class="p">.</code><code class="n">Length</code><code class="p">);</code>
<code class="p">});</code></pre></div>
<p>A continuation task is always a thread-based task (regardless of whether its antecedent task was thread-based, I/O-based, or something else). The task gets created as soon as you call <code>ContinueWith</code> but does not become runnable until its antecedent task completes. (It starts out in the <code>WaitingForActivation</code> state.)</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>A continuation is a task in its own right—<code>ContinueWith</code> returns either a <code>Task&lt;T&gt;</code> or <code>Task</code>, depending on whether the delegate you supply returns a result. You can set up a continuation for a continuation if you want to chain together a sequence of operations.</p>
</div>
<p>The method you provide for the continuation (such as the lambda in <a data-type="xref" href="#a_continuation">Example 16-17</a>) receives the antecedent task as its argument, and I’ve used this to retrieve the result. I could also have used the <code>webGetTask</code> variable, which is in scope from the containing method, as it refers to the same task. However, by using the argument, the lambda in <a data-type="xref" href="#a_continuation">Example 16-17</a> doesn’t use any variables from its containing method, which enables the compiler to produce slightly more efficient code—it doesn’t need to create an object to hold shared variables, and it can reuse the delegate instance it creates because it doesn’t have to create a context-specific one for each call. This means I could also easily separate this out into an ordinary noninline method, if I felt that would make the code easier to read.</p>
<p>You might be thinking that there’s a possible problem in <a data-type="xref" href="#a_continuation">Example 16-17</a>: What if the download completes extremely quickly so that <code>webGetTask</code> has already completed before the code manages to attach the continuation? In fact, that doesn’t matter—if you call <code>ContinueWith</code> on a task that has already completed, it will still run the continuation. It just schedules it immediately. You can attach as many continuations as you like. All the continuations you attach before the task completes will be scheduled for execution when it does complete. And any that you attach after the task has completed will be scheduled immediately.</p>
<p>By default, a continuation task will be scheduled for execution on the thread pool like any other task. However, there are some things you can do to change how it runs.</p>
<p>Some overloads of <code>ContinueWith</code> take an argument of the <code>enum</code> type <code>Task​Conti⁠nua⁠tionOptions</code>, which controls how (and whether) your task is scheduled. This includes all of the same options that are available with <code>TaskCreationOptions</code> but adds some others specific to continuations.</p>
<p>You can specify that the continuation should run only in certain circumstances. For example, the <code>OnlyOnRanToCompletion</code> flag will ensure that the continuation runs only if the antecedent task succeeds. There are similar <code>OnlyOnFaulted</code> and <code>OnlyOn​Can⁠celed</code> flags. Alternatively, you can specify <code>NotOnRanToCompletion</code>, which means that the continuation will run only if the task either faults or is canceled.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can create multiple continuations for a single task. So you could set up one to handle the success case and another one to handle failures.</p>
</div>
<p>You can also specify <code>ExecuteSynchronously</code>. This indicates that the continuation should not be scheduled as a separate work item. Normally, when a task completes, any continuations for that task will be scheduled for execution and will have to wait until the normal thread pool mechanisms pick the work items out of the queue and execute them. (This won’t take long if you use the default options—unless you specify <code>PreferFairness</code>, the LIFO operation the thread pool uses for tasks means that the most recently scheduled items run first.) However, if your completion does only the tiniest amount of work, the overhead of scheduling it as a completely separate item may be overkill. So <code>ExecuteSynchronously</code> lets you piggyback the completion task on the same thread pool work item that ran the antecedent—the TPL will run this kind of continuation immediately after the antecedent finishes before returning the thread to the pool. You should use this option only if the continuation will run quickly.</p>
<p>The <code>LazyCancellation</code> option handles a tricky situation that can occur if you make tasks cancelable (as described later in <a data-type="xref" href="#cancellation">“Cancellation”</a>) and you are using continuations. If you cancel a task, any continuations will, by default, become runnable instantly. If the task being canceled was itself set up as a continuation for another task that hadn’t yet finished, and if it has a continuation of its own, as <a data-type="xref" href="#lazy_cancellation_scenario">Example 16-18</a> shows, this can have a mildly surprising effect.</p>
<div data-type="example" id="lazy_cancellation_scenario">
<h5><span class="label">Example 16-18. </span>Cancellation and chained continuations</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">ShowContinuations</code><code class="p">()</code>
<code class="p">{</code>
    <code class="n">Task</code> <code class="n">op</code> <code class="p">=</code> <code class="n">Task</code><code class="p">.</code><code class="n">Run</code><code class="p">(</code><code class="n">DoSomething</code><code class="p">);</code>
    <code class="kt">var</code> <code class="n">cs</code> <code class="p">=</code> <code class="k">new</code> <code class="n">CancellationTokenSource</code><code class="p">();</code>
    <code class="n">Task</code> <code class="n">onDone</code> <code class="p">=</code> <code class="n">op</code><code class="p">.</code><code class="n">ContinueWith</code><code class="p">(</code>
        <code class="n">_</code> <code class="p">=&gt;</code> <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Never runs"</code><code class="p">),</code>
        <code class="n">cs</code><code class="p">.</code><code class="n">Token</code><code class="p">);</code>
    <code class="n">Task</code> <code class="n">andAnotherThing</code> <code class="p">=</code> <code class="n">onDone</code><code class="p">.</code><code class="n">ContinueWith</code><code class="p">(</code>
        <code class="n">_</code> <code class="p">=&gt;</code> <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Continuation's continuation"</code><code class="p">));</code>
    <code class="n">cs</code><code class="p">.</code><code class="n">Cancel</code><code class="p">();</code>
<code class="p">}</code>

<code class="k">static</code> <code class="k">void</code> <code class="nf">DoSomething</code><code class="p">()</code>
<code class="p">{</code>
    <code class="n">Thread</code><code class="p">.</code><code class="n">Sleep</code><code class="p">(</code><code class="m">1000</code><code class="p">);</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Initial task finishing"</code><code class="p">);</code>
<code class="p">}</code></pre></div>
<p>This creates a task that will call <code>DoSomething</code>, followed by a cancelable continuation for that task (the <code>Task</code> in <code>onDone</code>), and then a final task (<code>andAnotherThing</code>) that is a continuation for the first continuation. This code cancels almost immediately, which is almost certain to happen before the first task completes. The effect of this is that the final task runs before the first completes. The final <code>andAnotherThing</code> task becomes runnable when <code>onDone</code> completes, even if that completion was due to <code>onDone</code> being canceled. Since there was a chain here—<code>andAnotherThing</code> is a continuation for <code>onDone</code>, which is a continuation for <code>op</code>—it is a bit odd that <code>andAnotherThing</code> ends up running before <code>op</code> has finished. <code>LazyCancellation</code> changes the behavior so that the first continuation will not be deemed to have completed until its antecedent completes, meaning that the final continuation will run only after the first task has finished.</p>
<p>There’s another mechanism for controlling how tasks execute: you can specify a scheduler.<a data-startref="ix_ch16-asciidoc39" data-type="indexterm" id="idm45884786348128"/><a data-startref="ix_ch16-asciidoc38" data-type="indexterm" id="idm45884786347424"/><a data-startref="ix_ch16-asciidoc37" data-type="indexterm" id="idm45884786314752"/></p>
</div></section>
<section data-pdf-bookmark="Schedulers" data-type="sect2"><div class="sect2" id="schedulers-id1">
<h2>Schedulers</h2>
<p><a data-primary="schedulers (thread-based tasks)" data-type="indexterm" id="idm45884786312624"/><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="schedulers" data-type="indexterm" id="idm45884786311952"/><a data-primary="TaskScheduler class" data-type="indexterm" id="idm45884786310992"/>All thread-based tasks are executed by a <code>TaskScheduler</code>. By default, you’ll get the TPL-supplied scheduler that runs work items via the thread pool. However, there are other kinds of schedulers, and you can even write your own.</p>
<p>The most common reason for selecting a nondefault scheduler is to handle thread affinity requirements. The <code>TaskScheduler</code> class’s static <code>FromCurrentSynchroniza⁠tion​Context</code> method returns a scheduler based on the current synchronization context for whichever thread you call the method from. This scheduler will execute all work via that synchronization context. So, if you call 
<span class="keep-together"><code>FromCurrentSynchronizationContext</code></span> from a UI thread, the resulting scheduler can be used to run tasks that can safely update the UI. You would typically use this for a continuation—you can run some task-based asynchronous work and then hook up a continuation that updates the UI when that work is complete. <a data-type="xref" href="#scheduling_a_continuation_on_the_ui_thre">Example 16-19</a> shows this technique in use in the code<span class="keep-together">behind</span> file for a window in a WPF application.</p>
<div data-type="example" id="scheduling_a_continuation_on_the_ui_thre">
<h5><span class="label">Example 16-19. </span>Scheduling a continuation on the UI thread</h5>
<pre data-code-language="csharp" data-type="programlisting">
<code class="k">public</code><code> </code><code class="k">partial</code><code> </code><code class="k">class</code><code> </code><code class="nc">MainWindow</code><code> </code><code class="p">:</code><code> </code><code class="n">Window</code><code>
</code><code class="p">{</code><code>
</code><code>    </code><code class="k">public</code><code> </code><code class="nf">MainWindow</code><code class="p">(</code><code class="p">)</code><code>
</code><code>    </code><code class="p">{</code><code>
</code><code>        </code><code class="n">InitializeComponent</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>
</code><code>    </code><code class="p">}</code><code>
</code><code>
</code><code>    </code><code class="k">private</code><code> </code><code class="k">static</code><code> </code><code class="k">readonly</code><code> </code><code class="n">HttpClient</code><code> </code><code class="n">w</code><code> </code><code class="p">=</code><code> </code><code class="k">new</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>
</code><code>    </code><strong><code class="k">private</code><code> </code><code class="k">readonly</code><code> </code><code class="n">TaskScheduler</code><code> </code><code class="n">_uiScheduler</code><code> </code><code class="p">=</code></strong><code>
</code><code>        </code><strong><code class="n">TaskScheduler</code><code class="p">.</code><code class="n">FromCurrentSynchronizationContext</code><code class="p">(</code><code class="p">)</code><code class="p">;</code></strong><code>
</code><code>
</code><code>    </code><code class="k">private</code><code> </code><code class="k">void</code><code> </code><code class="nf">FetchButtonClicked</code><code class="p">(</code><code class="kt">object</code><code> </code><code class="n">sender</code><code class="p">,</code><code> </code><code class="n">RoutedEventArgs</code><code> </code><code class="n">e</code><code class="p">)</code><code>
</code><code>    </code><code class="p">{</code><code>
</code><code>        </code><code class="kt">string</code><code> </code><code class="n">url</code><code> </code><code class="p">=</code><code> </code><code class="s">"https://endjin.com/"</code><code class="p">;</code><code>
</code><code>        </code><code class="n">Task</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">&gt;</code><code> </code><code class="n">webGetTask</code><code> </code><code class="p">=</code><code> </code><code class="n">w</code><code class="p">.</code><code class="n">GetStringAsync</code><code class="p">(</code><code class="n">url</code><code class="p">)</code><code class="p">;</code><code>
</code><code>
</code><code>        </code><code class="n">webGetTask</code><code class="p">.</code><code class="n">ContinueWith</code><code class="p">(</code><code class="n">t</code><code> </code><code class="p">=</code><code class="p">&gt;</code><code>
</code><code>        </code><code class="p">{</code><code>
</code><code>            </code><code class="kt">string</code><code> </code><code class="n">webContent</code><code> </code><code class="p">=</code><code> </code><code class="n">t</code><code class="p">.</code><code class="n">Result</code><code class="p">;</code><code>
</code><code>            </code><code class="n">outputTextBox</code><code class="p">.</code><code class="n">Text</code><code> </code><code class="p">=</code><code> </code><code class="n">webContent</code><code class="p">;</code><code>
</code><code>        </code><code class="p">}</code><code class="p">,</code><code>
</code><code>        </code><strong><code class="n">_uiScheduler</code><code class="p">)</code><code class="p">;</code></strong><code>
</code><code>    </code><code class="p">}</code><code>
</code><code class="p">}</code></pre></div>
<p>This uses a field initializer to obtain the scheduler—the constructor for a UI element runs on the UI thread, so this will get a scheduler for the synchronization context for the UI thread. A click handler then downloads a web page using the <code>HttpClient</code> class’s <code>GetStringAsync</code>. This runs asynchronously, so it won’t block the UI thread, meaning that the application will remain responsive while the download is in progress. The method sets up a continuation for the task using an overload of <code>ContinueWith</code> that takes a <code>TaskScheduler</code>. This ensures that when the task that gets the content completes, the lambda passed to <code>ContinueWith</code> runs on the UI thread, so it’s safe for it to access UI elements.</p>
<div data-type="tip"><h6>Tip</h6>
<p>While this works perfectly well, the <code>await</code> keyword described in the next chapter provides a more straightforward solution to this particular problem.</p>
</div>
<p>The runtime libraries provide three built-in kinds of schedulers. There’s the default one that uses the thread pool, and the one I just showed that uses a synchronization context. The third is provided by a class called <code>ConcurrentExclusiveSchedulerPair</code>, and as the name suggests, this provides two schedulers, which it makes available through properties. The <code>ConcurrentScheduler</code> property returns a scheduler that will run tasks concurrently much like the default scheduler. The <code>ExclusiveScheduler</code> property returns a scheduler that can be used to run tasks one at a time, and it will temporarily suspend the other scheduler while it does so. (This is reminiscent of the reader/writer synchronization semantics I described earlier in the chapter—it allows exclusivity when required but concurrency the rest of the time.)</p>
</div></section>
<section data-pdf-bookmark="Error Handling" data-type="sect2"><div class="sect2" id="error_handling">
<h2>Error Handling</h2>
<p><a data-primary="error handling" data-secondary="Task object and" data-type="indexterm" id="idm45884786176256"/><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="error handling" data-type="indexterm" id="idm45884786175280"/>A <code>Task</code> object indicates when its work has failed by entering the <code>Faulted</code> state. There will always be at least one exception associated with failure, but the TPL allows composite tasks—tasks that contain a number of subtasks. This makes it possible for multiple failures to occur, and the root task will report them all. <code>Task</code> defines an <code>Exception</code> property, and its type is <code>AggregateException</code>. You may recall from <a data-type="xref" href="ch08.xhtml#ch_exceptions">Chapter 8</a> that as well as inheriting the <code>InnerException</code> property from the base 
<span class="keep-together"><code>Exception</code></span> type, <code>AggregateException</code> defines an <code>InnerExceptions</code> property that returns a collection of exceptions. This is where you will find the complete set of exceptions that caused the task to fault. (If the task was not a composite task, there will usually be just one.)</p>
<p>If you attempt to get the <code>Result</code> property or call <code>Wait</code> on a faulted task, it will throw the same <code>AggregateException</code> as it would return from the <code>Exception</code> property. A faulted task remembers whether you have used at least one of these members, and if you have not yet done so, it considers the exception to be <em>unobserved</em>. The TPL uses finalization to track faulted tasks with unobserved exceptions, and if you allow such a task to become unreachable, the <code>TaskScheduler</code> will raise its static <code>UnobservedTaskException</code> event. This gives you one last chance to do something about the exception, after which it will be lost.</p>
</div></section>
<section data-pdf-bookmark="Custom Threadless Tasks" data-type="sect2"><div class="sect2" id="custom_threadless_tasks">
<h2>Custom Threadless Tasks</h2>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="custom threadless tasks" data-type="indexterm" id="idm45884786117360"/>Many I/O-based APIs return threadless tasks. You can do the same if you want. <a data-primary="TaskCompletionSource&lt;T&gt; class" data-type="indexterm" id="idm45884786116064"/>The <code>TaskCompletionSource&lt;T&gt;</code> class provides a way to create a <code>Task&lt;T&gt;</code> that does not have an associated method to run on the thread pool and instead completes when you tell it to. There’s no nongeneric <code>TaskCompletionSource</code>, but there doesn’t need to be. <code>Task&lt;T&gt;</code> derives from <code>Task</code>, so you can just pick any type argument. By convention, most developers use <code>TaskCompletionSource&lt;object?&gt;</code> when they don’t need to provide a return value.</p>
<p>Suppose you’re using a class that does not provide a task-based API, and you’d like to add a task-based wrapper. The <code>SmtpClient</code> class I used in <a data-type="xref" href="#waiting_for_work_to_complete_with_manual">Example 16-12</a> supports the older event-based asynchronous pattern but not the task-based one. <a data-type="xref" href="#using_taskcompletionsource_of_t">Example 16-20</a> uses that API in conjunction with <code>TaskCompletionSource&lt;object?&gt;</code> to provide a task-based wrapper. (And, yes, there are two spellings of <code>Canceled</code>/​<code>Cancelled</code> in there. The TPL consistently uses <code>Canceled</code>, but older APIs exhibit more <span class="keep-together">variety.)</span></p>
<div data-type="example" id="using_taskcompletionsource_of_t">
<h5><span class="label">Example 16-20. </span>Using <code>TaskCompletionSource&lt;T&gt;</code></h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">static</code> <code class="k">class</code> <code class="nc">SmtpAsyncExtensions</code>
<code class="p">{</code>
    <code class="k">public</code> <code class="k">static</code> <code class="n">Task</code> <code class="nf">SendTaskAsync</code><code class="p">(</code><code class="k">this</code> <code class="n">SmtpClient</code> <code class="n">mailClient</code><code class="p">,</code> <code class="kt">string</code> <code class="k">from</code><code class="p">,</code>
                                <code class="kt">string</code> <code class="n">recipients</code><code class="p">,</code> <code class="kt">string</code> <code class="n">subject</code><code class="p">,</code> <code class="kt">string</code> <code class="n">body</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="kt">var</code> <code class="n">tcs</code> <code class="p">=</code> <code class="k">new</code> <code class="n">TaskCompletionSource</code><code class="p">&lt;</code><code class="kt">object?</code><code class="p">&gt;();</code>

        <code class="k">void</code> <code class="nf">CompletionHandler</code><code class="p">(</code><code class="kt">object</code> <code class="n">s</code><code class="p">,</code> <code class="n">AsyncCompletedEventArgs</code> <code class="n">e</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="c1">// Check this is the notification for our SendAsync.</code>
            <code class="k">if</code> <code class="p">(!</code><code class="kt">object</code><code class="p">.</code><code class="n">ReferenceEquals</code><code class="p">(</code><code class="n">e</code><code class="p">.</code><code class="n">UserState</code><code class="p">,</code> <code class="n">tcs</code><code class="p">))</code> <code class="p">{</code> <code class="k">return</code><code class="p">;</code> <code class="p">}</code>
            <code class="n">mailClient</code><code class="p">.</code><code class="n">SendCompleted</code> <code class="p">-=</code> <code class="n">CompletionHandler</code><code class="p">;</code>
            <code class="k">if</code> <code class="p">(</code><code class="n">e</code><code class="p">.</code><code class="n">Canceled</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">tcs</code><code class="p">.</code><code class="n">SetCanceled</code><code class="p">();</code>
            <code class="p">}</code>
            <code class="k">else</code> <code class="k">if</code> <code class="p">(</code><code class="n">e</code><code class="p">.</code><code class="n">Error</code> <code class="p">!=</code> <code class="k">null</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">tcs</code><code class="p">.</code><code class="n">SetException</code><code class="p">(</code><code class="n">e</code><code class="p">.</code><code class="n">Error</code><code class="p">);</code>
            <code class="p">}</code>
            <code class="k">else</code>
            <code class="p">{</code>
                <code class="n">tcs</code><code class="p">.</code><code class="n">SetResult</code><code class="p">(</code><code class="k">null</code><code class="p">);</code>
            <code class="p">}</code>
        <code class="p">};</code>

        <code class="n">mailClient</code><code class="p">.</code><code class="n">SendCompleted</code> <code class="p">+=</code> <code class="n">CompletionHandler</code><code class="p">;</code>
        <code class="n">mailClient</code><code class="p">.</code><code class="n">SendAsync</code><code class="p">(</code><code class="k">from</code><code class="p">,</code> <code class="n">recipients</code><code class="p">,</code> <code class="n">subject</code><code class="p">,</code> <code class="n">body</code><code class="p">,</code> <code class="n">tcs</code><code class="p">);</code>

        <code class="k">return</code> <code class="n">tcs</code><code class="p">.</code><code class="n">Task</code><code class="p">;</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>The <code>SmtpClient</code> notifies us that the operation is complete by raising an event. The handler for this event first checks that the event corresponds to our call to <code>SendAsync</code> and not some other operation that may have already been in progress. It then detaches itself (so that it doesn’t run a second time if something uses that same <code>SmtpClient</code> for further work). Then it detects whether the operation succeeded, was canceled, or failed, and calls the <code>SetResult</code>, <code>SetCanceled</code>, or <code>SetException</code> method, respectively, on the <code>TaskCompletionSource&lt;object&gt;</code>. This will cause the task to transition into the relevant state and will also take care of running any continuations attached to that task. The completion source makes the threadless <code>Task</code> object it creates available through its <code>Task</code> property, which this method returns.</p>
</div></section>
<section data-pdf-bookmark="Parent/Child Relationships" data-type="sect2"><div class="sect2" id="parent_solidus_child_relationships">
<h2>Parent/Child Relationships</h2>
<p><a data-primary="parent/child relationships, multithreading tasks and" data-type="indexterm" id="idm45884785934624"/><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="parent/child relationships" data-type="indexterm" id="idm45884785933952"/>If a thread-based task’s method creates a new thread-based task, then by default, there will be no particular relationship between those tasks. However, one of the <code>Task​Crea⁠tionOptions</code> flags is <code>AttachedToParent</code>, and if you set this, the newly created task will be a child of the task currently executing. The significance of this is that the parent task won’t report completion until all its children have completed. (Its own method also needs to complete, of course.) If any children fault, the parent task will fault, and it will include all the children’s exceptions in its own <code>AggregateException</code>.</p>
<p>You can also specify the <code>AttachedToParent</code> flag for a continuation. Be aware that this does not make it a child of its antecedent task. It will be a child of whichever task was running when <code>ContinueWith</code> was called to create the continuation.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Threadless tasks (e.g., most tasks representing I/O) often cannot be made children of another task. If you’re creating one yourself through a <code>TaskCompletionSource&lt;T&gt;</code>, you can do it because that class has a constructor overload that accepts a <code>TaskCreation​Op⁠tions</code>. However, the majority of .NET APIs that return tasks do not provide a way to request that the task be a child.</p>
</div>
<p>Parent/child relationships are not the only way of creating a task whose outcome is based on multiple other items.</p>
</div></section>
<section data-pdf-bookmark="Composite Tasks" data-type="sect2"><div class="sect2" id="composite_tasks">
<h2>Composite Tasks</h2>
<p><a data-primary="Task and Task&lt;T&gt; classes" data-secondary="composite tasks" data-type="indexterm" id="idm45884785889648"/>The <code>Task</code> class has static <code>WhenAll</code> and <code>WhenAny</code> methods. Each of these has overloads that accept either a collection of <code>Task</code> objects or a collection of <code>Task&lt;T&gt;</code> objects as the only argument. The <code>WhenAll</code> method returns either a <code>Task</code> or a <code>Task&lt;T[]&gt;</code> that completes only when all of the tasks provided in the argument have completed (and in the latter case, the composite task produces an array containing each of the individual tasks’ results). The <code>WhenAny</code> method returns a <code>Task&lt;Task&gt;</code> or <code>Task&lt;Task&lt;T&gt;&gt;</code> that completes as soon as the first task completes, providing that task as the result.</p>
<p>As with a parent task, if any of the tasks that make up a task produced with <code>WhenAll</code> fail, the exceptions from all of the failed tasks will be available in the composite task’s <code>AggregateException</code>. (<code>WhenAny</code> does not report errors. It completes as soon as the first task completes, and you must inspect that to discover if it failed.)</p>
<p>You can attach a continuation to these tasks, but there’s a slightly more direct route. Instead of creating a composite task with <code>WhenAll</code> or <code>WhenAny</code> and then calling 
<span class="keep-together"><code>ContinueWith</code></span> on the result, you can just call the <code>ContinueWhenAll</code> or <code>Continue​WhenAny</code> method of a task factory. Again, these take a collection of <code>Task</code> or <code>Task&lt;T&gt;</code>, but they also take a method to invoke as the continuation.<a data-startref="ix_ch16-asciidoc34" data-type="indexterm" id="idm45884785878032"/><a data-startref="ix_ch16-asciidoc33" data-type="indexterm" id="idm45884785877328"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Other Asynchronous Patterns" data-type="sect1"><div class="sect1" id="other_asynchronous_patterns">
<h1>Other Asynchronous Patterns</h1>
<p><a data-primary="multithreading" data-secondary="various asynchronous patterns" data-type="indexterm" id="idm45884785875104"/>Although the TPL provides the preferred mechanism for exposing asynchronous APIs, .NET had been around for almost a decade before it was added, so you will come across older approaches. <a data-primary="APM (Asynchronous Programming Model)" data-type="indexterm" id="idm45884785873808"/><a data-primary="Asynchronous Programming Model (APM)" data-type="indexterm" id="idm45884785873168"/>The longest established form is the Asynchronous Programming Model (APM). This was introduced in .NET 1.0, so it is widely implemented, but its use is now discouraged. With this pattern, methods come in pairs: one to start the work and a second to collect the results when it is complete. <a data-type="xref" href="#an_apm_pair_and_the_corresponding_synchr">Example 16-21</a> shows just such a pair from the <code>Stream</code> class in the <code>System.IO</code> namespace, and it also shows the corresponding synchronous method. (Code written today should use a task-based <code>WriteAsync</code> instead.)</p>
<div data-type="example" id="an_apm_pair_and_the_corresponding_synchr">
<h5><span class="label">Example 16-21. </span>An APM pair and the corresponding synchronous method</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">virtual</code> <code class="n">IAsyncResult</code> <code class="nf">BeginWrite</code><code class="p">(</code><code class="kt">byte</code><code class="p">[]</code> <code class="n">buffer</code><code class="p">,</code> <code class="kt">int</code> <code class="n">offset</code><code class="p">,</code> <code class="kt">int</code> <code class="n">count</code><code class="p">,</code>
    <code class="n">AsyncCallback</code> <code class="n">callback</code><code class="p">,</code> <code class="kt">object</code> <code class="n">state</code><code class="p">)...</code>
<code class="k">public</code> <code class="k">virtual</code> <code class="k">void</code> <code class="nf">EndWrite</code><code class="p">(</code><code class="n">IAsyncResult</code> <code class="n">asyncResult</code><code class="p">)...</code>

<code class="k">public</code> <code class="k">abstract</code> <code class="k">void</code> <code class="nf">Write</code><code class="p">(</code><code class="kt">byte</code><code class="p">[]</code> <code class="n">buffer</code><code class="p">,</code> <code class="kt">int</code> <code class="n">offset</code><code class="p">,</code> <code class="kt">int</code> <code class="n">count</code><code class="p">)...</code></pre></div>
<p>Notice that the first three arguments of the <code>BeginWrite</code> method are identical to those of the <code>Write</code> method. In the APM, the <code>Begin<em>Xxx</em></code> method takes all of the inputs (i.e., any normal arguments and any <code>ref</code> arguments but not <code>out</code> arguments, should any be present). The <code>End<em>Xxx</em></code> method provides any outputs, which means the return value, any <code>ref</code> arguments (because those can pass information either in or out), and any <code>out</code> arguments.</p>
<p>The <code>Begin<em>Xxx</em></code> method also takes two additional arguments: a delegate of type <span class="keep-together"><code>AsyncCallback</code></span>, which will be invoked when the operation completes, and an argument of type <code>object</code> that accepts any object you would like to associate with the operation (or <code>null</code> if you have no use for this). This method also returns an <code>IAsync​Re⁠sult</code>, which represents the asynchronous <span class="keep-together">operation</span>.</p>
<p>When your completion callback gets invoked, you can call the <code>End<em>Xxx</em></code> method, passing in the same <code>IAsyncResult</code> object returned by the <code>Begin<em>Xxx</em></code> method, and this will provide the return value if there is one. If the operation failed, the <code>End<em>Xxx</em></code> method will throw an exception.</p>
<p>You can wrap APIs that use the APM with a <code>Task</code>. The <code>TaskFactory</code> objects provided by <code>Task</code> and <code>Task&lt;T&gt;</code> provide <code>FromAsync</code> methods to which you can pass a pair of delegates for the <code>Begin<em>Xxx</em></code> and <code>End<em>Xxx</em></code> methods, and you also pass any arguments that the <code>Begin<em>Xxx</em></code> method requires. This will return a <code>Task</code> or <code>Task&lt;T&gt;</code> that represents the operation.</p>
<p><a data-primary="EAP (Event-based Asynchronous Pattern)" data-type="indexterm" id="idm45884785822192"/><a data-primary="Event-based Asynchronous Pattern (EAP)" data-type="indexterm" id="idm45884785821472"/>Another common older pattern is the Event-based Asynchronous Pattern (EAP). You’ve seen an example in this chapter—it’s what the <code>SmtpClient</code> uses. With this pattern, a class provides a method that starts the operation and a corresponding event that it raises when the operation completes. The method and event usually have related names, such as <code>SendAsync</code> and <code>SendCompleted</code>. An important feature of this pattern is that the method captures the synchronization context and uses that to raise the event, meaning that if you use an object that supports this pattern in UI code, it effectively presents a single-threaded asynchronous model. This makes it much easier to use than the APM, because you don’t need to write any extra code to get back onto the UI thread when asynchronous work completes.</p>
<p>There’s no automated mechanism for wrapping the EAP in a task, but as I showed in <a data-type="xref" href="#using_taskcompletionsource_of_t">Example 16-20</a>, it’s not particularly hard to do.</p>
<p>There’s one more common pattern used in asynchronous code: the <em>awaitable</em> pattern supported by the C# asynchronous language features (the <code>async</code> and <code>await</code> keywords). As I showed in <a data-type="xref" href="#getting_a_task_result_with_await">Example 16-16</a>, you can consume a TPL task directly with these features, but the language does not recognize <code>Task</code> directly, and it’s possible to await things other than tasks. You can use the <code>await</code> keyword with anything that implements a particular pattern. I will show this in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>.</p>
</div></section>
<section data-pdf-bookmark="Cancellation" data-type="sect1"><div class="sect1" id="cancellation">
<h1>Cancellation</h1>
<p><a data-primary="cancellation" data-type="indexterm" id="idm45884785760560"/><a data-primary="CancellationToken type" data-type="indexterm" id="idm45884785759856"/><a data-primary="multithreading" data-secondary="cancellation" data-type="indexterm" id="idm45884785759184"/>.NET defines a standard mechanism for canceling slow operations. Cancelable operations take an argument of the type <code>CancellationToken</code>, and if you set this into a canceled state, the operation will stop early if possible instead of running to 
<span class="keep-together">completion.</span></p>
<p>The <code>CancellationToken</code> type itself does not offer any methods to initiate cancellation—the API is designed so that you can tell operations when you want them to be canceled without giving them power to cancel whatever other operations you have associated with the same <code>CancellationToken</code>. The act of cancellation is managed through a separate object, <code>CancellationTokenSource</code>. As the name suggests, you can use this to get hold of any number of <code>CancellationToken</code> instances. If you call the <code>CancellationTokenSource</code> object’s <code>Cancel</code> method, that sets all of the associated <code>CancellationToken</code> instances into a canceled state.</p>
<p>Some of the synchronization mechanisms I described earlier can be passed a 
<span class="keep-together"><code>CancellationToken</code>.</span> (The ones that derive from <code>WaitHandle</code> cannot, because the underlying Windows primitives do not support .NET’s cancellation model. <code>Monitor</code> also does not support cancellation, but many newer APIs do.) It’s also common for task-based APIs to take a cancellation token, and the TPL itself also offers overloads of the <code>StartNew</code> and <code>ContinueWith</code> methods that take them. If the task has already started to run, there’s nothing the TPL can do to cancel it, but if you cancel a task before it begins to run, the TPL will take it out of the scheduled task queue for you. If you want to be able to cancel your task after it starts running, you’ll need to write code in the body of your task that inspects the <code>CancellationToken</code> and abandons the work if its <code>IsCancellationRequested</code> property is <code>true</code>.</p>
<p>Cancellation support is not ubiquitous, because it’s not always possible. Some operations simply cannot be canceled. For example, once a message has been sent out over the network, you can’t unsend it. Some operations allow work to be canceled up until some point of no return has been reached. (If a message is queued up to be sent but hasn’t actually been sent, then it might not be too late to cancel, for example.) This means that even when cancellation is offered, it might not do anything. So, when you use cancellation, you need to be prepared for it not to work.</p>
</div></section>
<section data-pdf-bookmark="Parallelism" data-type="sect1"><div class="sect1" id="parallelism">
<h1>Parallelism</h1>
<p><a data-primary="multithreading" data-secondary="parallelism" data-type="indexterm" id="ix_ch16-asciidoc40"/><a data-primary="parallelism, multithreading" data-type="indexterm" id="ix_ch16-asciidoc41"/>The runtime libraries include some classes that can work with collections of data concurrently on multiple threads. There are three ways to do this: the <code>Parallel</code> class, Parallel LINQ, and TPL Dataflow.</p>
<section data-pdf-bookmark="The Parallel Class" data-type="sect2"><div class="sect2" id="the_parallel_class">
<h2>The Parallel Class</h2>
<p><a data-primary="Parallel class" data-type="indexterm" id="idm45884785741632"/><a data-primary="parallelism, multithreading" data-secondary="Parallel class" data-type="indexterm" id="idm45884785740592"/>The <code>Parallel</code> class offers four static methods: <code>For</code>, <code>ForEach</code>, <code>ForEachAsync</code>, and <code>Invoke</code>. The last of those takes an array of delegates and executes all of them, potentially in parallel. (Whether it decides to use parallelism depends on various factors such as the number of hardware threads the computer has, how heavily loaded the system is, and how many items you want it to process.) The <code>For</code> and <code>ForEach</code> methods mimic the C# loop constructs of the same names, but they will also potentially execute iterations in parallel. <a data-primary=".NET 6.0" data-primary-sortas="NET 6.0" data-secondary="ForEachAsync method" data-type="indexterm" id="idm45884785736000"/><a data-primary="ForEachAsync method" data-type="indexterm" id="idm45884785734752"/><code>ForEachAsync</code>, which is new in .NET 6.0, also mimics a <code>foreach</code>, but it provides better support for asynchronous operation, including the ability to work with an <code>IAsyncEnumerable&lt;T&gt;</code> (like <code>await foreach</code>) or for each iteration to perform asynchronous operations (equivalent to using <code>await</code> in the body of a <code>foreach</code> loop).</p>
<p><a data-type="xref" href="#parallel_convolution">Example 16-22</a> illustrates the use of <code>Parallel.For</code> in code that performs a convolution of two sets of samples. This is a highly repetitive operation commonly used in signal processing. (In practice, a fast Fourier transform offers a more efficient way to perform this work unless the convolution kernel is small, but the complexity of that code would have obscured the main subject here, the <code>Parallel</code> class.) It produces one output sample for each input sample. Each output sample is produced by calculating the sum of a series of pairs of values from the two inputs, multiplied together. For large data sets, this can be time consuming, so it is the sort of work you might want to speed up by spreading it across multiple processors. Each individual output sample’s value can be calculated independently of all the others, so it is a good candidate for parallelization.</p>
<div data-type="example" id="parallel_convolution">
<h5><span class="label">Example 16-22. </span>Parallel convolution</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">static</code> <code class="kt">float</code><code class="p">[]</code> <code class="nf">ParallelConvolution</code><code class="p">(</code><code class="kt">float</code><code class="p">[]</code> <code class="n">input</code><code class="p">,</code> <code class="kt">float</code><code class="p">[]</code> <code class="n">kernel</code><code class="p">)</code>
<code class="p">{</code>
    <code class="kt">float</code><code class="p">[]</code> <code class="n">output</code> <code class="p">=</code> <code class="k">new</code> <code class="kt">float</code><code class="p">[</code><code class="n">input</code><code class="p">.</code><code class="n">Length</code><code class="p">];</code>
    <code class="n">Parallel</code><code class="p">.</code><code class="n">For</code><code class="p">(</code><code class="m">0</code><code class="p">,</code> <code class="n">input</code><code class="p">.</code><code class="n">Length</code><code class="p">,</code> <code class="n">i</code> <code class="p">=&gt;</code>
    <code class="p">{</code>
        <code class="kt">float</code> <code class="n">total</code> <code class="p">=</code> <code class="m">0</code><code class="p">;</code>
        <code class="k">for</code> <code class="p">(</code><code class="kt">int</code> <code class="n">k</code> <code class="p">=</code> <code class="m">0</code><code class="p">;</code> <code class="n">k</code> <code class="p">&lt;</code> <code class="n">Math</code><code class="p">.</code><code class="n">Min</code><code class="p">(</code><code class="n">kernel</code><code class="p">.</code><code class="n">Length</code><code class="p">,</code> <code class="n">i</code> <code class="p">+</code> <code class="m">1</code><code class="p">);</code> <code class="p">++</code><code class="n">k</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="n">total</code> <code class="p">+=</code> <code class="n">input</code><code class="p">[</code><code class="n">i</code> <code class="p">-</code> <code class="n">k</code><code class="p">]</code> <code class="p">*</code> <code class="n">kernel</code><code class="p">[</code><code class="n">k</code><code class="p">];</code>
        <code class="p">}</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="p">=</code> <code class="n">total</code><code class="p">;</code>
    <code class="p">});</code>

    <code class="k">return</code> <code class="n">output</code><code class="p">;</code>
<code class="p">}</code></pre></div>
<p>The basic structure of this code is very similar to a pair of nested <code>for</code> loops. I’ve simply replaced the outer <code>for</code> loop with a call to <code>Parallel.For</code>. (I’ve not attempted to parallelize the inner loop—if you make each individual step trivial, <code>Parallel.For</code> will spend more of its time in housekeeping work than it does running your code.)</p>
<p>The first argument, <code>0</code>, sets the initial value of the loop counter, and the second sets the upper limit. The final argument is a delegate that will be invoked once for each value of the loop counter, and the calls will occur concurrently if the <code>Parallel</code> class’s heuristics tell it that this is likely to produce a speedup as a result of the work running in parallel. Running this method with large data sets on a multicore machine causes all of the available hardware threads to be used to full capacity.</p>
<p>It may be possible to get better performance by partitioning the work in more cache-friendly ways—naive parallelization can give the impression of high performance by maxing out all your CPU cores while delivering suboptimal throughput. However, there is a trade-off between complexity and performance, and the simplicity of the <code>Parallel</code> class can often provide worthwhile wins for relatively little effort.</p>
</div></section>
<section data-pdf-bookmark="Parallel LINQ" data-type="sect2"><div class="sect2" id="parallel_linq">
<h2>Parallel LINQ</h2>
<p><a data-primary="parallelism, multithreading" data-secondary="Parallel LINQ" data-type="indexterm" id="idm45884785574864"/>Parallel LINQ is a LINQ provider that works with in-memory information, much like LINQ to Objects. The <code>System.Linq</code> namespace makes this available as an extension method called <code>AsParallel</code> defined for any <code>IEnumerable&lt;T&gt;</code> <a data-primary="ParallelEnumerable class" data-type="indexterm" id="idm45884785572208"/>(by the <code>Parallel​Enumera⁠ble</code> class). This returns a <code>ParallelQuery&lt;T&gt;</code>, which supports the usual LINQ 
<span class="keep-together">operators.</span></p>
<p>Any LINQ query built this way provides a <code>ForAll</code> method, which takes a delegate. When you call this, it invokes the delegate for all of the items that the query produces, and it will do so in parallel on multiple threads where possible.</p>
</div></section>
<section data-pdf-bookmark="TPL Dataflow" data-type="sect2"><div class="sect2" id="tpl_dataflow">
<h2>TPL Dataflow</h2>
<p><a data-primary="parallelism, multithreading" data-secondary="TPL Dataflow" data-type="indexterm" id="idm45884785567584"/>TPL Dataflow is a runtime library feature that lets you construct a graph of objects that perform some kind of processing on information that flows through them. You can tell the TPL which of these nodes needs to process information sequentially and which are happy to work on multiple blocks of data simultaneously. You push data into the graph, and the TPL will then manage the process of providing each node with blocks to process, and it will attempt to optimize the level of parallelism to match the resources available on your computer.</p>
<p>The dataflow API is in the <code>System.Threading.Tasks.Dataflow</code> namespace. (It’s built into .NET Core and .NET; on .NET Framework you’ll need to add a reference to a NuGet package, also called <code>System.Threading.Tasks.Dataflow</code>.) It is large and complex and could have a whole chapter to itself. Sadly, this makes it beyond the scope of this book. I mention it because it’s worth being aware of for certain kinds of work.<a data-startref="ix_ch16-asciidoc41" data-type="indexterm" id="idm45884785565328"/><a data-startref="ix_ch16-asciidoc40" data-type="indexterm" id="idm45884785564656"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="summary-multithreading">
<h1>Summary</h1>
<p>Threads provide the ability to execute multiple pieces of code simultaneously. On a computer with multiple CPU execution units (i.e., multiple hardware threads), you can exploit this potential for parallelism by using multiple software threads. You can create new software threads explicitly with the <code>Thread</code> class, or you can use either the thread pool or a parallelization mechanism, such as the <code>Parallel</code> class or Parallel LINQ, to determine automatically how many threads to use to run the work your application supplies. If multiple threads need to use and modify shared data structures, you will need to use the synchronization mechanisms offered by .NET to ensure that the threads can coordinate their work correctly.</p>
<p>Threads can also provide a way to execute multiple concurrent operations that do not need the CPU the whole time (e.g., waiting for a response from an external service), but it is often more efficient to perform such work with asynchronous APIs (where available). The Task Parallel Library (TPL) provides abstractions that are useful for both kinds of concurrency. It can manage multiple work items in the thread pool, with support for combining multiple operations and handling potentially complex error scenarios, and its <code>Task</code> abstraction can also represent inherently asynchronous operations. The next chapter describes C# language features that greatly simplify working with tasks.
<a data-startref="ix_ch16-asciidoc0" data-type="indexterm" id="idm45884785560032"/></p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="CHP-17-FN-2"><sup><a href="ch16.xhtml#CHP-17-FN-2-marker">1</a></sup> I’m using the word <em>state</em> here broadly. I just mean information stored in variables and objects.</p><p data-type="footnote" id="CHP-17-FN-3"><sup><a href="ch16.xhtml#CHP-17-FN-3-marker">2</a></sup> At the time of this writing, the documentation does not offer read-only thread safety guarantees for  <span class="keep-together"><code>HashSet&lt;T&gt;</code></span> and <code>SortedSet&lt;T&gt;</code>. Nonetheless, I have been assured by Microsoft that these also support concurrent reads.</p><p data-type="footnote" id="CHP-17-FN-4"><sup><a href="ch16.xhtml#CHP-17-FN-4-marker">3</a></sup> On machines with just one hardware thread, when <code>SpinLock</code> enters its loop, it tells the OS scheduler that it wants to yield control of the CPU so that other threads (hopefully including the one that currently has the lock) can make progress. <code>SpinLock</code> sometimes does this even on multicore systems to avoid some subtle problems that excessive spinning can cause.</p></div></div></section></div></body></html>