<html><head></head><body><section class="pagenumrestart" data-pdf-bookmark="Chapter 1. Concurrency: An Overview" data-type="chapter" epub:type="chapter"><div class="chapter" id="intro">&#13;
<h1><span class="label">Chapter 1. </span>Concurrency: An Overview</h1>&#13;
&#13;
&#13;
<p>Concurrency <a data-primary="concurrency" data-secondary="overview" data-type="indexterm" id="ch1over"/>is a key aspect of beautiful software. For decades, concurrency was possible but difficult to achieve. Concurrent software was difficult to write, difficult to debug, and difficult to maintain. As a result, many developers chose the easier path and avoided concurrency. With the libraries and language features available for modern .NET programs, concurrency is now much easier. Microsoft has led the way in significantly lowering the bar for concurrency. Previously, concurrent programming was the domain of experts; these days, every developer can (and should) embrace concurrency.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Introduction to Concurrency" data-type="sect1"><div class="sect1" id="idm45458718736760">&#13;
<h1>Introduction to Concurrency</h1>&#13;
&#13;
<p>Before continuing, I’d like to clear up some terminology that I’ll be using throughout this book. These are my own definitions that I use consistently to disambiguate different programming techniques. Let’s start with <em>concurrency</em>.</p>&#13;
<dl>&#13;
<dt>Concurrency</dt>&#13;
<dd>&#13;
<p>Doing more than one thing at a time.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>I hope it’s obvious how concurrency is helpful. End-user applications use concurrency to respond to user input <em>while</em> writing to a database. Server applications use concurrency to respond to a second request <em>while</em> finishing the first request. You need concurrency any time you need an application to do one thing <em>while</em> it’s working on something else. Almost every software application in the world can benefit from concurrency.</p>&#13;
&#13;
<p>Most developers hearing the term “concurrency” immediately think of “multithreading.” I’d like to draw a distinction between these two.</p>&#13;
<dl>&#13;
<dt>Multithreading</dt>&#13;
<dd>&#13;
<p>A form of concurrency that uses multiple threads of execution.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Multithreading <a data-primary="multithreading" data-seealso="thread pool" data-type="indexterm" id="idm45458718726984"/><a data-primary="threads" data-type="indexterm" id="idm45458718725976"/>refers to literally using multiple threads. As demonstrated in many recipes in this book, multithreading is <em>one</em> form of concurrency, but certainly not the only one. In fact, direct use of low-level threading types has almost no purpose in a modern application; higher-level abstractions are more powerful and more efficient than old-school multithreading. For that reason, I’ll minimize my coverage of outdated techniques. None of the multithreading recipes in this book use the <code>Thread</code> or <code>BackgroundWorker</code> types; they have been replaced with superior alternatives.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>As soon as you type <code>new Thread()</code>, it’s over; your project already has legacy code.</p>&#13;
</div>&#13;
&#13;
<p>But <a data-primary="thread pool" data-secondary="overview" data-type="indexterm" id="idm45458718721336"/>don’t get the idea that multithreading is dead! Multithreading lives on in the <em>thread pool</em>, a useful place to queue work that automatically adjusts itself according to demand. In turn, the thread pool enables another important form of concurrency: <em>parallel processing</em>.</p>&#13;
<dl>&#13;
<dt>Parallel processing</dt>&#13;
<dd>&#13;
<p>Doing <a data-primary="parallel programming" data-secondary="overview" data-type="indexterm" id="idm45458718717688"/>lots of work by dividing it up among multiple threads that run concurrently.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Parallel processing (or parallel programming) uses multithreading to maximize the use of multiple processor cores. Modern CPUs have multiple cores, and if there’s a lot of work to do, then it makes no sense to make one core do all the work while the others sit idle. Parallel processing splits the work among multiple threads, which can each run independently on a different core.</p>&#13;
&#13;
<p>Parallel processing is one type of multithreading, and multithreading is one type of concurrency. There’s another type of concurrency that is important in modern applications but isn’t as familiar to many developers: <em>asynchronous programming</em>.</p>&#13;
<dl>&#13;
<dt>Asynchronous programming</dt>&#13;
<dd>&#13;
<p>A <a data-primary="asynchronous programming" data-secondary="overview" data-type="indexterm" id="ch1aover"/><a data-primary="callbacks" data-secondary="asynchronous programming using" data-type="indexterm" id="idm45458718711528"/>form of concurrency that uses futures or callbacks to avoid unnecessary threads.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>A <em>future</em> (or <em>promise</em>) <a data-primary="futures" data-type="indexterm" id="idm45458718708680"/><a data-primary="asynchronous programming" data-secondary="futures" data-type="indexterm" id="idm45458718707944"/>is a type that represents some operation that will complete in the future. Some modern future types in .NET are <code>Task</code> and <code>Task&lt;TResult&gt;</code>. Older asynchronous APIs use callbacks or events instead of futures. Asynchronous programming is centered around the idea of an <em>asynchronous operation</em>: some operation that is started that will complete some time later. While the operation is in progress, it doesn’t block the original thread; the thread that starts the operation is free to do other work. When the operation completes, it notifies its future or invokes its callback or event to let the application know the operation is finished.</p>&#13;
&#13;
<p>Asynchronous programming is a powerful form of concurrency, but until recently, it required extremely complex code. The <code>async</code> and <code>await</code> support in modern <span class="keep-together">languages</span> make asynchronous programming almost as easy as synchronous (nonconcurrent) programming.</p>&#13;
&#13;
<p>Another <a data-primary="reactive programming" data-secondary="asynchronous events" data-type="indexterm" id="idm45458718528104"/>form of concurrency is <em>reactive programming</em>. Asynchronous programming implies that the application will start an operation that will complete once at a later time. Reactive programming is closely related to asynchronous programming but is built on <em>asynchronous events</em> instead of <em>asynchronous operations</em>. Asynchronous events may not have an actual “start,” may happen at any time, and may be raised multiple times. One example is user input.</p>&#13;
<dl>&#13;
<dt>Reactive programming</dt>&#13;
<dd>&#13;
<p>A <a data-primary="reactive programming" data-secondary="overview" data-type="indexterm" id="idm45458718523800"/>declarative style of programming where the application reacts to events.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>If you consider an application to be a massive state machine, the application’s behavior can be described as reacting to a series of events by updating its state at each event. This isn’t as abstract or theoretical as it sounds; modern frameworks make this approach quite useful in real-world applications. Reactive programming isn’t necessarily concurrent, but it is closely related to concurrency, so this book covers the basics.</p>&#13;
&#13;
<p>Usually, a mixture of techniques is used when writing a concurrent program. Most applications at least use multithreading (via the thread pool) and asynchronous programming. Feel free to mix and match all the various forms of concurrency, using the appropriate tool for each part of the <a data-startref="ch1over" data-type="indexterm" id="idm45458718520856"/>application.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Introduction to Asynchronous Programming" data-type="sect1"><div class="sect1" id="intro-async">&#13;
<h1>Introduction to Asynchronous Programming</h1>&#13;
&#13;
<p>Asynchronous <a data-primary="asynchronous programming" data-secondary="benefits of" data-type="indexterm" id="idm45458718517720"/>programming has two primary benefits. The first benefit is for end-user GUI programs: asynchronous programming enables responsiveness. Everyone has used a program that temporarily locks up while it’s working; an asynchronous program can remain responsive to user input while it’s working. The second benefit is for server-side programs: asynchronous programming enables scalability. A server application can scale somewhat just by using the thread pool, but an asynchronous server application can usually scale an order of magnitude better than that.</p>&#13;
&#13;
<p>Both benefits of asynchronous programming derive from the same underlying aspect: asynchronous programming frees up a thread. For GUI programs, asynchronous programming frees up the UI thread; this permits the GUI application to remain responsive to user input. For server applications, asynchronous programming frees up request threads; this permits the server to use its threads to serve more requests.</p>&#13;
&#13;
<p>Modern <a data-primary="async keyword" data-seealso="asynchronous programming" data-type="indexterm" id="ch1key"/><a data-primary="await keyword" data-seealso="asynchronous programming" data-type="indexterm" id="ch1key2"/>asynchronous .NET applications use two keywords: <code>async</code> and <code>await</code>. The <code>async</code> keyword is added to a method declaration, and performs a double purpose: it enables the <code>await</code> keyword within that method and it signals the compiler to generate a state machine for that method, similar to how <code>yield return</code> works. An <code>async</code> <a data-primary="tasks" data-secondary="in asynchronous programming" data-secondary-sortas="asynchronous" data-type="indexterm" id="idm45458718509240"/>method may return <code>Task&lt;TResult&gt;</code> if it returns a value, <code>Task</code> if it doesn’t return a value, or any other “task-like” type, such as <code>ValueTask</code>. In addition, an <code>async</code> method may return <code>IAsyncEnumerable&lt;T&gt;</code> or <code>IAsyncEnumerator&lt;T&gt;</code> if it returns multiple values in an enumeration. The task-like <a data-primary="futures" data-type="indexterm" id="idm45458718505224"/><a data-primary="asynchronous programming" data-secondary="futures" data-type="indexterm" id="idm45458718504440"/>types represent futures; they can notify the calling code when the <code>async</code> method completes.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Avoid<a data-primary="async keyword" data-secondary="async void" data-type="indexterm" id="idm45458718501864"/> <code>async void</code>! It is possible to have an <code>async</code> method return <code>void</code>, but you should only do this if you’re writing an <code>async</code> event handler. A regular <code>async</code> method without a return value should return <code>Task</code>, not <code>void</code>.</p>&#13;
</div>&#13;
&#13;
<p>With that background, let’s take a quick look at an example:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="k">async</code> <code class="n">Task</code> <code class="nf">DoSomethingAsync</code><code class="p">()</code>&#13;
<code class="p">{</code>&#13;
  <code class="kt">int</code> <code class="k">value</code> <code class="p">=</code> <code class="m">13</code><code class="p">;</code>&#13;
&#13;
  <code class="c1">// Asynchronously wait 1 second.</code>&#13;
  <code class="k">await</code> <code class="n">Task</code><code class="p">.</code><code class="n">Delay</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">));</code>&#13;
&#13;
  <code class="k">value</code> <code class="p">*=</code> <code class="m">2</code><code class="p">;</code>&#13;
&#13;
  <code class="c1">// Asynchronously wait 1 second.</code>&#13;
  <code class="k">await</code> <code class="n">Task</code><code class="p">.</code><code class="n">Delay</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">));</code>&#13;
&#13;
  <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="k">value</code><code class="p">);</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>An <code>async</code> method begins executing synchronously, just like any other method. Within an <code>async</code> method, the <code>await</code> keyword performs an <em>asynchronous wait</em> on its argument. First, it checks whether the operation is already complete; if it is, it continues executing (synchronously). Otherwise, it will pause the <code>async</code> method and return an incomplete task. When that operation completes some time later, the <code>async</code> method will resume executing.</p>&#13;
&#13;
<p>You can think of an <code>async</code> method as having several synchronous portions, broken up by <code>await</code> statements. The first synchronous portion executes on whatever thread calls the method, but where do the other synchronous portions execute? The answer is a bit complicated.</p>&#13;
&#13;
<p>When <a data-primary="context" data-secondary="overview" data-type="indexterm" id="ch1con2"/>you <code>await</code> a task (the most common scenario), a <em>context</em> is captured when the <code>await</code> decides to pause the method. This is the current <code>SynchronizationContext</code> unless it’s <code>null</code>, in which case the context is the current <code>TaskScheduler</code>. The method resumes executing within that captured context. Usually, this context is the UI context (if you’re on the UI thread) or the threadpool context (most other situations). If <a data-primary="ASP.NET" data-secondary="context in" data-type="indexterm" id="idm45458713831608"/>you have an ASP.NET Classic (pre-Core) application, then the context could also be an ASP.NET request context. ASP.NET Core uses the threadpool context rather than a special request context.</p>&#13;
&#13;
<p>So, in the preceding code, all the synchronous portions will attempt to resume on the original context. If you call <code>DoSomethingAsync</code> from a UI thread, each of its synchronous portions will run on that UI thread; but if you call it from a threadpool thread, each of its synchronous portions will run on any threadpool thread.</p>&#13;
&#13;
<p>You <a data-primary="ConfigureAwait method" data-type="indexterm" id="idm45458713643048"/>can avoid this default behavior by awaiting the result of the <code>ConfigureAwait</code> extension method and passing <code>false</code> for the <code>continueOnCapturedContext</code> parameter. The following code will start on the calling thread, and after it is paused by an <code>await</code>, it’ll resume on a threadpool thread:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting" id="example-async-configureawait"><code class="k">async</code> <code class="n">Task</code> <code class="nf">DoSomethingAsync</code><code class="p">()</code>&#13;
<code class="p">{</code>&#13;
  <code class="kt">int</code> <code class="k">value</code> <code class="p">=</code> <code class="m">13</code><code class="p">;</code>&#13;
&#13;
  <code class="c1">// Asynchronously wait 1 second.</code>&#13;
  <code class="k">await</code> <code class="n">Task</code><code class="p">.</code><code class="n">Delay</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">)).</code><code class="n">ConfigureAwait</code><code class="p">(</code><code class="k">false</code><code class="p">);</code>&#13;
&#13;
  <code class="k">value</code> <code class="p">*=</code> <code class="m">2</code><code class="p">;</code>&#13;
&#13;
  <code class="c1">// Asynchronously wait 1 second.</code>&#13;
  <code class="k">await</code> <code class="n">Task</code><code class="p">.</code><code class="n">Delay</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">)).</code><code class="n">ConfigureAwait</code><code class="p">(</code><code class="k">false</code><code class="p">);</code>&#13;
&#13;
  <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="k">value</code><code class="p">);</code>&#13;
<code class="p">}</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>It’s good practice to always call <code>ConfigureAwait</code> in your core “library” methods, and only resume the context when you need it—in your outer “user interface” methods.</p>&#13;
</div>&#13;
&#13;
<p>The <code>await</code> <a data-primary="awaitable types" data-type="indexterm" id="idm45458708114616"/><a data-primary="asynchronous programming" data-secondary="awaitable types" data-type="indexterm" id="idm45458708113880"/>keyword is not limited to working with tasks; it can work with any kind of <em>awaitable</em> that follows a certain pattern. As <a data-primary="Base Class library" data-type="indexterm" id="idm45458708112456"/><a data-primary="ValueTask type" data-type="indexterm" id="idm45458708111752"/>an example, the Base Class Library includes the <code>ValueTask&lt;T&gt;</code> type, which reduces memory allocations if the result is commonly synchronous; for example, if the result can be read from an in-memory cache. <code>ValueTask&lt;T&gt;</code> is not directly convertible to <code>Task&lt;T&gt;</code>, but it does follow the awaitable pattern, so you can directly <code>await</code> it. There are other examples, and you can build your own, but most of the time <code>await</code> will take a <code>Task</code> or <code>Task&lt;TResult&gt;</code>.</p>&#13;
&#13;
<p>There <a data-primary="tasks" data-secondary="creating" data-type="indexterm" id="idm45458708107496"/><a data-primary="Task.Run method" data-type="indexterm" id="idm45458708106488"/><a data-primary="Task.Factory.StartNew method" data-type="indexterm" id="idm45458708105816"/>are two basic ways to create a <code>Task</code> instance. Some tasks represent actual code that a CPU has to execute; these computational tasks should be created by calling <code>Task.Run</code> (or <code>TaskFactory.StartNew</code> if you need them to run on a particular scheduler). Other tasks represent a <em>notification</em>; these kinds of event-based tasks are created by <code>TaskCompletionSource&lt;TResult&gt;</code> (or one of its shortcuts). Most I/O tasks use <code>TaskCompletionSource&lt;TResult&gt;</code>.</p>&#13;
&#13;
<p>Error <a data-primary="error handling" data-secondary="in asynchronous programming" data-secondary-sortas="asynchronous" data-type="indexterm" id="idm45458708101784"/><a data-primary="asynchronous programming" data-secondary="error handling" data-type="indexterm" id="idm45458708100536"/>handling is natural with <code>async</code> and <code>await</code>. In the code snippet that follows, <code>PossibleExceptionAsync</code> may throw a <code>NotSupportedException</code>, but <code>TrySomethingAsync</code> can catch the exception naturally. The caught exception has its stack trace properly preserved and isn’t artificially wrapped in a <code>TargetInvocationException</code> or <code>AggregateException</code>:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting" id="example-async-exceptions"><code class="k">async</code> <code class="n">Task</code> <code class="nf">TrySomethingAsync</code><code class="p">()</code>&#13;
<code class="p">{</code>&#13;
  <code class="k">try</code>&#13;
  <code class="p">{</code>&#13;
    <code class="k">await</code> <code class="nf">PossibleExceptionAsync</code><code class="p">();</code>&#13;
  <code class="p">}</code>&#13;
  <code class="k">catch</code> <code class="p">(</code><code class="n">NotSupportedException</code> <code class="n">ex</code><code class="p">)</code>&#13;
  <code class="p">{</code>&#13;
    <code class="n">LogException</code><code class="p">(</code><code class="n">ex</code><code class="p">);</code>&#13;
    <code class="k">throw</code><code class="p">;</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>When an <code>async</code> method throws (or propagates) an exception, the exception is placed on its returned <code>Task</code> and the <code>Task</code> is completed. When that <code>Task</code> is awaited, the <code>await</code> operator will retrieve that exception and (re)throw it in a way such that its original stack trace is preserved. Thus, code such as the following example would work as expected if <code>PossibleExceptionAsync</code> was an <code>async</code> method:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting" id="example-async-exceptions-2"><code class="k">async</code> <code class="n">Task</code> <code class="nf">TrySomethingAsync</code><code class="p">()</code>&#13;
<code class="p">{</code>&#13;
  <code class="c1">// The exception will end up on the Task, not thrown directly.</code>&#13;
  <code class="n">Task</code> <code class="n">task</code> <code class="p">=</code> <code class="n">PossibleExceptionAsync</code><code class="p">();</code>&#13;
&#13;
  <code class="k">try</code>&#13;
  <code class="p">{</code>&#13;
    <code class="c1">// The Task's exception will be raised here, at the await.</code>&#13;
    <code class="k">await</code> <code class="n">task</code><code class="p">;</code>&#13;
  <code class="p">}</code>&#13;
  <code class="k">catch</code> <code class="p">(</code><code class="n">NotSupportedException</code> <code class="n">ex</code><code class="p">)</code>&#13;
  <code class="p">{</code>&#13;
    <code class="n">LogException</code><code class="p">(</code><code class="n">ex</code><code class="p">);</code>&#13;
    <code class="k">throw</code><code class="p">;</code>&#13;
  <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>There’s one other important guideline when it comes to <code>async</code> methods: once you start using <code>async</code>, it’s best to allow it to grow through your code. If you call an <code>async</code> method, you should (eventually) <code>await</code> the task it returns. Resist the temptation to call <code>Task.Wait</code>, <code>Task&lt;TResult&gt;.Result</code>, or <code>GetAwaiter().GetResult()</code>; doing so could cause a deadlock. Consider the following method:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting" id="example-async-deadlock"><code class="k">async</code> <code class="n">Task</code> <code class="nf">WaitAsync</code><code class="p">()</code>&#13;
<code class="p">{</code>&#13;
  <code class="c1">// This await will capture the current context ...</code>&#13;
  <code class="k">await</code> <code class="n">Task</code><code class="p">.</code><code class="n">Delay</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">));</code>&#13;
  <code class="c1">// ... and will attempt to resume the method here in that context.</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="k">void</code> <code class="nf">Deadlock</code><code class="p">()</code>&#13;
<code class="p">{</code>&#13;
  <code class="c1">// Start the delay.</code>&#13;
  <code class="n">Task</code> <code class="n">task</code> <code class="p">=</code> <code class="n">WaitAsync</code><code class="p">();</code>&#13;
&#13;
  <code class="c1">// Synchronously block, waiting for the async method to complete.</code>&#13;
  <code class="n">task</code><code class="p">.</code><code class="n">Wait</code><code class="p">();</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The <a data-primary="deadlocks" data-type="indexterm" id="idm45458707999816"/><a data-primary="ConfigureAwait method" data-type="indexterm" id="idm45458707932472"/><a data-primary="WaitAsync method" data-type="indexterm" id="idm45458707931864"/><a data-primary="ASP.NET" data-secondary="context in" data-type="indexterm" id="idm45458707931192"/>code in this example will deadlock if called from a UI or ASP.NET Classic context because both of those contexts only allow one thread in at a time. <code>Deadlock</code> will call <code>WaitAsync</code>, which begins the delay. <code>Deadlock</code> then (synchronously) waits for that method to complete, blocking the context thread. When the delay completes, <code>await</code> attempts to resume <code>WaitAsync</code> within the captured context, but it cannot because there’s already a thread blocked in the context, and the context only allows one thread at a time. Deadlock can be prevented two ways: you can use <code>ConfigureAwait(false)</code> within <code>WaitAsync</code> (which causes <code>await</code> to ignore its context), or you can <code>await</code> the call to <code>WaitAsync</code> (making <code>Deadlock</code> into an <code>async</code> method).</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>If you use <code>async</code>, it’s best to use <code>async</code> all the way.</p>&#13;
</div>&#13;
&#13;
<p>For <a data-startref="ch1con2" data-type="indexterm" id="idm45458707921976"/><a data-primary="online resources" data-secondary="asynchronous programming" data-type="indexterm" id="idm45458707921240"/><a data-primary="asynchronous programming" data-secondary="online resources for" data-type="indexterm" id="idm45458707920328"/>a more complete introduction to <code>async</code>, the online documentation that Microsoft has provided for <code>async</code> is fantastic; I recommend reading at least the <a href="http://bit.ly/async-prog">Asynchronous Programming overview</a> and the <a href="http://bit.ly/task-async-patt">Task-based Asynchronous Pattern (TAP)</a> overview. If you want to go a bit deeper, there’s also the <a href="http://bit.ly/async-indepth">Async in Depth</a> documentation.</p>&#13;
&#13;
<p>Asynchronous <a data-primary="asynchronous streams" data-secondary="overview" data-type="indexterm" id="idm45458707915800"/>streams take the groundwork of <code>async</code> and <code>await</code> and extend it to handle multiple values. Asynchronous streams are built around the concept of asynchronous enumerables, which are like regular enumerables, except that they enable asynchronous work to be done when retrieving the next item in the sequence. This is an extremely powerful concept that <a data-type="xref" href="ch03.html#async-streams">Chapter 3</a> covers in more detail. Asynchronous <a data-primary="asynchronous programming" data-secondary="benefits of" data-type="indexterm" id="idm45458707912680"/>streams are especially useful whenever you have a sequence of data that arrives either one at a time or in chunks. For example, if your application processes the response of an API that uses paging with <code>limit</code> and <code>offset</code> parameters, then asynchronous streams are an ideal abstraction. As of the time of this writing, asynchronous streams are only available on the newest .NET <a data-startref="ch1aover" data-type="indexterm" id="idm45458707910360"/><a data-startref="ch1key" data-type="indexterm" id="idm45458707909656"/><a data-startref="ch1key2" data-type="indexterm" id="idm45458707908984"/>platforms.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Introduction to Parallel Programming" data-type="sect1"><div class="sect1" id="idm45458718519112">&#13;
<h1>Introduction to Parallel Programming</h1>&#13;
&#13;
<p>Parallel <a data-primary="parallel programming" data-secondary="overview" data-type="indexterm" id="ch1par"/><a data-primary="parallel programming" data-secondary="benefits of" data-type="indexterm" id="idm45458707905048"/>programming should be used any time you have a fair amount of computation work that can be split up into independent chunks. Parallel programming increases the CPU usage temporarily to improve throughput; this is desirable on client systems where CPUs are often idle, but it’s usually not appropriate for server systems. Most servers have some parallelism built in; for example, ASP.NET will handle multiple requests in parallel. Writing parallel code on the server may still be useful in some situations (if you <em>know</em> that the number of concurrent users will always be low), but in general, parallel programming on the server would work against its built-in parallelism and therefore wouldn’t provide any real benefit.</p>&#13;
&#13;
<p>There <a data-primary="data parallelism" data-secondary="overview" data-type="indexterm" id="idm45458707902424"/>are two forms of parallelism: <em>data parallelism</em> and <em>task parallelism</em>. Data parallelism is when you have a bunch of data items to process, and the processing of each piece of data is mostly independent from the other pieces. Task parallelism is when you have a pool of work to do, and each piece of work is mostly independent from the other pieces. Task parallelism may be dynamic; if one piece of work results in several additional pieces of work, they can be added to the pool of work.</p>&#13;
&#13;
<p>There <a data-primary="Parallel.ForEach method" data-type="indexterm" id="idm45458707899608"/><a data-primary="Parallel.For method" data-type="indexterm" id="idm45458707898552"/><a data-primary="data parallelism" data-secondary="Parallel.ForEach method" data-type="indexterm" id="idm45458707897880"/><a data-primary="data parallelism" data-secondary="Parallel.For method" data-type="indexterm" id="idm45458707896936"/>are a few different ways to do data parallelism. <code>Parallel.ForEach</code> is similar to a <code>foreach</code> loop and should be used when possible. <code>Parallel.ForEach</code> is covered in <a data-type="xref" href="ch04.html#recipe-parallel-foreach">Recipe 4.1</a>. The <code>Parallel</code> class also supports <code>Parallel.For</code>, which is similar to a <code>for</code> loop, and can be used if the data processing depends on the index. Code that uses <code>Parallel.ForEach</code> looks like the following:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="k">void</code> <code class="nf">RotateMatrices</code><code class="p">(</code><code class="n">IEnumerable</code><code class="p">&lt;</code><code class="n">Matrix</code><code class="p">&gt;</code> <code class="n">matrices</code><code class="p">,</code> <code class="kt">float</code> <code class="n">degrees</code><code class="p">)</code>&#13;
<code class="p">{</code>&#13;
  <code class="n">Parallel</code><code class="p">.</code><code class="n">ForEach</code><code class="p">(</code><code class="n">matrices</code><code class="p">,</code> <code class="n">matrix</code> <code class="p">=&gt;</code> <code class="n">matrix</code><code class="p">.</code><code class="n">Rotate</code><code class="p">(</code><code class="n">degrees</code><code class="p">));</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Another <a data-primary="PLINQ (Parallel LINQ)" data-secondary="overview" data-type="indexterm" id="idm45458707835784"/><a data-primary="AsParallel method" data-type="indexterm" id="idm45458707834936"/><a data-primary="data parallelism" data-secondary="AsParallel method" data-type="indexterm" id="idm45458707834264"/>option is PLINQ (Parallel LINQ), which provides an <code>AsParallel</code> extension method for LINQ queries. <code>Parallel</code> is more resource friendly than PLINQ; <code>Parallel</code> will play more nicely with other processes in the system, while PLINQ will (by default) attempt to spread itself over all CPUs. The downside to <code>Parallel</code> is that it’s more explicit; PLINQ in many cases has more elegant code. PLINQ is covered in <a data-type="xref" href="ch04.html#recipe-parallel-plinq">Recipe 4.5</a> and looks like this:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="n">IEnumerable</code><code class="p">&lt;</code><code class="kt">bool</code><code class="p">&gt;</code> <code class="n">PrimalityTest</code><code class="p">(</code><code class="n">IEnumerable</code><code class="p">&lt;</code><code class="kt">int</code><code class="p">&gt;</code> <code class="n">values</code><code class="p">)</code>&#13;
<code class="p">{</code>&#13;
  <code class="k">return</code> <code class="n">values</code><code class="p">.</code><code class="n">AsParallel</code><code class="p">().</code><code class="n">Select</code><code class="p">(</code><code class="k">value</code> <code class="p">=&gt;</code> <code class="n">IsPrime</code><code class="p">(</code><code class="k">value</code><code class="p">));</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Regardless of the method you choose, one guideline stands out when doing parallel processing.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>The chunks of work should be as independent from one another as possible.</p>&#13;
</div>&#13;
&#13;
<p>As long as your chunk of work is independent from all other chunks, you maximize your parallelism. As soon as you start sharing state between multiple threads, you have to synchronize access to that shared state, and your application becomes less parallel. <a data-type="xref" href="ch12.html#synchronization">Chapter 12</a> covers synchronization in more detail.</p>&#13;
&#13;
<p>The <a data-primary="parallel programming" data-secondary="concurrent collections" data-type="indexterm" id="idm45458707780440"/><a data-primary="parallel programming" data-secondary="aggregation" data-type="indexterm" id="idm45458707779432"/><a data-primary="concurrent collections" data-type="indexterm" id="idm45458707778488"/><a data-primary="aggregation" data-type="indexterm" id="idm45458707777816"/>output of your parallel processing can be handled in various ways. You can place the results in some kind of a concurrent collection, or you can aggregate the results into a summary. Aggregation is common in parallel processing; this kind of map/reduce functionality is also supported by the <code>Parallel</code> class method overloads. <a data-type="xref" href="ch04.html#recipe-parallel-aggregate">Recipe 4.2</a> looks at aggregation in more detail.</p>&#13;
&#13;
<p>Now <a data-primary="task parallelism" data-secondary="overview" data-type="indexterm" id="idm45458707775144"/><a data-primary="parallel programming" data-secondary="task parallelism" data-type="indexterm" id="idm45458707774136"/>let’s turn to task parallelism. Data parallelism is focused on processing data; task parallelism is just about doing work. At a high level, data parallelism and task parallelism are similar; “processing data” is a kind of “work.” Many parallelism problems can be solved either way; it’s convenient to use whichever API is more natural for the problem at hand.</p>&#13;
&#13;
<p><code>Parallel.Invoke</code> is one<a data-primary="task parallelism" data-secondary="Parallel.Invoke method" data-type="indexterm" id="idm45458707772008"/><a data-primary="Parallel.Invoke method" data-type="indexterm" id="idm45458707771000"/> type of <code>Parallel</code> method that does a kind of fork/join task parallelism. This method is covered in <a data-type="xref" href="ch04.html#recipe-parallel-invoke">Recipe 4.3</a>; you just pass in the delegates you want to execute in parallel:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="k">void</code> <code class="nf">ProcessArray</code><code class="p">(</code><code class="kt">double</code><code class="p">[]</code> <code class="n">array</code><code class="p">)</code>&#13;
<code class="p">{</code>&#13;
  <code class="n">Parallel</code><code class="p">.</code><code class="n">Invoke</code><code class="p">(</code>&#13;
      <code class="p">()</code> <code class="p">=&gt;</code> <code class="n">ProcessPartialArray</code><code class="p">(</code><code class="n">array</code><code class="p">,</code> <code class="m">0</code><code class="p">,</code> <code class="n">array</code><code class="p">.</code><code class="n">Length</code> <code class="p">/</code> <code class="m">2</code><code class="p">),</code>&#13;
      <code class="p">()</code> <code class="p">=&gt;</code> <code class="n">ProcessPartialArray</code><code class="p">(</code><code class="n">array</code><code class="p">,</code> <code class="n">array</code><code class="p">.</code><code class="n">Length</code> <code class="p">/</code> <code class="m">2</code><code class="p">,</code> <code class="n">array</code><code class="p">.</code><code class="n">Length</code><code class="p">)</code>&#13;
  <code class="p">);</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="k">void</code> <code class="nf">ProcessPartialArray</code><code class="p">(</code><code class="kt">double</code><code class="p">[]</code> <code class="n">array</code><code class="p">,</code> <code class="kt">int</code> <code class="n">begin</code><code class="p">,</code> <code class="kt">int</code> <code class="n">end</code><code class="p">)</code>&#13;
<code class="p">{</code>&#13;
  <code class="c1">// CPU-intensive processing...</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The<a data-primary="parallel programming" data-secondary="tasks in" data-type="indexterm" id="idm45458707767160"/><a data-primary="tasks" data-secondary="in task parallelism" data-secondary-sortas="task" data-type="indexterm" id="idm45458707673592"/> <code>Task</code> type was originally introduced for task parallelism, though these days it’s also used for asynchronous programming. A <code>Task</code> instance—as used in task parallelism—represents some work. You can use the <code>Wait</code> method to wait for a task to complete, and you can use the <code>Result</code> and <code>Exception</code> properties to retrieve the results of that work. Code using <code>Task</code> directly is more complex than code using <code>Parallel</code>, but it can be useful if you don’t know the structure of the parallelism until runtime. With<a data-primary="dynamic parallelism" data-type="indexterm" id="idm45458707668984"/><a data-primary="parallel programming" data-secondary="dynamic parallelism" data-type="indexterm" id="idm45458707668280"/> this kind of dynamic parallelism, you don’t know how many pieces of work you need to do at the beginning of the processing; you find out as you go along. Generally, a dynamic piece of work should start whatever child tasks it needs and then wait for them to complete. The <code>Task</code> type has a special flag, <code>TaskCreationOptions.AttachedToParent</code>, which you could use for this. Dynamic parallelism is covered in <a data-type="xref" href="ch04.html#recipe-parallel-dynamicparallelism">Recipe 4.4</a>.</p>&#13;
&#13;
<p>Task parallelism should strive to be independent, just like data parallelism. The more independent your delegates can be, the more efficient your program can be. Also, if your delegates aren’t independent, then they need to be synchronized, and it’s harder to write correct code if that code needs synchronization. With task parallelism, be especially careful of variables captured in closures. Remember that closures capture references (not values), so you can end up with sharing that isn’t obvious.</p>&#13;
&#13;
<p>Error <a data-primary="error handling" data-secondary="in parallel programming" data-secondary-sortas="parallel" data-type="indexterm" id="idm45458707664136"/><a data-primary="parallel programming" data-secondary="error handling" data-type="indexterm" id="idm45458707662856"/><a data-primary="AggregateException type" data-type="indexterm" id="idm45458707661912"/>handling is similar for all kinds of parallelism. Because operations are proceeding in parallel, it’s possible for multiple exceptions to occur, so they are wrapped up in an <code>AggregateException</code> that’s thrown to your code. This behavior is consistent across <code>Parallel.ForEach</code>, <code>Parallel.Invoke</code>, <code>Task.Wait</code>, etc. The <code>AggregateException</code> type has some useful <code>Flatten</code> and <code>Handle</code> methods to simplify the error handling code:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="k">try</code>&#13;
<code class="p">{</code>&#13;
  <code class="n">Parallel</code><code class="p">.</code><code class="n">Invoke</code><code class="p">(()</code> <code class="p">=&gt;</code> <code class="p">{</code> <code class="k">throw</code> <code class="k">new</code> <code class="n">Exception</code><code class="p">();</code> <code class="p">},</code>&#13;
      <code class="p">()</code> <code class="p">=&gt;</code> <code class="p">{</code> <code class="k">throw</code> <code class="k">new</code> <code class="n">Exception</code><code class="p">();</code> <code class="p">});</code>&#13;
<code class="p">}</code>&#13;
<code class="k">catch</code> <code class="p">(</code><code class="n">AggregateException</code> <code class="n">ex</code><code class="p">)</code>&#13;
<code class="p">{</code>&#13;
  <code class="n">ex</code><code class="p">.</code><code class="n">Handle</code><code class="p">(</code><code class="n">exception</code> <code class="p">=&gt;</code>&#13;
  <code class="p">{</code>&#13;
    <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">exception</code><code class="p">);</code>&#13;
    <code class="k">return</code> <code class="k">true</code><code class="p">;</code> <code class="c1">// "handled"</code>&#13;
  <code class="p">});</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Usually, <a data-primary="thread pool" data-secondary="overview" data-type="indexterm" id="idm45458707655544"/>you don’t have to worry about how the work is handled by the thread pool. Data and task parallelism use dynamically adjusting partitioners to divide work among worker threads. The thread pool increases its thread count as necessary. The thread pool has a single work queue, and each threadpool thread also has its own work queue. When a threadpool thread queues additional work, it sends it to its own queue first because the work is usually related to the current work item; this behavior encourages threads to work on their own work, and maximizes cache hits. If another thread doesn’t have work to do, it’ll steal work from another thread’s queue. Microsoft put a lot of work into making the thread pool as efficient as possible, and there are a large number of knobs you can tweak if you need maximum performance. As long as your tasks are not extremely short, they should work well with the default settings.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Tasks should neither be extremely short, nor extremely long.</p>&#13;
</div>&#13;
&#13;
<p>If <a data-primary="task parallelism" data-secondary="length of tasks" data-type="indexterm" id="idm45458707570072"/><a data-primary="parallel programming" data-secondary="task parallelism" data-type="indexterm" id="idm45458707569064"/>your tasks are too short, then the overhead of breaking up the data into tasks and scheduling those tasks on the thread pool becomes significant. If your tasks are too long, then the thread pool cannot dynamically adjust its work balancing efficiently. It’s difficult to determine how short is too short and how long is too long; it really depends on the problem being solved and the approximate capabilities of the hardware. As a general rule, I try to make my tasks as short as possible without running into performance issues (you’ll see your performance suddenly degrade when your tasks are too short). Even better, instead of using tasks directly, use the <code>Parallel</code> type or PLINQ. These higher-level forms of parallelism have partitioning built in to handle this automatically for you (and adjust as necessary at runtime).</p>&#13;
&#13;
<p>If <a data-startref="ch1par" data-type="indexterm" id="idm45458707566328"/>you want to dive deeper into parallel programming, the best book on the subject is <em>Parallel Programming with Microsoft .NET</em>, by Colin Campbell et al. (Microsoft Press).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Introduction to Reactive Programming (Rx)" data-type="sect1"><div class="sect1" id="idm45458707907400">&#13;
<h1>Introduction to Reactive Programming (Rx)</h1>&#13;
&#13;
<p>Reactive <a data-primary="reactive programming" data-secondary="overview" data-type="indexterm" id="ch1rea"/>programming has a higher learning curve than other forms of concurrency, and the code can be harder to maintain unless you keep up with your reactive skills. If you’re willing to learn it, though, reactive programming is extremely powerful. Reactive programming enables you to treat a stream of events like a stream of data. As a rule of thumb, if you use any of the event arguments passed to an event, then your code would benefit from using System.Reactive instead of a regular event handler.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>System.Reactive used to be called Reactive Extensions, which was often shortened to “Rx.” All three of these terms refer to the same technology.</p>&#13;
</div>&#13;
&#13;
<p>Reactive <a data-primary="observable streams" data-secondary="overview" data-type="indexterm" id="idm45458707559752"/>programming is based on the notion of observable streams. When you subscribe to an observable stream, you’ll receive any number of data items (<code>OnNext</code>), and then the stream may end with a single error (<code>OnError</code>) or “end of stream” notification (<code>OnCompleted</code>). Some observable streams never end. The actual interfaces look like the following:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="k">interface</code> <code class="n">IObserver</code><code class="p">&lt;</code><code class="k">in</code> <code class="n">T</code><code class="p">&gt;</code>&#13;
<code class="p">{</code>&#13;
  <code class="k">void</code> <code class="nf">OnNext</code><code class="p">(</code><code class="n">T</code> <code class="n">item</code><code class="p">);</code>&#13;
  <code class="k">void</code> <code class="nf">OnCompleted</code><code class="p">();</code>&#13;
  <code class="k">void</code> <code class="nf">OnError</code><code class="p">(</code><code class="n">Exception</code> <code class="n">error</code><code class="p">);</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="k">interface</code> <code class="n">IObservable</code><code class="p">&lt;</code><code class="k">out</code> <code class="n">T</code><code class="p">&gt;</code>&#13;
<code class="p">{</code>&#13;
  <code class="n">IDisposable</code> <code class="nf">Subscribe</code><code class="p">(</code><code class="n">IObserver</code><code class="p">&lt;</code><code class="n">TResult</code><code class="p">&gt;</code> <code class="n">observer</code><code class="p">);</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>However, <a data-primary="reactive programming" data-secondary="compared to LINQ" data-type="indexterm" id="idm45458707440648"/><a data-primary="LINQ" data-secondary="compared to reactive programming" data-type="indexterm" id="idm45458707482968"/>you should never implement these interfaces. The System.Reactive (Rx) library by Microsoft has all the implementations you should ever need. Reactive code ends up looking very much like LINQ; you can think of it as “LINQ to Events.” System.Reactive has everything that LINQ does and adds in a large number of its own operators, particularly ones that deal with time. The following code starts with some unfamiliar operators (<code>Interval</code> and <code>Timestamp</code>) and ends with a <code>Subscribe</code>, but in the middle are some <code>Where</code> and <code>Select</code> operators that should be familiar from LINQ:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="n">Observable</code><code class="p">.</code><code class="n">Interval</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">))</code>&#13;
    <code class="p">.</code><code class="n">Timestamp</code><code class="p">()</code>&#13;
    <code class="p">.</code><code class="n">Where</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">x</code><code class="p">.</code><code class="n">Value</code> <code class="p">%</code> <code class="m">2</code> <code class="p">==</code> <code class="m">0</code><code class="p">)</code>&#13;
    <code class="p">.</code><code class="n">Select</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">x</code><code class="p">.</code><code class="n">Timestamp</code><code class="p">)</code>&#13;
    <code class="p">.</code><code class="n">Subscribe</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">x</code><code class="p">));</code></pre>&#13;
&#13;
<p>The example code starts with a counter running off a periodic timer (<code>Interval</code>) and adds a timestamp to each event (<code>Timestamp</code>). It then filters the events to only include even counter values (<code>Where</code>), selects the timestamp values (<code>Timestamp</code>), and then as each resulting timestamp value arrives, writes it to the debugger (<code>Subscribe</code>). Don’t worry if you don’t understand the new operators, such as <code>Interval</code>: these are covered later in this book. For now, just keep in mind that this is a LINQ query very similar to the ones you’re already familiar with. The main difference is that LINQ to Objects and LINQ to Entities use a <em>“pull” model</em>, where the enumeration of a LINQ query pulls the data through the query, while LINQ to Events (System.Reactive) uses a <em>“push” model</em>, where the events arrive and travel through the query by themselves.</p>&#13;
&#13;
<p>The <a data-primary="reactive programming" data-secondary="subscriptions" data-type="indexterm" id="idm45458707400568"/><a data-primary="subscriptions" data-type="indexterm" id="idm45458707399560"/>definition of an observable stream is independent from its subscriptions. The last example is the same as the following code:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="n">IObservable</code><code class="p">&lt;</code><code class="n">DateTimeOffset</code><code class="p">&gt;</code> <code class="n">timestamps</code> <code class="p">=</code>&#13;
    <code class="n">Observable</code><code class="p">.</code><code class="n">Interval</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">))</code>&#13;
        <code class="p">.</code><code class="n">Timestamp</code><code class="p">()</code>&#13;
        <code class="p">.</code><code class="n">Where</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">x</code><code class="p">.</code><code class="n">Value</code> <code class="p">%</code> <code class="m">2</code> <code class="p">==</code> <code class="m">0</code><code class="p">)</code>&#13;
        <code class="p">.</code><code class="n">Select</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">x</code><code class="p">.</code><code class="n">Timestamp</code><code class="p">);</code>&#13;
<code class="n">timestamps</code><code class="p">.</code><code class="n">Subscribe</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">x</code><code class="p">));</code></pre>&#13;
&#13;
<p>It is normal for a type to define the observable streams and make them available as an <code>IObservable&lt;TResult&gt;</code> resource. Other types can then subscribe to those streams or combine them with other operators to create another observable stream.</p>&#13;
&#13;
<p>A System.Reactive subscription is also a resource. The <code>Subscribe</code> operators return an <code>IDisposable</code> that represents the subscription. When your code is done listening to an observable stream, it should dispose its subscription.</p>&#13;
&#13;
<p>Subscriptions <a data-primary="hot observables" data-type="indexterm" id="idm45458707318264"/><a data-primary="cold observables" data-type="indexterm" id="idm45458707317528"/><a data-primary="observable streams" data-secondary="hot and cold" data-type="indexterm" id="idm45458707316856"/>behave differently with hot and cold observables. A <em>hot observable</em> is a stream of events that is always going on, and if there are no subscribers when the events come in, they are lost. For example, mouse movement is a hot observable. A <em>cold observable</em> is an observable that doesn’t have incoming events all the time. A cold observable will react to a subscription by starting the sequence of events. For example, an HTTP download is a cold observable; the subscription causes the HTTP request to be sent.</p>&#13;
&#13;
<p>The <code>Subscribe</code> <a data-primary="reactive programming" data-secondary="error handling" data-type="indexterm" id="idm45458707313656"/><a data-primary="error handling" data-secondary="in reactive programming" data-secondary-sortas="reactive" data-type="indexterm" id="idm45458707312648"/>operator should always take an error handling parameter as well. The preceding examples do not; the following is a better example that will respond appropriately if the observable stream ends in an error:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="n">Observable</code><code class="p">.</code><code class="n">Interval</code><code class="p">(</code><code class="n">TimeSpan</code><code class="p">.</code><code class="n">FromSeconds</code><code class="p">(</code><code class="m">1</code><code class="p">))</code>&#13;
    <code class="p">.</code><code class="n">Timestamp</code><code class="p">()</code>&#13;
    <code class="p">.</code><code class="n">Where</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">x</code><code class="p">.</code><code class="n">Value</code> <code class="p">%</code> <code class="m">2</code> <code class="p">==</code> <code class="m">0</code><code class="p">)</code>&#13;
    <code class="p">.</code><code class="n">Select</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">x</code><code class="p">.</code><code class="n">Timestamp</code><code class="p">)</code>&#13;
    <code class="p">.</code><code class="n">Subscribe</code><code class="p">(</code><code class="n">x</code> <code class="p">=&gt;</code> <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">x</code><code class="p">),</code>&#13;
        <code class="n">ex</code> <code class="p">=&gt;</code> <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">ex</code><code class="p">));</code></pre>&#13;
&#13;
<p><code>Subject&lt;TResult&gt;</code> is one type that is useful when experimenting with System.Reactive. This “subject” is like a manual implementation of an observable stream. Your code can call <code>OnNext</code>, <code>OnError</code>, and <code>OnCompleted</code>, and the subject will forward those calls to its subscribers. <code>Subject&lt;TResult&gt;</code> is great for experimenting, but in production code, you should strive to use operators like those covered in <a data-type="xref" href="ch06.html#rx-basics">Chapter 6</a>.</p>&#13;
&#13;
<p>There <a data-startref="ch1rea" data-type="indexterm" id="idm45458707221144"/><a data-primary="online resources" data-secondary="reactive programming" data-type="indexterm" id="idm45458707220408"/><a data-primary="reactive programming" data-secondary="online resources for" data-type="indexterm" id="idm45458707219464"/>are tons of useful System.Reactive operators, and I only cover a few selected ones in this book. For more information on System.Reactive, I recommend the excellent online book <a href="http://www.introtorx.com/"><em>Introduction to Rx</em></a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Introduction to Dataflows" data-type="sect1"><div class="sect1" id="idm45458707564696">&#13;
<h1>Introduction to Dataflows</h1>&#13;
&#13;
<p>TPL <a data-primary="dataflow" data-secondary="overview" data-type="indexterm" id="ch1df"/><a data-primary="dataflow" data-secondary="benefits of" data-type="indexterm" id="idm45458707214200"/>Dataflow is an interesting mix of asynchronous and parallel technologies. It’s useful when you have a sequence of processes that need to be applied to your data. For example, you may need to download data from a URL, parse it, and then process it in parallel with other data. TPL Dataflow is commonly used as a simple pipeline, where data enters one end and travels until it comes out the other. However, TPL Dataflow is far more powerful than this; it’s capable of handling any kind of mesh. You can define forks, joins, and loops in a mesh, and TPL Dataflow will handle them appropriately. Most<a data-primary="dataflow mesh" data-secondary="overview" data-type="indexterm" id="idm45458707212504"/> of the time, though, TPL Dataflow meshes are used as a pipeline.</p>&#13;
&#13;
<p>The <a data-primary="dataflow blocks" data-secondary="overview" data-type="indexterm" id="idm45458707210824"/><a data-primary="target block" data-type="indexterm" id="idm45458707209816"/><a data-primary="source block" data-type="indexterm" id="idm45458707209144"/>basic building unit of a dataflow mesh is a <em>dataflow block</em>. A block can either be a target block (receiving data), a source block (producing data), or both. Source blocks can be linked to target blocks to create the mesh; linking is covered in <a data-type="xref" href="ch05.html#recipe-dataflow-linking">Recipe 5.1</a>. Blocks are semi-independent; they will attempt to process data as it arrives and push the results downstream. The usual way of using TPL Dataflow is to create all the blocks, link them together, and then start putting data in at one end. The data then comes out of the other end by itself. Again, Dataflow is more powerful than this; it’s possible to break links and create new blocks and add them to the mesh <em>while</em> there is data flowing through it, but that is a very advanced scenario.</p>&#13;
&#13;
<p>Target <a data-primary="dataflow" data-secondary="buffering" data-type="indexterm" id="idm45458707205848"/>blocks have buffers for the data they receive. Having buffers enables them to accept new data items even if they aren’t ready to process them yet; this keeps data flowing through the mesh. This buffering can cause problems in fork scenarios, where one source block is linked to two target blocks. When the source block has data to send downstream, it starts offering it to its linked blocks one at a time. By default, the first target block would just take the data and buffer it, and the second target block would never get any. The fix for this situation is to limit the target block buffers by making them nongreedy; <a data-type="xref" href="ch05.html#recipe-dataflow-throttling">Recipe 5.4</a> covers this.</p>&#13;
&#13;
<p>A <a data-primary="error handling" data-secondary="in dataflow" data-secondary-sortas="dataflow" data-type="indexterm" id="idm45458707202888"/><a data-primary="dataflow" data-secondary="error handling" data-type="indexterm" id="idm45458707201608"/>block will fault when something goes wrong, for example, if the processing delegate throws an exception when processing a data item. When a block faults, it will stop receiving data. By default, it won’t take down the whole mesh; this enables you to rebuild that part of the mesh or redirect the data. However, this is an advanced scenario; most times, you want the faults to propagate along the links to the target blocks. Dataflow supports this option as well; the only tricky part is that when an exception is propagated along a link, it is wrapped in an <code>AggregateException</code>. So, if you have a long pipeline, you could end up with a deeply nested exception; the method <code>AggregateException.Flatten</code> can be used to work around this:</p>&#13;
&#13;
<pre data-code-language="csharp" data-type="programlisting"><code class="k">try</code>&#13;
<code class="p">{</code>&#13;
  <code class="kt">var</code> <code class="n">multiplyBlock</code> <code class="p">=</code> <code class="k">new</code> <code class="n">TransformBlock</code><code class="p">&lt;</code><code class="kt">int</code><code class="p">,</code> <code class="kt">int</code><code class="p">&gt;(</code><code class="n">item</code> <code class="p">=&gt;</code>&#13;
  <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="p">(</code><code class="n">item</code> <code class="p">==</code> <code class="m">1</code><code class="p">)</code>&#13;
      <code class="k">throw</code> <code class="k">new</code> <code class="nf">InvalidOperationException</code><code class="p">(</code><code class="s">"Blech."</code><code class="p">);</code>&#13;
    <code class="k">return</code> <code class="n">item</code> <code class="p">*</code> <code class="m">2</code><code class="p">;</code>&#13;
  <code class="p">});</code>&#13;
  <code class="kt">var</code> <code class="n">subtractBlock</code> <code class="p">=</code> <code class="k">new</code> <code class="n">TransformBlock</code><code class="p">&lt;</code><code class="kt">int</code><code class="p">,</code> <code class="kt">int</code><code class="p">&gt;(</code><code class="n">item</code> <code class="p">=&gt;</code> <code class="n">item</code> <code class="p">-</code> <code class="m">2</code><code class="p">);</code>&#13;
  <code class="n">multiplyBlock</code><code class="p">.</code><code class="n">LinkTo</code><code class="p">(</code><code class="n">subtractBlock</code><code class="p">,</code>&#13;
      <code class="k">new</code> <code class="n">DataflowLinkOptions</code> <code class="p">{</code> <code class="n">PropagateCompletion</code> <code class="p">=</code> <code class="k">true</code> <code class="p">});</code>&#13;
&#13;
  <code class="n">multiplyBlock</code><code class="p">.</code><code class="n">Post</code><code class="p">(</code><code class="m">1</code><code class="p">);</code>&#13;
  <code class="n">subtractBlock</code><code class="p">.</code><code class="n">Completion</code><code class="p">.</code><code class="n">Wait</code><code class="p">();</code>&#13;
<code class="p">}</code>&#13;
<code class="k">catch</code> <code class="p">(</code><code class="n">AggregateException</code> <code class="n">exception</code><code class="p">)</code>&#13;
<code class="p">{</code>&#13;
  <code class="n">AggregateException</code> <code class="n">ex</code> <code class="p">=</code> <code class="n">exception</code><code class="p">.</code><code class="n">Flatten</code><code class="p">();</code>&#13;
  <code class="n">Trace</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">ex</code><code class="p">.</code><code class="n">InnerException</code><code class="p">);</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p><a data-type="xref" href="ch05.html#recipe-dataflow-errors">Recipe 5.2</a> covers dataflow error handling in more detail.</p>&#13;
&#13;
<p>At <a data-primary="observable streams" data-secondary="compared to dataflow mesh" data-type="indexterm" id="idm45458707033240"/><a data-primary="dataflow mesh" data-secondary="compared to observable streams" data-type="indexterm" id="idm45458707032328"/>first glance, dataflow meshes sound very much like observable streams, and they do have much in common. Both meshes and streams have the concept of data items passing through them. Also, both meshes and streams have the notion of a normal completion (a notification that no more data is coming), as well as a faulting completion (a notification that some error occurred during data processing). But System.Reactive (Rx) and TPL Dataflow do not have the same capabilities. Rx observables are generally better than dataflow blocks when doing anything related to timing. Dataflow blocks are generally better than Rx observables when doing parallel processing. Conceptually, Rx works more like setting up callbacks: each step in the observable directly calls the next step. In contrast, each block in a dataflow mesh is very independent from all the other blocks. Both Rx and TPL Dataflow have their own uses, with some amount of overlap. They also work quite well together; <a data-type="xref" href="ch08.html#recipe-rx-interop-dataflow">Recipe 8.8</a> covers interoperability between Rx and TPL Dataflow.</p>&#13;
&#13;
<p>If <a data-primary="dataflow" data-secondary="compared to actor frameworks" data-type="indexterm" id="idm45458707029080"/>you’re familiar with actor frameworks, TPL Dataflow will seem to share similarities with them. Each dataflow block is independent, in the sense that it will spin up tasks to do work as needed, like executing a transformation delegate or pushing output to the next block. You can also set up each block to run in parallel, so that it’ll spin up multiple tasks to deal with additional input. Due to this behavior, each block does have a certain similarity to an actor in an actor framework. However, TPL Dataflow is not a full actor framework; in particular, there’s no built-in support for clean error recovery or retries of any kind. TPL Dataflow is a library with an actor-like feel, but it isn’t a full-featured actor framework.</p>&#13;
&#13;
<p>The most common TPL Dataflow block types are <code>TransformBlock&lt;TInput, TOutput&gt;</code> (similar to LINQ’s <code>Select</code>), <code>TransformManyBlock&lt;TInput, TOutput&gt;</code> (similar to LINQ’s <code>SelectMany</code>), and <code>ActionBlock&lt;TResult&gt;</code>, which executes a delegate for each data item. For <a data-startref="ch1df" data-type="indexterm" id="idm45458707024344"/><a data-primary="online resources" data-secondary="dataflow" data-type="indexterm" id="idm45458707023640"/><a data-primary="dataflow" data-secondary="online resources for" data-type="indexterm" id="idm45458707022696"/>more information on TPL Dataflow, I recommend the <a href="http://bit.ly/dataflow-doc">MSDN documentation</a> and the <a href="http://bit.ly/tpl-dataflow">“Guide to Implementing Custom TPL Dataflow Blocks”</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Introduction to Multithreaded Programming" data-type="sect1"><div class="sect1" id="idm45458707216824">&#13;
<h1>Introduction to Multithreaded Programming</h1>&#13;
&#13;
<p>A <em>thread</em> is <a data-primary="multithreading" data-type="indexterm" id="idm45458707017992"/><a data-primary="threads" data-type="indexterm" id="idm45458707017256"/>an independent executor. Each process has multiple threads in it, and each of those threads can be doing different things simultaneously. Each thread has its own independent stack but shares the same memory with all the other threads in a process. In some applications, there is one thread that is special. For example, user interface applications have a single special UI thread, and Console applications have a single special main thread.</p>&#13;
&#13;
<p>Every .NET <a data-primary="thread pool" data-secondary="overview" data-type="indexterm" id="idm45458707015608"/>application has a thread pool. The thread pool maintains a number of worker threads that are waiting to execute whatever work you have for them to do. The thread pool is responsible for determining how many threads are in the thread pool at any time. There are dozens of configuration settings you can play with to modify this behavior, but I recommend that you leave it alone; the thread pool has been carefully tuned to cover the vast majority of real-world scenarios.</p>&#13;
&#13;
<p>There is almost no need for you to ever create a new thread yourself. The only time you should ever create a <code>Thread</code> instance is if you need an STA thread for COM interop.</p>&#13;
&#13;
<p>A thread is a low-level abstraction. The thread pool is a slightly higher level of abstraction; when code queues work to the thread pool, the thread pool itself will take care of creating a thread if necessary. The abstractions covered in this book are higher still: parallel and dataflow processing queues work to the thread pool as necessary. Code using these higher abstractions is easier to get right than code using low-level abstractions.</p>&#13;
&#13;
<p>For this reason, the <code>Thread</code> and <code>BackgroundWorker</code> types are not covered at all in this book. They have had their time, and that time is over.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Collections for Concurrent Applications" data-type="sect1"><div class="sect1" id="idm45458707010568">&#13;
<h1>Collections for Concurrent Applications</h1>&#13;
&#13;
<p>There <a data-primary="concurrent collections" data-type="indexterm" id="idm45458707009000"/>are a couple of collection categories that are useful for concurrent programming: concurrent collections and immutable collections. Both of these collection categories are covered in <a data-type="xref" href="ch09.html#collections">Chapter 9</a>. Concurrent collections allow multiple threads to update them simultaneously in a safe way. Most <a data-primary="snapshots" data-type="indexterm" id="idm45458707007032"/>concurrent collections use <em>snapshots</em> to enable one thread to enumerate the values while another thread may be adding or removing values. Concurrent collections are usually more efficient than just protecting a regular collection with a lock.</p>&#13;
&#13;
<p>Immutable <a data-primary="immutable collections" data-secondary="overview" data-type="indexterm" id="idm45458707005208"/>collections are a bit different. An immutable collection cannot actually be modified; instead, to modify an immutable collection, you create a new collection that represents the modified collection. This sounds horribly inefficient, but immutable collections share as much memory as possible between collection instances, so it’s not as bad as it sounds. The nice thing about immutable collections is that all operations are pure, so they work very well with functional code.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Modern Design" data-type="sect1"><div class="sect1" id="idm45458707003320">&#13;
<h1>Modern Design</h1>&#13;
&#13;
<p>Most <a data-primary="concurrency" data-secondary="functional programming design for" data-type="indexterm" id="idm45458707001576"/><a data-primary="functional programming" data-type="indexterm" id="idm45458707000600"/>concurrent technologies have one similar aspect: they are functional in nature. I don’t mean <em>functional</em> as in “they get the job done,” but rather <em>functional</em> as a style of programming that is based on function composition. If you adopt a functional mindset, your concurrent designs will be less convoluted.</p>&#13;
&#13;
<p>One <a data-primary="purity, in functional programming" data-type="indexterm" id="idm45458706998024"/>principle of functional programming is <em>purity</em> (that is, avoiding side effects). Each piece of the solution takes some value(s) as input and produces some value(s) as output. As much as possible, you should avoid having these pieces depend on global (or shared) variables or update global (or shared) data structures. This is true whether the piece is an <code>async</code> method, a parallel task, a System.Reactive operation, or a dataflow block. Of course, sooner or later your computations will have to have an effect, but you’ll find your code is cleaner if you can handle the <em>processing</em> with pure pieces and then perform updates with the <em>results</em>.</p>&#13;
&#13;
<p>Another <a data-primary="immutability, in functional programming" data-type="indexterm" id="idm45458706994632"/>principle of functional programming is <em>immutability</em>. Immutability means that a piece of data cannot change. One reason that immutable data is useful for concurrent programs is that you never need synchronization for immutable data; the fact that it cannot change makes synchronization unnecessary. Immutable data also helps you avoid side effects. Developers are beginning to use more immutable types, and this book has several recipes covering immutable data structures.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="orm:non-recipe" data-pdf-bookmark="Summary of Key Technologies" data-type="sect1"><div class="sect1" id="idm45458706992808">&#13;
<h1>Summary of Key Technologies</h1>&#13;
&#13;
<p>The .NET framework<a data-primary="asynchronous programming" data-secondary="platform support for" data-type="indexterm" id="idm45458706990776"/><a data-primary=".NET platforms, support for" data-primary-sortas="NET platforms" data-type="indexterm" id="idm45458706989752"/><a data-primary="platform support" data-secondary="current" data-type="indexterm" id="idm45458706988792"/> has had some support for asynchronous programming since the very beginning. However, asynchronous programming was difficult until 2012, when .NET 4.5 (along with C# 5.0 and VB 2012) introduced the <code>async</code> and <code>await</code> keywords. This book will use the modern <code>async</code>/<code>await</code> approach for all asynchronous recipes, and it has some recipes showing how to interoperate between <code>async</code> and the older asynchronous programming patterns. If you need support for older platforms, see <a data-type="xref" href="app01.html#legacy-platform-support">Appendix A</a>.</p>&#13;
&#13;
<p>The<a data-primary="parallel programming" data-secondary="platform support for" data-type="indexterm" id="idm45458706984040"/><a data-primary="TPL (Task Parallel Library)" data-type="indexterm" id="idm45458706983032"/><a data-primary="parallel programming" data-secondary="Task Parallel Library" data-type="indexterm" id="idm45458706982392"/> Task Parallel Library was introduced in .NET 4.0 with full support for both data and task parallelism. These days, it’s available even on platforms with fewer resources, such as mobile phones. The TPL is built in to .NET.</p>&#13;
&#13;
<p>The<a data-primary="online resources" data-secondary="libraries" data-seealso="specific library names" data-type="indexterm" id="idm45458706980472"/><a data-primary="libraries" data-seealso="specific library names" data-type="indexterm" id="idm45458706979192"/><a data-primary="reactive programming" data-secondary="platform support for" data-type="indexterm" id="idm45458706978248"/><a data-primary="System.Reactive library" data-type="indexterm" id="idm45458706977304"/><a data-primary="reactive programming" data-secondary="System.Reactive library" data-type="indexterm" id="idm45458706976632"/> System.Reactive team has worked hard to support as many platforms as possible. System.Reactive, like <code>async</code> and <code>await</code>, provide benefits for all sorts of applications, both client and server. System.Reactive is available in the <a href="http://bit.ly/sys-reactive"><code>System.Reactive</code></a> NuGet package.</p>&#13;
&#13;
<p>The<a data-primary="dataflow" data-secondary="platform support for" data-type="indexterm" id="idm45458706973384"/><a data-primary="TPL Dataflow library" data-type="indexterm" id="idm45458706972376"/><a data-primary="dataflow" data-secondary="TPL Dataflow library" data-type="indexterm" id="idm45458706971704"/> TPL Dataflow library is officially distributed within the NuGet package for <a href="http://bit.ly/nuget-df"><code>System.Threading.Tasks.Dataflow</code></a>.</p>&#13;
&#13;
<p>Most <a data-primary="collections" data-secondary="libraries for" data-type="indexterm" id="idm45458706969208"/><a data-primary="concurrent collections" data-type="indexterm" id="idm45458706968200"/><a data-primary="immutable collections" data-secondary="libraries for" data-type="indexterm" id="idm45458706967528"/><a data-primary="System.Threading.Channels library" data-type="indexterm" id="idm45458706966584"/><a data-primary="System.Collections.Immutable library" data-type="indexterm" id="idm45458706965944"/>concurrent collections are built into .NET; there are some additional concurrent collections available in the <a href="https://www.nuget.org/packages/System.Threading.Channels"><code>System.Threading.Channels</code></a> NuGet package. Immutable collections are available in the <a href="http://bit.ly/sys-coll-imm"><code>System.Collections.Immutable</code></a> NuGet package.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>