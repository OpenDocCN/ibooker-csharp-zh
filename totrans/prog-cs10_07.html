<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 7. Object Lifetime" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch_object_lifetime">
<h1><span class="label">Chapter 7. </span>Object Lifetime</h1>
<p><a data-primary="object lifetime" data-type="indexterm" id="ix_ch07-asciidoc0"/>One benefit of .NET’s managed execution model is that the runtime can automate most of your application’s memory management. I have shown numerous examples that create objects with the <code>new</code> keyword, and none has explicitly freed the memory consumed by these objects.</p>
<p><a data-primary="CLR (Common Language Runtime)" data-secondary="GC and" data-type="indexterm" id="idm45884816424416"/>In most cases, you do not need to take any action to reclaim memory. The runtime provides a <em>garbage collector</em> (GC),<sup><a data-type="noteref" href="ch07.xhtml#CHP-7-FN-1" id="CHP-7-FN-1-marker">1</a></sup> a mechanism that automatically discovers when objects are no longer in use and recovers the memory they had been occupying so that it can be used for new objects. However, there are certain usage patterns that can cause performance issues or even defeat the GC entirely, so it’s useful to understand how it works. This is particularly important with long-running processes that could run for days (short-lived processes may be able to tolerate a few memory leaks).</p>
<p>The GC is designed to manage memory efficiently, but memory is not the only limited resource you may need to deal with. Some things have a small memory footprint in the CLR but represent something relatively expensive, such as a database connection or a handle from an OS API. The GC doesn’t always deal with these effectively, so I’ll explain <code>IDisposable</code>, the interface designed for dealing with things that need to be freed more urgently than memory.</p>
<p>Value types often have completely different rules governing their lifetime—some local variable values live only for as long as their containing method runs, for example. Nonetheless, value types sometimes end up acting like reference types and being managed by the GC. I will discuss why that can be useful, and I will explain the <em>boxing</em> mechanism that makes it possible.</p>
<section data-pdf-bookmark="Garbage Collection" data-type="sect1"><div class="sect1" id="garbage_collection">
<h1>Garbage Collection</h1>
<p><a data-primary="garbage collector/garbage collection (GC)" data-type="indexterm" id="ix_ch07-asciidoc1"/><a data-primary="object lifetime" data-secondary="garbage collection" data-type="indexterm" id="ix_ch07-asciidoc2"/>The <a data-primary="garbage collector/garbage collection (GC)" data-secondary="about" data-type="indexterm" id="ix_ch07-asciidoc3"/>CLR maintains a <a data-primary="heap" data-secondary="defined" data-type="indexterm" id="idm45884816412480"/><em>heap</em>, a service that provides memory for the objects and values whose lifetime is managed by the GC. Each time you construct an instance of a class with <code>new</code>, or you create a new array object, the CLR allocates a new heap block. The GC decides when to deallocate that block.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you are writing a .NET application that runs on an Android device using .NET’s Xamarin tools, there will be two garbage collected heaps: one for .NET and one for Java. Normal C# activity in Xamarin applications uses the .NET heap, so Java’s heap only enters the picture if you write C# code that uses Xamarin’s services for manipulating Java objects. This is a .NET book, so I will be focusing on the .NET GC.</p>
</div>
<p><a data-primary="fields" data-secondary="GC and" data-type="indexterm" id="idm45884816408992"/>A heap block contains all the nonstatic fields for an object, or all the elements if it’s an array. The CLR also adds a header, which is not directly visible to your program. This includes a pointer to a structure describing the object’s type. This supports operations that depend on the real type of an object. For example, if you call <code>GetType</code> on a reference, the runtime uses this pointer to find out the type. (The type is often not completely determined by the static type of the reference, which could be an interface type or a base class of the actual type.) It’s also used to work out which method to use when you invoke a virtual method or an interface member. The CLR also uses this to know how large the heap block is—the header does not include the block size, because the runtime can work that out from the object’s type. (Most types are fixed size. There are only two exceptions, strings and arrays, which the CLR handles as special cases.) The header contains one other field, which is used for a variety of diverse purposes, including multithreaded synchronization and default hash code generation. Heap block headers are just an implementation detail, and different runtimes could choose different strategies.<sup><a data-type="noteref" href="ch07.xhtml#idm45884816407152" id="idm45884816407152-marker">2</a></sup> However, it’s useful to know what the overhead is. On a 32-bit system, the header is 8 bytes long, and if you’re running in a 64-bit process, it takes 16 bytes. So an object that contained just one field of type <code>double</code> (an 8-byte type) would consume 16 bytes in a 32-bit process, and 24 bytes in a 64-bit process.</p>
<p>Although objects (i.e., instances of a class) always live on the heap, instances of value types are different: some live on the heap, and some don’t.<sup><a data-type="noteref" href="ch07.xhtml#idm45884816405152" id="idm45884816405152-marker">3</a></sup> The CLR stores some value-typed local variables on the stack, for example, but if the value is in an instance field of a class, the class instance will live on the heap, and that value will therefore live inside that object on the heap. And in some cases, a value will have an entire heap block to itself.</p>
<p>If you’re using something through a reference type variable, then you are accessing something on the heap. It’s important to clarify exactly what I mean by a reference type variable, because unfortunately, the terminology is a little confusing here: <a data-primary="references" data-secondary="in C# context" data-type="indexterm" id="idm45884816402784"/>C# uses the term <em>reference</em> to describe two quite different things. For the purposes of this discussion, a reference is something you can store in a variable of a type that derives from <code>object</code> (but not from <code>ValueType</code>) or that is an interface type. This does not include every <code>in</code>-, <code>out</code>-, or <code>ref</code>-style method argument, nor <code>ref</code> variables or returns. Although those are references of a kind, a <code>ref int</code> argument is a reference to a value type, and that’s not the same thing as a reference type. (The CLR actually uses a different term than C# for the mechanism that supports <code>ref</code>, <code>in</code>, and <code>out</code>: it calls these <em>managed pointers</em>, making it clear that they are rather different from object references.)</p>
<p>The managed execution model used by C# (and all .NET languages) means the CLR knows about every heap block your code creates, and also about every field, variable, and array element in which your program stores references. <a data-primary="reachability" data-secondary="defined" data-type="indexterm" id="idm45884816395376"/>This information enables the runtime to determine at any time which objects are <em>reachable</em>—that is, those that the program could conceivably get access to in order to use its fields and other members. If an object is not reachable, then by definition the program will never be able to use it again. To illustrate how the CLR determines reachability, I’ve written a simple method that fetches web pages from my employer’s website, shown in <a data-type="xref" href="#using_and_discarding_objects">Example 7-1</a>.<a data-primary="HttpClient class" data-type="indexterm" id="idm45884816392576"/></p>
<div data-type="example" id="using_and_discarding_objects">
<h5><span class="label">Example 7-1. </span>Using and discarding objects</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">static</code> <code class="kt">string</code> <code class="nf">FetchUrl</code><code class="p">(</code><code class="kt">string</code> <code class="n">relativeUri</code><code class="p">)</code>
<code class="p">{</code>
    <code class="kt">var</code> <code class="n">baseUri</code> <code class="p">=</code> <code class="k">new</code> <code class="n">Uri</code><code class="p">(</code><code class="s">"https://endjin.com/"</code><code class="p">);</code>
    <code class="kt">var</code> <code class="n">fullUri</code> <code class="p">=</code> <code class="k">new</code> <code class="n">Uri</code><code class="p">(</code><code class="n">baseUri</code><code class="p">,</code> <code class="n">relativeUri</code><code class="p">);</code>
    <code class="kt">var</code> <code class="n">w</code> <code class="p">=</code> <code class="k">new</code> <code class="n">HttpClient</code><code class="p">();</code>
    <code class="n">HttpResponseMessage</code> <code class="n">response</code> <code class="p">=</code> <code class="n">w</code><code class="p">.</code><code class="n">Send</code><code class="p">(</code>
        <code class="k">new</code> <code class="nf">HttpRequestMessage</code><code class="p">(</code><code class="n">HttpMethod</code><code class="p">.</code><code class="n">Get</code><code class="p">,</code> <code class="n">fullUri</code><code class="p">));</code>
    <code class="k">return</code> <code class="k">new</code> <code class="nf">StreamReader</code><code class="p">(</code><code class="n">response</code><code class="p">.</code><code class="n">Content</code><code class="p">.</code><code class="n">ReadAsStream</code><code class="p">()).</code><code class="n">ReadToEnd</code><code class="p">();</code>
<code class="p">}</code></pre></div>
<p>The CLR analyzes the way in which we use local variables and method arguments. For example, although the <code>relativeUri</code> argument is in scope for the whole method, we use it just once as an argument when constructing the second <code>Uri</code> and then never use it again. A variable is described as <em>live</em> from the first point at which it receives a value up until the last point at which it is used. Method arguments are live from the start of the method until their final usage, unless they are unused, in which case they are never live. Local variables become live later; <code>baseUri</code> becomes live once it has been assigned its initial value and then ceases to be live with its final usage, which in this example, happens at the same point as <code>relativeUri</code>. Liveness is an important property in determining whether a particular object is still in use.</p>
<p>To see the role that liveness plays, suppose that when <a data-type="xref" href="#using_and_discarding_objects">Example 7-1</a> reaches the line that constructs the <code>HttpClient</code>, the CLR doesn’t have enough free memory to hold the new object. It could request more memory from the OS at this point, but it also has the option to try to free up memory from objects that are no longer in use, meaning that our program wouldn’t need to consume more memory than it’s already using.<sup><a data-type="noteref" href="ch07.xhtml#CHP-7-FN-2" id="CHP-7-FN-2-marker">4</a></sup> The next section describes the process that the CLR uses when it takes that second option.<a data-startref="ix_ch07-asciidoc3" data-type="indexterm" id="idm45884816295040"/></p>
<section data-pdf-bookmark="Determining Reachability" data-type="sect2"><div class="sect2" id="determining_reachability">
<h2>Determining Reachability</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="determining reachability" data-type="indexterm" id="ix_ch07-asciidoc4"/><a data-primary="reachability" data-secondary="determining" data-type="indexterm" id="ix_ch07-asciidoc5"/>.NET’s basic approach is to determine which of the objects on the heap are reachable. If there’s no way for a program to get hold of some object, it can safely be discarded. The CLR starts by determining all of the <a data-primary="root references" data-type="indexterm" id="idm45884816275136"/><em>root references</em> in your program. A <em>root</em> is a storage location, such as a local variable, that could contain a reference and is known to have been initialized, and that your program could use at some point in the future without needing to go via some other object reference. Not all storage locations are considered to be roots. If an object contains an instance field of some reference type, that field is not a root, because before you can use it, you’d need to get hold of a reference to the containing object, and it’s possible that the object itself is not reachable. However, a reference type static field is a root reference, because the program can read the value in that field at any time—the only situation in which that field will become inaccessible in the future is when the component that defines the type is unloaded, which in most cases will be when the program exits.</p>
<p>Local variables and method arguments are more interesting. Sometimes they are roots but sometimes not. It depends on exactly which part of the method is currently executing. A local variable or argument can be a root only if the flow of execution is currently inside the region in which that variable or argument is live. So, in <a data-type="xref" href="#using_and_discarding_objects">Example 7-1</a>, <code>baseUri</code> is a root reference only after it has had its initial value assigned and before the call to construct the second <code>Uri</code>, which is a rather narrow window. The <code>fullUri</code> variable is a root reference for slightly longer, because it becomes live after receiving its initial value and continues to be live during the construction of the <code>HttpClient</code> on the following line; its liveness ends only once <code>HttpRequestMessage</code> constructor has been called.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>When a variable’s last use is as an argument in a method or constructor invocation, it ceases to be live when the method call begins. At that point, the method being called takes over—its own arguments are live at the start (except for arguments it does not use). However, they will typically cease to be live before the method returns. This means that in <a data-type="xref" href="#using_and_discarding_objects">Example 7-1</a>, the object referred to by <code>fullUri</code> may cease to be accessible through root references before the <code>HttpRequestMessage</code> constructor returns.</p>
</div>
<p>Since the set of live variables changes as the program executes, the set of root references also evolves. To guarantee correct behavior in the face of this moving target, the CLR can suspend all threads that are running managed code when necessary during garbage collection.</p>
<p>Live variables and static fields are not the only kinds of roots. Temporary objects created as a result of evaluating expressions need to stay alive for as long as necessary to complete the evaluation, so there can be some root references that don’t correspond directly to any named entities in your code. And there are other types of root. For example, the <code>GCHandle</code> class lets you create new roots explicitly, which can be useful in interop scenarios to enable some unmanaged code to get access to a particular object. There are also situations in which roots are created implicitly. <a data-primary="COM (Component Object Model)" data-type="indexterm" id="idm45884816265088"/><a data-primary="Component Object Model (COM)" data-type="indexterm" id="idm45884816264416"/>Certain kinds of applications can interoperate with non-.NET object-based systems (e.g., COM in Windows applications, or Java on Android), which can establish root references without explicit use of <code>GCHandle</code>—if the CLR needs to generate a wrapper making one of your .NET objects available to some other runtime, that wrapper will effectively be a root reference. Calls into unmanaged code may also involve passing pointers to memory on the heap, which will mean that the relevant heap block needs to be treated as reachable for the duration of the call. The broad principle is that roots will exist where necessary to ensure that objects that are still in use remain reachable.</p>
<p>Having built up a complete list of current root references for all threads, the GC works out which objects can be reached from these references. It looks at each reference in turn, and if non-null, the GC knows that the object it refers to is reachable. There may be duplicates—multiple roots may refer to the same object, so the GC keeps track of which objects it has already seen. For each newly discovered object, the GC adds all of the instance fields of reference type in that object to the list of references it needs to look at, again discarding  duplicates. (This includes hidden fields generated by the compiler, such as those for automatic properties, which I described in <a data-type="xref" href="ch03.xhtml#ch_types">Chapter 3</a>.) It does the same for each element of any reference-typed arrays it discovers. This means that if an object is reachable, so are all the objects to which it holds references. The GC repeats this process until it runs out of new references to examine. Any objects that it has <em>not</em> discovered to be reachable must be unreachable, because the GC is simply doing what the program does: a program can use only objects that are accessible either directly or indirectly through its variables, temporary local storage, static fields, and other roots.</p>
<p>Going back to <a data-type="xref" href="#using_and_discarding_objects">Example 7-1</a>, what would all this mean if the CLR decides to run the GC when we construct the <code>HttpClient</code>? The <code>fullUri</code> variable is still live, so the <code>Uri</code> it refers to is reachable, but the <code>baseUri</code> is no longer live. We did pass a copy of <code>baseUri</code> into the constructor for the second <code>Uri</code>, and if that had stored a copy of the reference in a field, then it wouldn’t matter that <code>baseUri</code> is not live; as long as there’s some way to get to an object by starting from a root reference, then the object is reachable. But as it happens, the second <code>Uri</code> won’t do that, so the first <code>Uri</code> the example allocates would be deemed to be unreachable, and the CLR would be free to recover the memory it had been using.</p>
<p>One important upshot of how reachability is determined is that the GC is unfazed by circular references. This is one reason .NET uses GC instead of reference counting (another popular approach for automating memory management). If you have two objects that refer to each other, a reference counting scheme will consider both objects to be in use, because each is referred to at least once. But the objects may be unreachable—if there are no other references to the objects, the application will not have any way to use them. Reference counting fails to detect this, so it could cause memory leaks, but with the scheme used by the CLR’s GC, the fact that they refer to each other is irrelevant—the GC will never get to either of them, so it will correctly determine that they are no longer in use.<a data-startref="ix_ch07-asciidoc5" data-type="indexterm" id="idm45884816255200"/><a data-startref="ix_ch07-asciidoc4" data-type="indexterm" id="idm45884816254496"/></p>
</div></section>
<section data-pdf-bookmark="Accidentally Defeating the Garbage Collector" data-type="sect2"><div class="sect2" id="accidentally_defeating_the_gc">
<h2>Accidentally Defeating the Garbage Collector</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="accidentally defeating the garbage collector" data-type="indexterm" id="ix_ch07-asciidoc6"/>Although the GC can discover ways that your program could reach an object, it has no way to prove that it necessarily will. Take the impressively idiotic piece of code in <a data-type="xref" href="#an_appallingly_inefficient_piece_of_code">Example 7-2</a>. Although you’d never write code this bad, it makes a common mistake. It’s a problem that usually crops up in more subtle ways, but I want to show it in a more obvious example first. Once I’ve shown how it prevents the GC from freeing objects that we’re not going to be using, I’ll describe a less straightforward but more realistic scenario in which this same problem often occurs.</p>
<div data-type="example" id="an_appallingly_inefficient_piece_of_code">
<h5><span class="label">Example 7-2. </span>An appallingly inefficient piece of code</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">static</code> <code class="k">void</code> <code class="nf">Main</code><code class="p">()</code>
<code class="p">{</code>
    <code class="kt">var</code> <code class="n">numbers</code> <code class="p">=</code> <code class="k">new</code> <code class="n">List</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">&gt;();</code>
    <code class="kt">long</code> <code class="n">total</code> <code class="p">=</code> <code class="m">0</code><code class="p">;</code>
    <code class="k">for</code> <code class="p">(</code><code class="kt">int</code> <code class="n">i</code> <code class="p">=</code> <code class="m">1</code><code class="p">;</code> <code class="n">i</code> <code class="p">&lt;</code> <code class="m">100_000</code><code class="p">;</code> <code class="p">++</code><code class="n">i</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">numbers</code><code class="p">.</code><code class="n">Add</code><code class="p">(</code><code class="n">i</code><code class="p">.</code><code class="n">ToString</code><code class="p">());</code>
        <code class="n">total</code> <code class="p">+=</code> <code class="n">i</code><code class="p">;</code>
    <code class="p">}</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Total: {total}, average: {total / numbers.Count}"</code><code class="p">);</code>
<code class="p">}</code></pre></div>
<p>This adds together the numbers from 1 to 100,000 and then displays their average. The first mistake here is that we don’t even need to do the addition in a loop, because there’s a simple and very well-known closed-form solution for this sort of sum: <code>n*(n+1)/2</code>, with <code>n</code> being 100,000 in this case. That mathematical gaffe notwithstanding, this code does something even more stupid: it builds up a list containing every number it adds, <a data-primary="Count property" data-secondary="garbage collection" data-type="indexterm" id="idm45884816168416"/>but all it does with that list is retrieve its <code>Count</code> property to calculate an average at the end. Just to make things worse, the code converts each number into a string before putting it in the list. It never actually uses those strings. (I’ve shown the <code>Main</code> method declaration here to make it clear that <code>numbers</code> isn’t used later on.)</p>
<p>Obviously, this is a contrived example, although I wish I could say I’d never encountered anything this bafflingly pointless in real programs. Sadly, I’ve come across genuine examples at least this bad, although they were all better obfuscated—when you encounter this sort of thing in the wild, it normally takes half an hour or so to work out that it really is doing something as staggeringly pointless as this. However, my point here is not to lament standards of software development. The purpose of this example is to show how you can run into a limitation of the GC.</p>
<p>Suppose the loop in <a data-type="xref" href="#an_appallingly_inefficient_piece_of_code">Example 7-2</a> has been running for a while—perhaps it’s on its 90,000th iteration and is trying to add an entry to the <code>numbers</code> list. Suppose that the <code>List&lt;string&gt;</code> has used up its spare capacity, and the <code>Add</code> method will therefore need to allocate a new, larger internal array. The CLR may decide at this point to run the GC to see if it can free up some space. What will happen?</p>
<p><a data-type="xref" href="#an_appallingly_inefficient_piece_of_code">Example 7-2</a> creates three kinds of objects: it constructs a <code>List&lt;string&gt;</code> at the start, it creates a new <code>string</code> each time around the loop by calling <code>ToString()</code> on an <code>int</code>, and more subtly, the <code>List&lt;string&gt;</code> will allocate a <code>string[]</code> to hold references to those strings. Because we keep adding new items, it will have to allocate larger and larger arrays. (That array is an implementation detail of <code>List&lt;string&gt;</code>, so we can’t see it directly.) So the question is: Which of these objects can the GC discard to make space for a larger array in the call to <code>Add</code>?</p>
<p>Our <code>numbers</code> variable remains live until the program’s final statement, and we’re looking at an earlier point in the code, so the <code>List&lt;string&gt;</code> object it refers to is reachable. The <code>string[]</code> array object it is currently using must also be reachable: it’s allocating a newer, larger one, but it will need to copy the contents of the old one across to the new one, so the list must still have a reference to that current array stored in one of its fields. Since that array is still reachable, every string the array refers to will also be reachable. Our program has created 90,000 strings so far, and the GC will find all of them by starting at our <code>numbers</code> variable, looking at the fields of the <code>List&lt;string&gt;</code> object that refers to, and then looking at every element in the array that one of the list’s private fields refers to.</p>
<p>The only allocated items that the GC might be able to collect are old <code>string[]</code> arrays that the <code>List&lt;string&gt;</code> created back when the list was smaller and that it no longer has a reference to. By the time we’ve added 90,000 items, the list will probably have resized itself quite a few times. So depending on when the GC last ran, it will probably be able to find a few of these now-unused arrays. But more interesting here is what it cannot free.</p>
<p>The program will never use any of the 90,000 strings it has created, so ideally, we’d like the GC to free up the memory they occupy—they will be taking up a few megabytes. We can see very easily that these strings are not used, because this is such a short program. But the GC will not know that; it bases its decisions on reachability, and it correctly determines that all 90,000 strings are reachable by starting at the <code>numbers</code> variable. <a data-primary="Count property" data-secondary="garbage collection" data-type="indexterm" id="idm45884816138976"/>And as far as the GC is concerned, it’s entirely possible that the list’s <code>Count</code> property, which we use after the loop finishes, will look at the contents of the list. You and I happen to know that it won’t, because it doesn’t need to, but that’s because we know what the <code>Count</code> property means. For the GC to infer that our program will never use any of the list’s elements directly or indirectly, it would need to know what <code>List&lt;string&gt;</code> does inside its <code>Add</code> and <code>Count</code> methods. This would mean analysis with a level of detail far beyond the mechanisms I’ve described, which could make GCs considerably more expensive. Moreover, even with the serious step up in complexity required to detect which reachable objects this example will never use, in more realistic scenarios the GC is unlikely to be able to make predictions that were significantly better than relying on reachability alone.</p>
<p>For example, a much more plausible way to run into this problem is in a cache. If you write a class that caches data that is expensive to fetch or calculate, imagine what would happen if your code only ever added items to the cache and never removed them. All of the cached data would be reachable for as long as the cache object itself is reachable. The problem is that your cache will consume more and more space, and unless your computer has sufficient memory to hold every piece of data that your program could conceivably need to use, it will eventually run out of memory.</p>
<p>A naive developer might complain that this is supposed to be the GC’s problem. The whole point of GC is meant to be that I don’t need to think about memory management, so why am I running out of memory all of a sudden? But, of course, the problem is that the GC has no way of knowing which objects are safe to remove. Not being clairvoyant, it cannot accurately predict which cached items your program may need in the future—if the code is running in a server, future cache usage could depend on what requests the server receives, something the GC cannot predict. So although it’s possible to imagine memory management smart enough to analyze something as simple as <a data-type="xref" href="#an_appallingly_inefficient_piece_of_code">Example 7-2</a>, in general, this is not a problem the GC can solve. Thus, if you add objects to collections and keep those collections reachable, the GC will treat everything in those collections as being reachable. It’s your job to decide when to remove items.</p>
<p>Collections are not the only situation in which you can fool the GC. As I’ll show in <a data-type="xref" href="ch09.xhtml#ch_delegates_lambdas_events">Chapter 9</a>, there’s a common scenario in which careless use of events can cause memory leaks. More generally, if your program makes it possible for an object to be reached, the GC has no way of working out whether you’re going to use that object again, so it has to be conservative.</p>
<p>That said, there is a technique for mitigating this with a little help from the GC.<a data-startref="ix_ch07-asciidoc6" data-type="indexterm" id="idm45884816132096"/></p>
</div></section>
<section data-pdf-bookmark="Weak References" data-type="sect2"><div class="sect2" id="weak_references">
<h2>Weak References</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="weak references" data-type="indexterm" id="ix_ch07-asciidoc7"/><a data-primary="weak references" data-type="indexterm" id="ix_ch07-asciidoc8"/>Although the GC will follow ordinary references in a reachable object’s fields, it is possible to hold a <em>weak reference</em>. The GC does not follow weak references, so if the only way to reach an object is through weak references, the GC behaves as though the object is not reachable and will remove it. A weak reference provides a way of telling the CLR, “Do not keep this object around on my account, but for as long as something else needs it, I would like to be able to get access to it.” <a data-type="xref" href="#using_weak_references_in_a_cache">Example 7-3</a> shows a cache that uses <code>WeakReference&lt;T&gt;</code>.</p>
<div data-type="example" id="using_weak_references_in_a_cache">
<h5><span class="label">Example 7-3. </span>Using weak references in a cache</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">WeakCache</code><code class="p">&lt;</code><code class="n">TKey</code><code class="p">,</code> <code class="n">TValue</code><code class="p">&gt;</code>
    <code class="k">where</code> <code class="n">TKey</code> <code class="p">:</code> <code class="n">notnull</code>
    <code class="k">where</code> <code class="n">TValue</code> <code class="p">:</code> <code class="k">class</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">readonly</code> <code class="n">Dictionary</code><code class="p">&lt;</code><code class="n">TKey</code><code class="p">,</code> <code class="n">WeakReference</code><code class="p">&lt;</code><code class="n">TValue</code><code class="p">&gt;&gt;</code> <code class="n">_cache</code> <code class="p">=</code> <code class="k">new</code> <code class="p">();</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Add</code><code class="p">(</code><code class="n">TKey</code> <code class="n">key</code><code class="p">,</code> <code class="n">TValue</code> <code class="k">value</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">_cache</code><code class="p">.</code><code class="n">Add</code><code class="p">(</code><code class="n">key</code><code class="p">,</code> <code class="k">new</code> <code class="n">WeakReference</code><code class="p">&lt;</code><code class="n">TValue</code><code class="p">&gt;(</code><code class="k">value</code><code class="p">));</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="kt">bool</code> <code class="nf">TryGetValue</code><code class="p">(</code>
        <code class="n">TKey</code> <code class="n">key</code><code class="p">,</code> <code class="p">[</code><code class="n">NotNullWhen</code><code class="p">(</code><code class="k">true</code><code class="p">)]</code> <code class="k">out</code> <code class="n">TValue</code><code class="p">?</code> <code class="n">cachedItem</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">_cache</code><code class="p">.</code><code class="n">TryGetValue</code><code class="p">(</code><code class="n">key</code><code class="p">,</code> <code class="k">out</code> <code class="n">WeakReference</code><code class="p">&lt;</code><code class="n">TValue</code><code class="p">&gt;?</code> <code class="n">entry</code><code class="p">))</code>
        <code class="p">{</code>
            <code class="kt">bool</code> <code class="n">isAlive</code> <code class="p">=</code> <code class="n">entry</code><code class="p">.</code><code class="n">TryGetTarget</code><code class="p">(</code><code class="k">out</code> <code class="n">cachedItem</code><code class="p">);</code>
            <code class="k">if</code> <code class="p">(!</code><code class="n">isAlive</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">_cache</code><code class="p">.</code><code class="n">Remove</code><code class="p">(</code><code class="n">key</code><code class="p">);</code>
            <code class="p">}</code>
            <code class="k">return</code> <code class="n">isAlive</code><code class="p">;</code>
        <code class="p">}</code>
        <code class="k">else</code>
        <code class="p">{</code>
            <code class="n">cachedItem</code> <code class="p">=</code> <code class="k">null</code><code class="p">;</code>
            <code class="k">return</code> <code class="k">false</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>This cache stores all values via a <code>WeakReference&lt;T&gt;</code>. Its <code>Add</code> method passes the object to which we’d like a weak reference as the constructor argument for a new <code>WeakReference&lt;T&gt;</code>. The <code>TryGetValue</code> method attempts to retrieve a value previously stored with <code>Add</code>. It first checks to see if the dictionary contains a relevant entry. If it does, that entry’s value will be the <code>WeakReference&lt;T&gt;</code> we created earlier. My code calls that weak reference’s <code>TryGetTarget</code> method, which will return <code>true</code> if the object is still available and <code>false</code> if it has been collected.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a data-primary="availability, reachability versus" data-type="indexterm" id="idm45884815961344"/><a data-primary="reachability" data-secondary="availability versus" data-type="indexterm" id="idm45884815960672"/>Availability doesn’t necessarily imply reachability. The object may have become unreachable since the most recent GC. Or there may not even have been a GC since the object was allocated. <code>TryGet​Tar⁠get</code> can tell you only whether the GC has detected that it is eligible for collection.</p>
</div>
<p>If the object is available, <code>TryGetTarget</code> provides it through an <code>out</code> parameter, and this will be a strong reference. So, if this method returns <code>true</code>, we don’t need to worry about any race condition in which the object becomes unreachable moments later—the fact that we’ve now stored that reference in the variable the caller supplied via the <span class="keep-together"><code>cachedItem</code></span> argument will keep the target alive. If <code>TryGetTarget</code> returns <code>false</code>, my code removes the relevant entry from the dictionary, because it represents an object that no longer exists. That’s important because although a weak reference won’t keep its target alive, the <code>WeakReference&lt;T&gt;</code> is an object in its own right, and the GC can’t free it until I’ve removed it from this dictionary. <a data-type="xref" href="#exercising_the_weak_cache">Example 7-4</a> tries this code out, forcing a couple of garbage collections so we can see it in action. (This splits each stage into separate methods with inlining disabled because otherwise, .NET’s JIT compiler will inline these methods, and it ends up creating hidden temporary variables that can cause the array to remain reachable longer than it should, distorting the results of this test.)</p>
<div data-type="example" id="exercising_the_weak_cache">
<h5><span class="label">Example 7-4. </span>Exercising the weak cache</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">internal</code> <code class="k">class</code> <code class="nc">Program</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="k">static</code> <code class="n">WeakCache</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">,</code> <code class="kt">byte</code><code class="p">[]&gt;</code> <code class="n">cache</code> <code class="p">=</code> <code class="k">new</code> <code class="p">();</code>
    <code class="k">private</code> <code class="k">static</code> <code class="kt">byte</code><code class="p">[]?</code> <code class="n">data</code> <code class="p">=</code> <code class="k">new</code> <code class="kt">byte</code><code class="p">[</code><code class="m">100</code><code class="p">];</code>

    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">Main</code><code class="p">(</code><code class="kt">string</code><code class="p">[]</code> <code class="n">args</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">AddData</code><code class="p">();</code>
        <code class="n">CheckStillAvailable</code><code class="p">();</code>

        <code class="n">GC</code><code class="p">.</code><code class="n">Collect</code><code class="p">();</code>
        <code class="n">CheckStillAvailable</code><code class="p">();</code>

        <code class="n">SetOnlyRootToNull</code><code class="p">();</code>
        <code class="n">GC</code><code class="p">.</code><code class="n">Collect</code><code class="p">();</code>
        <code class="n">CheckNoLongerAvailable</code><code class="p">();</code>
    <code class="p">}</code>

<code class="na">    [MethodImpl(MethodImplOptions.NoInlining)]</code>
    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">AddData</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="n">cache</code><code class="p">.</code><code class="n">Add</code><code class="p">(</code><code class="s">"d"</code><code class="p">,</code> <code class="n">data</code><code class="p">!);</code>
    <code class="p">}</code>

<code class="na">    [MethodImpl(MethodImplOptions.NoInlining)]</code>
    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">CheckStillAvailable</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Retrieval: "</code> <code class="p">+</code>
            <code class="n">cache</code><code class="p">.</code><code class="n">TryGetValue</code><code class="p">(</code><code class="s">"d"</code><code class="p">,</code> <code class="k">out</code> <code class="kt">byte</code><code class="p">[]?</code> <code class="n">fromCache</code><code class="p">));</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Same ref?  "</code> <code class="p">+</code>
            <code class="kt">object</code><code class="p">.</code><code class="n">ReferenceEquals</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">fromCache</code><code class="p">));</code>
    <code class="p">}</code>

<code class="na">    [MethodImpl(MethodImplOptions.NoInlining)]</code>
    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">SetOnlyRootToNull</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="n">data</code> <code class="p">=</code> <code class="k">null</code><code class="p">;</code>
    <code class="p">}</code>

<code class="na">    [MethodImpl(MethodImplOptions.NoInlining)]</code>
    <code class="k">private</code> <code class="k">static</code> <code class="k">void</code> <code class="nf">CheckNoLongerAvailable</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="kt">byte</code><code class="p">[]?</code> <code class="n">fromCache</code><code class="p">;</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Retrieval: "</code> <code class="p">+</code> <code class="n">cache</code><code class="p">.</code><code class="n">TryGetValue</code><code class="p">(</code><code class="s">"d"</code><code class="p">,</code> <code class="k">out</code> <code class="n">fromCache</code><code class="p">));</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Null?  "</code> <code class="p">+</code> <code class="p">(</code><code class="n">fromCache</code> <code class="p">==</code> <code class="k">null</code><code class="p">));</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>This begins by creating an instance of my cache class and then adding a reference to a 100-byte array to the cache. It also stores a reference to the same array in a static field called <code>data</code>, keeping it reachable until the code calls <code>SetOnlyRootToNull</code>, which sets its value to <code>null</code>. The example tries to retrieve the value from the cache immediately after adding it and also uses <code>object.ReferenceEquals</code> just to check that the value we get back really refers to the same object that we put in. Then I force a garbage collection and try again. (This sort of artificial test code is one of the few situations in which you’d want to do this—see the section <a data-type="xref" href="#forcing_garbage_collections">“Forcing Garbage Collections”</a> for details.) Since the <code>data</code> field still holds a reference to the array, the array is still reachable, so we would expect the value still to be available from the cache. Next I set <code>data</code> to <code>null</code>, so my code is no longer keeping that array reachable. The only remaining reference is a weak one, so when I force another GC, we expect the array to be collected and the final lookup in the cache to fail. To verify this, I check both the return value, expecting <code>false</code>, and the value returned through the <code>out</code> parameter, which should be <code>null</code>. And that is exactly what happens when I run the program, as you can see:</p>
<pre data-type="programlisting">Retrieval: True
Same ref?  True
Retrieval: True
Same ref?  True
Retrieval: False
Null?  True</pre>
<div class="note1" data-type="note" epub:type="note"><h6>Note</h6>
<p>Writing code to illustrate GC behavior means entering treacherous territory. The principles of operation remain the same, but the exact behavior of small examples changes over time, often due to optimizations performed during JIT compilation. It’s entirely possible that if you try these examples, you might see different behavior due to changes in the runtime since going to press.</p>
</div>
<p>Later, I will describe finalization, which complicates matters by introducing a twilight zone in which the object has been determined to be unreachable but has not yet gone. Objects that are in this state are typically of little use, so by default, a weak reference will treat objects waiting for finalization as though they have already gone. <a data-primary="short weak reference" data-type="indexterm" id="idm45884815673056"/>This is called a <em>short weak reference</em>. <a data-primary="long weak reference" data-type="indexterm" id="idm45884815671808"/>If, for some reason, you need to know whether an object has really gone (rather than merely being on its way out), the <code>WeakReference&lt;T&gt;</code> class’s constructor has overloads, some of which can create a <em>long weak reference</em>, which provides access to the object even in this zone between unreachability and final removal.<a data-startref="ix_ch07-asciidoc8" data-type="indexterm" id="idm45884815669904"/><a data-startref="ix_ch07-asciidoc7" data-type="indexterm" id="idm45884815669200"/></p>
</div></section>
<section data-pdf-bookmark="Reclaiming Memory" data-type="sect2"><div class="sect2" id="reclaiming_memory">
<h2>Reclaiming Memory</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="reclaiming memory" data-type="indexterm" id="ix_ch07-asciidoc9"/><a data-primary="memory, reclaiming" data-type="indexterm" id="ix_ch07-asciidoc10"/><a data-primary="reclaiming memory" data-type="indexterm" id="ix_ch07-asciidoc11"/>So far, I’ve described how the CLR determines which objects are no longer in use but not what happens next. Having identified the garbage, the runtime must then collect it. The CLR uses different strategies for small and large objects. (By default, the .NET CLR defines a large object as one bigger than 85,000 bytes. Mono sets the bar lower at 8,000 bytes.) Most allocations involve small objects, so I’ll write about those first.</p>
<p>The CLR tries to keep the heap’s free space contiguous. That’s easy when the application first starts up, because there’s nothing but free space, and it can keep things contiguous by allocating memory for each new object directly after the last one. But after the first GC occurs, the heap is unlikely to look so neat. Most objects have short lifetimes, and it’s common for the majority of objects allocated after any one GC to be unreachable by the time the next GC runs. However, some will still be in use. From time to time, applications create objects that hang around for longer, and whatever work was in progress when the GC ran will probably be using some objects, so the most recently allocated heap blocks are likely still to be in use. This means that the end of the heap might look something like <a data-type="xref" href="#heap_section_with_some_reachable">Figure 7-1</a>, where the gray rectangles are the reachable blocks, and the white ones show blocks that are no longer in use.</p>
<figure><div class="figure" id="heap_section_with_some_reachable">
<img alt="" height="55" src="assets/pc10_0701.png" width="600"/>
<h6><span class="label">Figure 7-1. </span>Section of heap with some reachable objects</h6>
</div></figure>
<p>One possible allocation strategy would be to start using these empty blocks as new memory is required, but there are a couple of problems with that approach. First, it tends to be wasteful, because the blocks the application requires will probably not fit precisely into the holes available. Second, finding a suitable empty block can be somewhat expensive, particularly if there are lots of gaps and you’re trying to pick one that will minimize waste. It’s not impossibly expensive, of course—lots of heaps work this way—but it’s a lot costlier than the initial situation where each new block could be allocated directly after the last one because all the spare space was contiguous. The expense of heap fragmentation is nontrivial, so the CLR typically tries to get the heap back into a state where the free space is contiguous. As <a data-type="xref" href="#section_of_heap_after_compaction">Figure 7-2</a> shows, it moves all the reachable objects toward the start of the heap so that all the free space is at the end, which puts it back in the favorable situation of being able to allocate new heap blocks one after another in the contiguous lump of free space.</p>
<figure><div class="figure" id="section_of_heap_after_compaction">
<img alt="" height="58" src="assets/pc10_0702.png" width="600"/>
<h6><span class="label">Figure 7-2. </span>Section of heap after compaction</h6>
</div></figure>
<p>The runtime has to ensure that references to these relocated blocks continue to work after the blocks have moved. The CLR happens to implement references as pointers (although nothing requires this—a reference is just a value that identifies some particular instance on the heap). It already knows where all the references to any particular block are because it had to find them to discover which blocks were reachable. It adjusts all these pointers when it moves the block.</p>
<p>Besides making heap block allocation a relatively cheap operation, compaction offers another performance benefit. Because blocks are allocated into a contiguous area of free space, objects that were created in quick succession will typically end up right next to each other in the heap. This is significant, because the caches in modern CPUs tend to favor locality (i.e., they perform best when related pieces of data are stored close together).</p>
<p>The low cost of allocation and the high likelihood of good locality can sometimes mean that garbage-collected heaps offer better performance than traditional heaps that require the program to free memory explicitly. This may seem surprising, given that the GC appears to do a lot of extra work that is unnecessary in a noncollecting heap. Some of that “extra” work is nothing of the sort, however—something has to keep track of which objects are in use, and traditional heaps just push that housekeeping overhead into our code. However, relocating existing memory blocks comes at a price, so the CLR uses some tricks to minimize the amount of copying it needs 
<span class="keep-together">to do</span>.</p>
<p>The older an object is, the more expensive it will be for the CLR to compact the heap once it finally becomes unreachable. If the most recently allocated object is unreachable when the GC runs, compaction is free for that object: there are no more objects after <span class="keep-together">it, so nothing</span> needs to be moved. Compare that with the first object your program allocates—if that becomes unreachable, compaction would mean moving every <span class="keep-together">reachable</span> object on the heap. More generally, the older an object is, the more objects will be put after it, so the more data will need to be moved to compact the heap. Copying 20 MB of data to save 20 bytes does not sound like a great trade-off. So the CLR will often defer compaction for older parts of the heap.</p>
<p><a data-primary="generations (heap division)" data-type="indexterm" id="ix_ch07-asciidoc12"/>To decide what counts as “old,” the .NET runtime divides the heap into <em>generations</em>.<sup><a data-type="noteref" href="ch07.xhtml#idm45884815650576" id="idm45884815650576-marker">5</a></sup> The boundaries between generations move around at each GC, because generations are defined in terms of how many GCs an object has survived. Any object allocated after the most recent GC is in generation 0, because it has not yet survived any collections. When the GC next runs, generation 0 objects that are still reachable will be moved as necessary to compact the heap and will then be deemed to be in generation 1.</p>
<p>Objects in generation 1 are not yet considered to be old. A GC will typically occur while the code is right in the middle of doing things—after all, it runs when space on the heap is being used up, and that won’t happen if the program is idle. So there’s a high chance that some of the recently allocated objects represent work in progress, and although they are currently reachable, they will become unreachable shortly. Generation 1 acts as a sort of holding zone while we wait to see which objects are short-lived and which are longer-lived.</p>
<p>As the program continues to execute, the GC will run from time to time, promoting new, surviving objects into generation 1. Some of the objects in generation 1 will become unreachable. However, the GC does not necessarily compact this part of the heap immediately—it may allow a few generation 0 collections and compactions in between each generation 1 compaction, but it will happen eventually. Objects that survive this stage are moved into generation 2, which is the oldest generation.</p>
<p>The CLR attempts to recover memory from generation 2 much less frequently than from other generations. Research shows that in most applications, objects that survive into generation 2 are likely to remain reachable for a long time, so when one of those objects does eventually become unreachable, it’s likely to be very old, as will be the objects around it. This means that compacting this part of the heap to recover the memory is costly for two reasons: not only will this old object probably be followed by a large number of other objects (requiring a large volume of data to be copied), but also the memory it occupied might not have been used for a long time, meaning it’s probably no longer in the CPU’s cache, slowing down the copy even further. And the caching costs will continue after collection, because if the CPU has had to shift megabytes of data around in old areas of the heap, this will probably have the side effect of flushing other data out the CPU’s cache. Cache sizes can be as small as 512 KB at the low-power, low-cost end of the spectrum, and can be over 90 MB in high-end, server-oriented chips, but in the midrange, anything from 2 MB to 16 MB of cache is typical, and many .NET applications’ heaps will be larger than that. Most of the data the <span class="keep-together">application</span> had been using would have been in the cache right up until the generation 2 GC but would be gone once the GC has finished. So when the GC completes and normal execution resumes, the code will run in slow motion for a while until the data the application needs is loaded back into the cache.</p>
<p><a data-primary="ephemeral generations" data-type="indexterm" id="idm45884815646128"/>Generations 0 and 1 are sometimes referred to as the <em>ephemeral</em> generations, because they mostly contain objects that exist only for a short while. (The part of Mono’s heap that serves a similar purpose is called the <em>nursery</em>, because it’s for young objects.) The contents of these parts of the heap will often be in the CPU’s cache because they will have been accessed recently, so compaction is not particularly expensive for these sections. Moreover, because most objects have a short lifetime, the majority of memory that the GC is able to collect will be from objects in these first two generations, so these are likely to offer the greatest reward (in terms of memory recovered) in exchange for the CPU time expended. So it’s common to see several ephemeral collections per second in a busy program, but it’s also common for several minutes to elapse between successive generation 2 collections.</p>
<p>The CLR has another trick up its sleeve for generation 2 objects. They often don’t change much, so there’s a high likelihood that during the first phase of a GC—in which the runtime detects which objects are reachable—it would be repeating some work it did earlier, because it will follow exactly the same references and produce the same results for significant subsections of the heap. So the CLR will sometimes use the OS memory protection services to detect when older heap blocks are modified. This enables it to rely on summarized results from earlier GC operations instead of having to redo all of the work every time.</p>
<p>How does the GC decide whether to collect just from generation 0 or also from 1 or even 2? Collections for all three generations are triggered by using up a certain amount of memory. So, for generation 0 allocations, once you have allocated some particular number of bytes since the last GC, a new GC will occur. The objects that survive this will move into generation 1, and the CLR keeps track of the number of bytes added to generation 1 since the last generation 1 collection; if that number exceeds a threshold, generation 1 will be collected too. Generation 2 works in the same way. The thresholds are not documented, and in fact they’re not even constant; the CLR monitors your allocation patterns and modifies these thresholds to try to find a good balance for making efficient use of memory, minimizing the CPU time spent in the GC and avoiding the excessive latency that could arise if the CLR waited a very long time between collections, leaving huge amounts of work to do when the collection finally occurs.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This explains why, as mentioned earlier, the CLR doesn’t necessarily wait until it has actually run out of memory before triggering a GC. It may be more efficient to run one sooner.</p>
</div>
<p>You may be wondering how much of the preceding information is of  practical significance. After all, the bottom line would appear to be that the CLR ensures that heap blocks are kept around for as long as they are reachable, and that sometime after they become unreachable, it will eventually reclaim their memory, and it employs a strategy designed to do this efficiently. Are the details of this generational optimization scheme relevant to a developer? They are insofar as they tell us that some coding practices are likely to be more efficient than others.</p>
<p>The most obvious upshot of the process is that the more objects you allocate, the harder the GC will have to work. But you’d probably guess that without knowing anything about the implementation. More subtly, larger objects cause the GC to work harder—collections for each generation are triggered by the amount of memory your application uses. So bigger objects don’t just increase memory pressure, they also end up consuming more CPU cycles as a result of triggering more frequent GCs.</p>
<p>Perhaps the most important fact to emerge from an understanding of the generational nature of the collector is that the length of an object’s lifetime has an impact on how hard the GC must work. Objects that live for a very short time are handled efficiently, because the memory they use will be recovered quickly in a generation 0 or 1 collection, and the amount of data that needs to be moved to compact the heap will be small. Objects that live for an extremely long time are also OK, because they will end up in generation 2. They will not be moved about often, because collections are infrequent for that part of the heap. Furthermore, the CLR may be able to use the OS memory manager’s write detection feature to manage reachability discovery for old objects more efficiently. However, although very short-lived and very long-lived objects are handled efficiently, objects that live long enough to get into generation 2 but not much longer are a problem. Microsoft occasionally describes this occurrence as a <em>midlife crisis</em>.</p>
<p>If your application regularly creates lots of objects making it into generation 2 that go on to become unreachable, the CLR will need to perform collections on generation 2 more often than it otherwise might. (In fact, generation 2 is collected only during a <em>full collection</em>, which also collects free space previously used by large objects.) These are usually significantly more expensive than other collections. Compaction requires more work with older objects, but also, more housekeeping is required when disrupting the generation 2 heap. The picture the CLR has built up about reachability within this section of the heap may need to be rebuilt, and the GC will need to disable the write detection used to enable that while it compacts the heap, which incurs a cost. There’s a good chance that most of this part of the heap will not be in the CPU’s cache either, so working with it can be slow.</p>
<p>Full GCs consume significantly more CPU time than collections in the ephemeral generations. In UI applications, this can cause delays long enough to be irritating for the user, particularly if parts of the heap had been paged out by the OS. In server applications, full collections may cause significant blips in the typical time taken to service a request. Such problems are not the end of the world, and as I’ll describe later, the CLR offers some mechanisms to mitigate these kinds of issues. Even so, minimizing the number of objects that survive to generation 2 is good for performance. You would need to consider this when designing code that caches interesting data in memory—a cache aging policy that failed to take the GC’s behavior into account could easily behave inefficiently, and if you didn’t know about the perils of middle-aged objects, it would be hard to work out why. Also, as I’ll show later in this chapter, the midlife crisis issue is one reason you might want to avoid C# destructors where possible.<a data-startref="ix_ch07-asciidoc12" data-type="indexterm" id="idm45884815638160"/></p>
<p>I have left out some heap operational details, by the way. For example, I’ve not talked about how the GC typically dedicates sections of the address space to the heap in fixed-size chunks, nor the details of how it commits and releases memory. Interesting though these mechanisms are, they have much less relevance to how you design your code than an awareness of the assumptions that a generational GC makes about typical object lifetimes. They also tend to change—.NET 6.0 has made significant modifications in this area to improve performance.</p>
<p>There’s one last thing to talk about on the topic of collecting memory from unreachable objects. As mentioned earlier, large objects work differently. <a data-primary="large object heap (LOH)" data-type="indexterm" id="idm45884815635744"/><a data-primary="LOH (large object heap)" data-type="indexterm" id="idm45884815635040"/><a data-primary="heap" data-secondary="large object (LOH)" data-type="indexterm" id="idm45884815634368"/>There’s a separate heap called, appropriately enough, the <em>large object heap</em> (LOH), and the .NET runtime uses this for any object larger than 85,000 bytes;<sup><a data-type="noteref" href="ch07.xhtml#idm45884815632912" id="idm45884815632912-marker">6</a></sup> Mono’s runtime uses an 8,000-byte threshold, because it is often used in more memory-constrained environments. That’s just the object itself, not the sum total of all the memory an object allocates during construction. An instance of the <span class="keep-together"><code>GreedyObject</code></span> class in <a data-type="xref" href="#a_small_object_with_a_large_array">Example 7-5</a> would be tiny—it needs only enough space for a single reference, plus the heap block overhead. In a 32-bit process, that would be 4 bytes for the reference and 8 bytes of overhead, and in a 64-bit process, it would be twice as large. However, the array to which it refers is 400,000 bytes long, so that would go on the LOH, while the <code>GreedyObject</code> itself would go on the ordinary heap.</p>
<div data-type="example" id="a_small_object_with_a_large_array">
<h5><span class="label">Example 7-5. </span>A small object with a large array</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">GreedyObject</code>
<code class="p">{</code>
    <code class="k">public</code> <code class="kt">int</code><code class="p">[]</code> <code class="n">MyData</code> <code class="p">=</code> <code class="k">new</code> <code class="kt">int</code><code class="p">[</code><code class="m">100_000</code><code class="p">];</code>
<code class="p">}</code></pre></div>
<p>It’s technically possible to create a class whose instances are large enough to require the LOH, but it’s unlikely to happen outside of generated code or highly contrived examples. In practice, most LOH heap blocks will contain arrays and possibly strings.</p>
<p>The biggest difference between the LOH and the ordinary heap is that the GC does not usually compact the LOH, because copying large objects is expensive. (Applications can request that the LOH be compacted at the next full GC. But applications that do not explicitly request this will never have their LOH compacted in current CLR implementations.) It works more like a traditional C heap: the CLR maintains a list of free blocks and decides which block to use based on the size requested. However, the list of free blocks is populated by the same unreachability mechanism as is used by the rest of the heap.<a data-startref="ix_ch07-asciidoc11" data-type="indexterm" id="idm45884815624704"/><a data-startref="ix_ch07-asciidoc10" data-type="indexterm" id="idm45884815624208"/><a data-startref="ix_ch07-asciidoc9" data-type="indexterm" id="idm45884815623600"/></p>
</div></section>
<section data-pdf-bookmark="Garbage Collector Modes" data-type="sect2"><div class="sect2" id="garbage_collector_modes">
<h2>Garbage Collector Modes</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="garbage collector modes" data-type="indexterm" id="ix_ch07-asciidoc13"/>Although the .NET runtime will tune some aspects of the GC’s behavior at runtime (e.g., by dynamically adjusting the thresholds that trigger collections for each generation), it also offers a configurable choice between various modes designed to suit different kinds of applications. These fall into two broad categories—workstation and server, and then in each of these you can either use background or nonconcurrent collections. Background collection is on by default, but the default top-level mode depends on the project type: for console applications and applications using a GUI framework such as WPF, the GC runs in workstation mode, but ASP.NET Core web applications change this to server mode. You can control the GC mode explicitly by defining a property in your <em>.csproj</em> file, as <a data-type="xref" href="#configuring_server_gc">Example 7-6</a> shows. This can go anywhere inside the root <code>Project</code> element.</p>
<div data-type="example" id="configuring_server_gc">
<h5><span class="label">Example 7-6. </span>Enabling server GC in a .NET Core application project file</h5>
<pre data-code-language="xml" data-type="programlisting"><code class="nt">&lt;PropertyGroup&gt;</code>
  <code class="nt">&lt;ServerGarbageCollection&gt;</code>true<code class="nt">&lt;/ServerGarbageCollection&gt;</code>
<code class="nt">&lt;/PropertyGroup&gt;</code></pre></div>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This <code>ServerGarbageCollection</code> property makes the build system add a setting to the <em>YourApplication.runtimeconfig.json</em> file that it generates for your application. This contains a 
<span class="keep-together"><code>configProperties</code></span> section, which can contain one or more <em>CLR host configuration knobs</em>. Enabling server GC in the project file sets the <code>Sys⁠tem.​GC.⁠Ser⁠ver</code> knob to <code>true</code> in this configuration file. All GC settings are also controlled through configuration knobs, as are some other CLR behaviors, such as the JIT compiler mode.</p>
</div>
<p><a data-primary="workstation GC mode" data-type="indexterm" id="idm45884815571200"/>The workstation modes are designed for the workloads that client-side code typically has to deal with, in which the process is usually working on either a single task or a small number of tasks at any one time. Workstation mode offers two variations: nonconcurrent and background.</p>
<p><a data-primary="background GC mode" data-type="indexterm" id="idm45884815569808"/>In background mode (the default), the GC minimizes the amount of time for which it suspends threads during a GC. There are certain phases of the GC in which the CLR has to suspend execution to ensure consistency. For collections from the ephemeral generations, threads will be suspended for the majority of the operation. This is usually fine because these collections normally run very quickly—they take a similar amount of time as a page fault that didn’t cause any disk activity. (These nonblocking page faults happen fairly often and are fast enough that a lot of developers seem to be unaware that they even occur.) Full collections are the problem, and it’s these that the background mode handles differently. Not all of the work done in a collection really needs to bring everything to a halt, and background mode exploits this, enabling full (generation 2) collections to proceed on a background thread without forcing other threads to block until that collection completes. This can enable machines with multiple processor cores (most machines, these days) to perform full GC collections on one core while other cores continue with productive work. It is especially useful in applications with a UI, because it reduces the likelihood of an application becoming unresponsive due to GCs.</p>
<p><a data-primary="nonconcurrent GC mode" data-type="indexterm" id="idm45884815568848"/>The nonconcurrent mode is designed to optimize throughput on a single processor with a single core. It can be more efficient, because background GC uses slightly more memory and more CPU cycles for any particular workload than nonconcurrent GC in exchange for the lower latency. For some workloads, you may find your code runs faster if you set the <code>ConcurrentGarbageCollection</code> property to <code>false</code> in your project file. For most client-side code, the greatest concern is to avoid delays that are long enough to be visible to users. Users are more sensitive to unresponsiveness than they are to suboptimal average CPU utilization, so for interactive applications, using a bit more memory and CPU cycles in exchange for improved perceived performance is usually a good trade-off.</p>
<p><a data-primary="server GC mode" data-type="indexterm" id="idm45884815552448"/>Server mode is significantly different than workstation mode. It is available only when you have multiple hardware threads; e.g., a multicore CPU or multiple physical CPUs. (If you have enabled server GC but your code ends up running on a single-core machine,<sup><a data-type="noteref" href="ch07.xhtml#idm45884815551344" id="idm45884815551344-marker">7</a></sup> it falls back to using the workstation GC.) Its availability has nothing to do with which OS you’re running, by the way—for example, server mode is available on nonserver and server editions of Windows alike if you have suitable hardware, and workstation mode is always available. In server mode, each processor core gets its own section of the heap, so when a thread is working on its own problem independently of the rest of the process, it can allocate heap blocks with minimal contention. In server mode, the CLR creates several threads dedicated to GC, one for each logical CPU in the machine. These run with higher priority than normal threads, so when GCs do occur, all available CPU cores go to work on their own heaps, which can provide better throughput with large heaps than workstation mode.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Objects created by one thread can still be accessed by others—logically, the heap is still a unified service. Server mode is just an implementation strategy optimized for workloads where each thread works on its own jobs mostly in isolation. Be aware that it works best if the jobs all have similar heap allocation patterns.</p>
</div>
<p>Some problems can arise with server mode. It works best when only one process on the machine uses this mode, because it is set up to try to use all CPU cores simultaneously during collections. It also tends to use considerably more memory than workstation mode. If a single server hosts multiple .NET processes that all do this, contention for resources could reduce efficiency. Another issue with server GC is that it favors throughput over response time. In particular, collections happen less frequently, because this tends to increase the throughput benefits that multi-CPU collections can offer, but it also means that each individual collection takes longer.</p>
<p>As with workstation GC, the server GC uses background collection by default. In some cases, you may find you can improve throughput by disabling it, but be wary of the problems this can cause. The duration of a full collection in nonconcurrent server mode can cause serious delays in responsiveness on a website, for example, especially if the heap is large. You can mitigate this in a couple of ways. <a data-primary="GC class" data-type="indexterm" id="idm45884815548256"/>You can request notifications shortly before the collection occurs (using the <code>System.GC</code> class’s <code>Reg⁠ist⁠er​For⁠Ful⁠lGC⁠Not⁠ifi⁠cat⁠ion</code>, <code>WaitForFullGCApproach</code>, and <code>WaitForFullGC​Com⁠plete</code> methods), and if you have a server farm, a server that’s running a full GC may be able to ask the load balancer to avoid passing it requests until the GC completes. The simpler alternative is to leave background collection enabled. Since background collections allow application threads to continue to run and even to perform generation 0 and 1 collections while the full collection proceeds in the background, it significantly improves the application’s response time during collections while still delivering the throughput benefits of server mode.<a data-startref="ix_ch07-asciidoc13" data-type="indexterm" id="idm45884815533568"/></p>
</div></section>
<section data-pdf-bookmark="Temporarily Suspending Garbage Collections" data-type="sect2"><div class="sect2" id="suspending_garbage_collections">
<h2>Temporarily Suspending Garbage Collections</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="temporarily suspending" data-type="indexterm" id="idm45884815531408"/>It is possible to ask .NET to disallow GC while a particular section of code runs. This is useful if you are performing time-sensitive work. Windows, macOS, and Linux are not real-time operating systems, so there are never any guarantees, but temporarily ruling out GCs at critical moments can nonetheless be useful for reducing the chances of things going slowly at the worst possible moment. Be aware that this mechanism works by bringing forward any GC work that might otherwise have happened in the relevant section of code, so this can cause GC-related delays to happen earlier than they otherwise would have. It only guarantees that once your designated region of code starts to run, there will be no further GCs if you meet certain requirements—in effect, it gets necessary delays out of the way before the time-sensitive work begins.</p>
<p>The <code>GC</code> class offers a <code>TryStartNoGCRegion</code> method, which you call to indicate that you want to begin some work that needs to be free from GC-related interruption. You must pass in a value indicating how much memory you will need during this work, and it will attempt to ensure that at least that much memory is available before proceeding (performing a GC to free up that space if necessary). If the method indicates success, then as long as you do not consume more memory than requested, your code will not be interrupted by the GC. You should call <code>EndNoGCRegion</code> once you have finished the time-critical work, enabling the GC to return to its normal operation. If, before it calls <code>EndNoGCRegion</code>, your code uses more memory than you requested, the CLR may have to perform a GC, but it will only do so if it absolutely cannot avoid it until you call <code>EndNoGCRegion</code>.</p>
<p>Although the single-argument form of <code>TryStartNoGCRegion</code> will perform a full GC if necessary to meet your request, some overloads take a <code>bool</code>, enabling you to tell it that if a full blocking GC will be required to free up the necessary space, you’d prefer to abort. There are also overloads in which you can specify your memory requirements on the ordinary heap and the large object heap separately.</p>
</div></section>
<section data-pdf-bookmark="Accidentally Defeating Compaction" data-type="sect2"><div class="sect2" id="accidentally_defeating_compaction">
<h2>Accidentally Defeating Compaction</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="compaction" data-seealso="reclaiming memory" data-type="indexterm" id="ix_ch07-asciidoc14"/><a data-primary="garbage collector/garbage collection (GC)" data-secondary="accidentally defeating compaction" data-type="indexterm" id="ix_ch07-asciidoc15"/><a data-primary="heap compaction, accidentally defeating" data-type="indexterm" id="ix_ch07-asciidoc16"/>Heap compaction is an important feature of the CLR’s GC, because it has a strong positive impact on performance. Certain operations can prevent compaction, and that’s something you’ll want to minimize, because fragmentation can increase memory use and reduce performance significantly.</p>
<p>To be able to compact the heap, the CLR needs to be able to move heap blocks around. Normally, it can do this because it knows all of the places in which your application refers to heap blocks, and it can adjust all the references when it relocates a block. But what if you’re calling an OS API that works directly with the memory you provide? For example, if you read data from a file or a network socket, how will that interact with GC?</p>
<p>If you use system calls that read or write data using devices such as the hard drive or network interface, these normally work directly with your application’s memory. If you read data from the disk, the OS may instruct the disk controller to put the bytes directly into the memory your application passed to the API. The OS will perform the necessary calculations to translate the virtual address into a physical address. (With virtual memory, the value your application puts in a pointer is only indirectly related to the actual address in your computer’s RAM.) The OS will lock the pages into place for the duration of the I/O request to ensure that the physical address remains valid. It will then supply the disk system with that address. This enables the disk controller to copy data from the disk directly into memory, without needing further involvement from the CPU. This is very efficient but runs into problems when it encounters a compacting heap. What if the block of memory is a <code>byte[]</code> array on the heap? Suppose a GC occurs between us asking to read the data and the disk being able to supply the data. (The chances are fairly high; a mechanical disk with spinning platters can take 10 ms or more to start supplying data, which is an age in CPU terms.) If the GC decided to relocate our <code>byte[]</code> array to compact the heap, the physical memory address that the OS gave the disk controller would be out of date, so when the controller started putting data into memory, it would be writing to the wrong place.</p>
<p>There are three ways the CLR could deal with this. One would be to make the GC wait—heap relocations could be suspended while I/O operations are in progress. But that’s a nonstarter; a busy server can run for days without ever entering a state in which no I/O operations are in progress. In fact, the server doesn’t even need to be busy. It might allocate several <code>byte[]</code> arrays to hold the next few incoming network requests and would typically try to avoid getting into a state where it didn’t have at least one such buffer available. The OS would have pointers to all of these and may well have supplied the network card with the corresponding physical address so that it can get to work the moment data starts to arrive. So even an idle server has certain buffers that cannot be relocated.</p>
<p>An alternative would be for the CLR to provide a separate nonmoving heap for these sorts of operations. Perhaps we could allocate a fixed block of memory for an I/O operation, and then copy the results into the <code>byte[]</code> array on the GC heap once the I/O has finished. But that’s also not a brilliant solution. Copying data is expensive—the more copies you make of incoming or outgoing data, the slower your server will run, so you really want network and disk hardware to copy the data directly to or from its natural location. And if this hypothetical fixed heap were more than an implementation detail of the CLR—if it were available for application code to use directly to minimize copying—that might open the door to all the memory management bugs that GC is supposed to banish.</p>
<p>So the CLR uses a third approach: it selectively prevents heap block relocations. <a data-primary="heap" data-secondary="pinned blocks" data-type="indexterm" id="ix_ch07-asciidoc17"/><a data-primary="pinned blocks" data-type="indexterm" id="ix_ch07-asciidoc18"/>The GC is free to run while I/O operations are in progress, but certain heap blocks can be <em>pinned</em>. Pinning a block sets a flag that tells the GC that the block cannot currently be moved. So, if the GC encounters such a block, it will simply leave it where it is but will attempt to relocate everything around it.</p>
<p>There are five ways C# code normally causes heap blocks to be pinned. <a data-primary="fixed keyword" data-type="indexterm" id="idm45884815512464"/>You can do so explicitly using the <code>fixed</code> keyword. This allows you to obtain a raw pointer to a storage location, such as a field or an array element, and the compiler will generate code that ensures that for as long as a fixed pointer is in scope, the heap block to which it refers will be pinned. A more common way to pin a block is through interop (i.e., calls into unmanaged code, such as an OS API). If you make an interop call to an API that requires a pointer to something, the CLR will detect when that points to a heap block, and it will automatically pin the block. By default, the CLR will unpin it automatically when the method returns. If you’re calling an asynchronous API that will continue to use the memory after returning, you can use the <code>GCHandle</code> class mentioned earlier to pin a heap block until you explicitly unpin it; that’s the third pinning technique.</p>
<p>The fourth and most common way to pin heap blocks is also the least direct: many runtime library APIs call unmanaged code on your behalf and will pin the arrays you pass in as a result. For example, the runtime libraries define a <code>Stream</code> class that represents a stream of bytes. There are several implementations of this abstract class. Some streams work entirely in memory, but some wrap I/O mechanisms, providing access to files or to the data being sent or received through a network socket. The abstract <code>Stream</code> base class defines methods for reading and writing data via <code>byte[]</code> arrays, and the I/O-based stream implementations will often pin the heap blocks containing those arrays for as long as necessary.</p>
<p><a data-primary="GC class" data-secondary="AllocateArray method" data-type="indexterm" id="idm45884815508464"/><a data-primary="AllocateArray method" data-type="indexterm" id="idm45884815507264"/>The fifth way is to use the <code>GC</code> class’s <code>AllocateArray&lt;T&gt;</code> method. Instead of writing, say, <code>new byte[4096]</code>, you can write <code>GC.AllocateArray&lt;byte&gt;(4096, pinned: true)</code>. By passing <code>true</code> as that second argument, you are telling the CLR that you want this array to be pinned permanently. <a data-primary="POH (pinned object heap)" data-type="indexterm" id="idm45884815504240"/><a data-primary="pinned object heap (POH)" data-type="indexterm" id="idm45884815503520"/><a data-primary="heap" data-secondary="pinned object (POH)" data-type="indexterm" id="idm45884815502832"/>The CLR maintains an additional heap especially for this purpose called the <em>pinned object heap</em> (POH). As with the LOH, arrays in the POH will not be moved around, avoiding the overhead that pinning can otherwise cause.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The POH is not available on .NET Framework or Mono. It was introduced in .NET 5.0, so it’s also unavailable on .NET Core 3.1 (which will be fully supported until December 2022). For this reason, <code>AllocateArray&lt;T&gt;</code> is not available on these older versions of .NET.</p>
</div>
<p>If you are writing an application that does a lot of pinning (e.g., a lot of network I/O), you may need to think carefully about how you allocate the arrays that get pinned. Pinning does the most harm for recently allocated objects, because these live in the area of the heap where most compaction activity occurs. Pinning recently allocated blocks tends to cause the ephemeral section of the heap to fragment. Memory that would normally have been recovered almost instantly must now wait for blocks to become unpinned, so by the time the collector can get to those blocks, a lot more other blocks will have been allocated after them, meaning that a lot more work is required to recover the memory.</p>
<p>If pinning is causing your application problems, there will be a few common symptoms. The percentage of CPU time spent in the GC will be relatively high—anything over 10% is considered to be bad. But that alone does not necessarily implicate pinning—it could be the result of middle-aged objects causing too many full collections. So you can monitor the number of pinned blocks on the heap<sup><a data-type="noteref" href="ch07.xhtml#CHP-7-FN-3" id="CHP-7-FN-3-marker">8</a></sup> to see if these are the specific culprit. If it looks like excessive pinning is causing you pain, then if you’re able to use .NET 5.0 or later, you can use <code>GC.AllocateArray&lt;T&gt;</code> to allocate the relevant blocks on the POH.</p>
<p>If you need to support versions of .NET that don’t have a POH, there are still two ways to avoid pinning overhead. One is to design your application so that you only ever pin blocks that live on the LOH. Remember, by default the LOH is not compacted, so pinning does not impose any cost—the GC wasn’t going to move the block in any case. The challenging part of this is that it forces you to do all of your I/O with arrays that are at least 85,000 bytes long. That’s not necessarily a problem, because most I/O APIs can be told to work with a subsection of the array. So, if you actually wanted to work with, say, 4,096 byte blocks, you could create one array large enough to hold at least 21 of those blocks. You’d need to write some code to keep track of which slots in the array were in use, but if it fixes a performance problem, it may be worth the effort.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>If you choose to mitigate pinning by attempting to use the LOH, you need to remember that it is an implementation detail. Future versions of .NET could conceivably remove the LOH entirely. So you’d need to revisit this aspect of your design for each new release of .NET.</p>
</div>
<p>The <code>Span&lt;T&gt;</code> and <code>Memory&lt;T&gt;</code> types discussed in <a data-type="xref" href="ch18.xhtml#ch_memory_efficiency">Chapter 18</a> can make it easier to work with arrays in this way. (They also make it much easier than it used to be to work with memory that does not live on the GC heap. So you could sidestep pinning entirely, although you’d be taking on the responsibility for managing the relevant memory.) <a data-primary="MemoryPool&lt;T&gt; class" data-type="indexterm" id="idm45884815492624"/>In fact, the best strategy for dealing with pinning is often just to use <code>MemoryPool&lt;T&gt;</code>. On runtimes without a POH, it takes steps to mitigate pinning overheads for you, and on .NET 5.0 or later, it will allocate memory in the POH by default.</p>
<p>The other way to minimize the impact of pinning is to try to ensure that pinning mostly happens only to objects in generation 2. If you allocate a pool of buffers and reuse them for the duration of the application, this will mean that you’re pinning blocks that the GC is fairly unlikely to want to move, keeping the ephemeral generations free to be compacted at any time. The earlier you allocate the buffers, the better, because the older an object is, the less likely the GC is to want to move it, so if you’re going to use this approach, you should do it during your application startup if possible.<a data-startref="ix_ch07-asciidoc18" data-type="indexterm" id="idm45884815491024"/><a data-startref="ix_ch07-asciidoc17" data-type="indexterm" id="idm45884815490320"/><a data-startref="ix_ch07-asciidoc16" data-type="indexterm" id="idm45884815489648"/><a data-startref="ix_ch07-asciidoc15" data-type="indexterm" id="idm45884815488976"/><a data-startref="ix_ch07-asciidoc14" data-type="indexterm" id="idm45884815488304"/></p>
</div></section>
<section data-pdf-bookmark="Forcing Garbage Collections" data-type="sect2"><div class="sect2" id="forcing_garbage_collections">
<h2>Forcing Garbage Collections</h2>
<p><a data-primary="garbage collector/garbage collection (GC)" data-secondary="forcing" data-type="indexterm" id="idm45884815486144"/><a data-primary="GC class" data-type="indexterm" id="idm45884815485040"/>The <code>System.GC</code> class provides a <code>Collect</code> method that allows you to force a GC to occur. You can pass a number indicating the generation you would like to collect, and the overload that takes no arguments performs a full collection. You will rarely have good reason to call <code>GC.Collect</code>. I’m mentioning it here because it comes up a lot on the web, which could easily make it seem more useful than it is.</p>
<p>Forcing a GC can cause problems. The GC monitors its own performance and tunes its behavior in response to your application’s allocation patterns. But to do this, it needs to allow enough time between collections to get an accurate picture of how well its current settings are working. If you force collections to occur too often, it will not be able to tune itself, and the outcome will be twofold: the GC will run more often than necessary, and when it does run, its behavior will be suboptimal. Both problems are likely to increase the amount of CPU time spent in the GC.</p>
<p>So when would you force a collection? If you happen to know that your application has just finished some work and is about to go idle, it might be worth considering forcing a collection. GCs are usually triggered by activity, so if you know that your application is about to go to sleep—perhaps it’s a service that has just finished running a batch job and will not do any more work for another few hours—you know that it won’t be allocating new objects and will therefore not trigger the GC automatically. So forcing a GC would provide an opportunity to return memory to the OS before the application goes to sleep. That said, if this is your scenario, it might be worth looking at mechanisms that would enable your process to exit entirely—there are various ways in which jobs or services that are only required from time to time can be unloaded completely when they are inactive. But if that technique is inapplicable for some reason—perhaps your process has high startup costs or needs to stay running to receive incoming network requests—a forced full collection might be the next best option.</p>
<p>It’s worth being aware that there is one way that a GC can be triggered without your application needing to do anything. When the system is running low on memory, Windows broadcasts a message to all running processes. The CLR handles this message and forces a GC when it occurs. So even if your application does not proactively attempt to return memory, memory might be reclaimed eventually if something else in the system needs it.<a data-startref="ix_ch07-asciidoc2" data-type="indexterm" id="idm45884815480128"/><a data-startref="ix_ch07-asciidoc1" data-type="indexterm" id="idm45884815479424"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Destructors and Finalization" data-type="sect1"><div class="sect1" id="destructors_and_finalization">
<h1>Destructors and Finalization</h1>
<p><a data-primary="destructors" data-type="indexterm" id="ix_ch07-asciidoc19"/><a data-primary="finalization" data-type="indexterm" id="ix_ch07-asciidoc20"/><a data-primary="object lifetime" data-secondary="destructors and finalization" data-type="indexterm" id="ix_ch07-asciidoc21"/>The CLR works hard on our behalf to find out when our objects are no longer in use. It’s possible to get it to notify you of this—instead of simply removing unreachable objects, the CLR can first tell an object that it is about to be removed. The CLR calls this finalization, but C# presents it through a special syntax: to exploit finalization, you must write a destructor.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>If your background is in C++, do not be fooled by the name, or the similar syntax. As you will see, a C# destructor is different from a <span class="keep-together">C++</span> destructor in some important ways.</p>
</div>
<p><a data-type="xref" href="#class_with_destructor">Example 7-7</a> shows a destructor. This code compiles into an override of a method called <code>Finalize</code>, which as <a data-type="xref" href="ch06.xhtml#ch_inheritance">Chapter 6</a> mentioned, is a special method defined by the <code>object</code> base class. Finalizers are always required to call the base implementation of <code>Finalize</code> that they override. C# generates that call for us to prevent us from violating the rule, which is why it doesn’t let us simply write a <code>Finalize</code> method directly. You cannot write code that invokes a finalizer—they are called by the CLR, so we do not specify an accessibility level for the destructor.</p>
<div data-type="example" id="class_with_destructor">
<h5><span class="label">Example 7-7. </span>Class with destructor</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">LetMeKnowMineEnd</code>
<code class="p">{</code>
    <code class="p">~</code><code class="n">LetMeKnowMineEnd</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Goodbye, cruel world"</code><code class="p">);</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>The CLR does not guarantee to run finalizers on any particular schedule. First of all, it needs to detect that the object has become unreachable, which won’t happen until the GC runs. If your program is idle, that might not happen for a long time; the GC normally runs only when your program is doing something, or when system-wide memory pressure causes the GC to spring into life. It’s entirely possible that minutes, hours, or even days could pass between your object becoming unreachable and the CLR noticing that it has become unreachable.</p>
<p>Even when the CLR does detect unreachability, it still doesn’t guarantee to call the finalizer straightaway. Finalizers run on a dedicated thread. Because current versions of the CLR have only one finalization thread (regardless of which GC mode you choose), a slow finalizer will cause other finalizers to wait.</p>
<p>In most cases, the CLR doesn’t even guarantee to run finalizers at all. When a process exits, if the finalization thread hasn’t already managed to run all extant finalizers, it will exit without waiting for them all to finish.</p>
<p>In summary, finalizers can be delayed indefinitely if your program is either idle or busy, and are not guaranteed to run. But it gets worse—you can’t actually do much that is useful in a finalizer.</p>
<p>You might think that a finalizer would be a good place to ensure that certain work is properly completed. For example, if your object writes data to a file but buffers that data so as to be able to write a small number of large chunks rather than writing in tiny dribs and drabs (because large writes are often more efficient), you might think that finalization is the obvious place to ensure that data in your buffers has been safely flushed out to disk. But think again.</p>
<p>During finalization, an object cannot trust the other objects it has references to. If your object’s destructor runs, your object must have become unreachable. This means it’s highly likely that any other objects yours refers to have also become unreachable. The CLR is likely to discover the unreachability of groups of related objects simultaneously—if your object created three or four objects to help it do its job, the whole lot will become unreachable at the same time. The CLR makes no guarantees about the order in which it runs finalizers. This means it’s entirely possible that by the time your destructor runs, all the objects you were using have already been finalized. So, if they also perform any last-minute cleanup, it’s too late to use them. For example, the <code>FileStream</code> class, which derives from <code>Stream</code> and provides access to a file, closes its file handle in its destructor. Thus, if you were hoping to flush your data out to the <code>FileStream</code>, it’s too late—the file stream may well already be closed.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>To be fair, things are marginally less bad than I’ve made them sound so far. Although the CLR does not guarantee to run most finalizers, it will usually run them in practice. The absence of guarantees matters only in relatively extreme situations. Even so, this doesn’t mitigate the fact that you cannot, in general, rely on other objects in your destructor.</p>
</div>
<p>Since destructors seem to be of remarkably little use—that is, you can have no idea if or when they will run, and you can’t use other objects inside a destructor—then what use are they?</p>
<p>The main reason finalization exists at all is to make it possible to write .NET types that are wrappers for the sorts of entities that are traditionally represented by handles—things like files and sockets. These are created and managed outside of the CLR—files and sockets require the operating system to allocate resources; libraries may also provide handle-based APIs, and they will typically allocate memory on their own private heaps to store information about whatever the handle represents. The CLR cannot see these activities—all it sees is a .NET object with a field containing an integer, and it has no idea that the integer is a handle for some resource outside of the CLR. So it doesn’t know that it’s important that the handle be closed when the object falls out of use. This is where finalizers come in: they are a place to put code that tells something external to the CLR that the entity represented by the handle is no longer in use. The inability to use other objects is not a problem in this scenario.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you are writing code that wraps a handle, you should normally use one of the built-in classes that derive from <code>SafeHandle</code> or, if absolutely necessary, derive your own. This base class extends the basic finalization mechanism with some handle-oriented helpers. Furthermore, it gets special handling from the interop layer to avoid premature freeing of resources.</p>
</div>
<p>There are some other uses for finalization, although the unpredictability and unreliability already discussed mean there are limits to what it can do for you. Some classes contain a finalizer that does nothing other than check that the object was not abandoned in a state where it had unfinished work. <a data-primary="Flush method" data-type="indexterm" id="idm45884815439040"/>For example, if you had written a class that buffers data before writing it to a file, as described previously, you would need to define some method that callers should use when they are done with your object (perhaps called <code>Flush</code> or <code>Close</code>), and you could write a finalizer that checks to see if the object was put into a safe state before being abandoned, raising an error if not. This would provide a way to discover when programs have forgotten to clean things up correctly.</p>
<p>If you write a finalizer, you should disable it when your object is in a state where it no longer requires finalization, because finalization has its costs. <a data-primary="SuppressFinalize method" data-type="indexterm" id="idm45884815436480"/><a data-primary="GC class" data-secondary="SuppressFinalize method" data-type="indexterm" id="idm45884815435776"/>If you offer a <code>Close</code> or <code>Flush</code> method, finalization is unnecessary once these have been called, so you should call the <code>System.GC</code> class’s <code>SuppressFinalize</code> method to let the GC know that your object no longer needs to be finalized. If your object’s state subsequently changes, you can call the <code>ReRegisterForFinalize</code> method to reenable it.</p>
<p>The greatest cost of finalization is that it guarantees that your object will survive at least into the first generation and possibly beyond. Remember, all objects that survive from generation 0 make it into generation 1. If your object has a finalizer, and you have not disabled it by calling <code>SuppressFinalize</code>, the CLR cannot get rid of your object until it has run its finalizer. And since finalizers run asynchronously on a separate thread, the object has to remain alive even though it has been found to be unreachable. So the object is not yet collectable, even though it is unreachable. It therefore lives on into generation 1. It will usually be finalized shortly afterward, meaning that the object will then become a waste of space until a generation 1 collection occurs. Those happen rather less frequently than generation 0 collections. If your object had already made it into generation 1 before becoming unreachable, a finalizer increases the chances of getting into generation 2 just before it is about to fall out of use. A finalized object therefore makes inefficient use of memory, which is a reason to avoid finalization, and a reason to disable it whenever possible in objects that do sometimes require it.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Even though <code>SuppressFinalize</code> can save you from the most egregious costs of finalization, an object that uses this technique still has higher overheads than an object with no finalizer at all. The CLR does some extra work when constructing finalizable objects to keep track of those that have not yet been finalized. (Calling 
<span class="keep-together"><code>SuppressFinalize</code></span> just takes your object back out of this tracking list.) So, although suppressing finalization is much better than letting it occur, it’s better still if you don’t ask for it in the first place.</p>
</div>
<p>A slightly weird upshot of finalization is that an object that the GC discovered was unreachable can make itself reachable again. It’s possible to write a destructor that stores the <code>this</code> reference in a root reference, or perhaps in a collection that is reachable via a root reference. Nothing stops you from doing this, and the object will continue to work (although its finalizer will not run a second time if the object becomes unreachable again), but it’s an odd thing to do. This is referred to as <em>resurrection</em>, and just because you can do it doesn’t mean you should. It is best avoided.</p>
<p>I hope that by now, I have convinced you that destructors do not provide a general-purpose mechanism for shutting down objects cleanly. They are mostly useful only for dealing with handles for things that live outside of the CLR’s control, and it’s best to avoid relying on them. If you need timely, reliable cleanup of resources, there’s a better mechanism.<a data-startref="ix_ch07-asciidoc21" data-type="indexterm" id="idm45884815426736"/><a data-startref="ix_ch07-asciidoc20" data-type="indexterm" id="idm45884815401184"/><a data-startref="ix_ch07-asciidoc19" data-type="indexterm" id="idm45884815400576"/></p>
</div></section>
<section data-pdf-bookmark="IDisposable" data-type="sect1"><div class="sect1" id="idisposable">
<h1>IDisposable</h1>
<p><a data-primary="disposal" data-secondary="IDisposable interface" data-type="indexterm" id="ix_ch07-asciidoc22"/><a data-primary="IDisposable interface" data-type="indexterm" id="ix_ch07-asciidoc23"/><a data-primary="object lifetime" data-secondary="IDisposable" data-type="indexterm" id="ix_ch07-asciidoc24"/>The runtime libraries define an interface called <code>IDisposable</code>. The CLR does not treat this interface as being in any way special, but C# has some built-in support for it. <code>IDisposable</code> is a simple abstraction; as <a data-type="xref" href="#the_idisposable_interface">Example 7-8</a> shows, it defines just one member, the <code>Dispose</code> method.</p>
<div data-type="example" id="the_idisposable_interface">
<h5><span class="label">Example 7-8. </span>The <code>IDisposable</code> interface</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">interface</code> <code class="n">IDisposable</code>
<code class="p">{</code>
    <code class="k">void</code> <code class="nf">Dispose</code><code class="p">();</code>
<code class="p">}</code></pre></div>
<p><a data-primary="Dispose method" data-secondary="IDisposable interface and" data-type="indexterm" id="ix_ch07-asciidoc25"/>The idea behind <code>IDisposable</code> is straightforward. If your code creates an object that implements this interface, you should call <code>Dispose</code> once you’ve finished using that object (with the occasional exception—see <a data-type="xref" href="#optional_disposal">“Optional Disposal”</a>). This then provides the object with an opportunity to free up resources it may have allocated. If the object being disposed of was using resources represented by handles, it will typically close those handles immediately rather than waiting for finalization to kick in (and it should suppress finalization at the same time). If the object was using services on some remote machine in a stateful way—perhaps holding a connection open to a server to be able to make requests—it would immediately let the remote system know that it no longer requires the services, in whatever way is necessary (for example, by closing the connection).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>There is a persistent myth that calling <code>Dispose</code> causes the GC to do something. You may read on the web that <code>Dispose</code> finalizes the object, or even that it causes the object to be garbage collected. This is nonsense. The CLR does not handle <code>IDisposable</code> or <code>Dispose</code> differently than any other interface or method.</p>
</div>
<p class="widows_6"><code>IDisposable</code> is important because it’s possible for an object to consume very little memory and yet tie up some expensive resources. For example, consider an object that represents a connection to a database. Such an object might not need many fields—it could even have just a single field containing a handle representing the connection. From the CLR’s point of view, this is a pretty cheap object, and we could allocate hundreds of them without triggering a GC. But in the database server, things would look different—it might need to allocate a considerable amount of memory for each incoming connection. Connections might even be strictly limited by licensing terms. (This illustrates that “resource” is a fairly broad concept—it means pretty much anything that you might run out of.)</p>
<p>Relying on GC to notice when database connection objects are no longer in use is likely to be a bad strategy. The CLR will know that we’ve allocated, say, 50 of the things, but if that consumes only a few hundred bytes in total, it will see no reason to run the GC. And yet our application may be about to grind to a halt—if we have only 50 connection licenses for the database, the next attempt to create a connection will fail. And even if there’s no licensing limitation, we could still be making highly inefficient use of database resources by opening far more connections than we need.</p>
<p>It’s imperative that we close connection objects as soon as we can, without waiting for the GC to tell us which ones are out of use. This is where <code>IDisposable</code> comes in. It’s not just for database connections, of course. It’s critically important for any object that is a front for something that lives outside the CLR, such as a file or a network connection. Even for resources that aren’t especially constrained, <code>IDisposable</code> provides a way to tell objects when we’re finished with them so that they can shut down cleanly, solving the problem described earlier for objects that perform internal buffering.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If a resource is expensive to create, you may want to reuse it. This is often the case with database connections, so the usual practice is to maintain a pool of connections. Instead of closing a connection when you’re finished with it, you return it to the pool, making it available for reuse. (Many of .NET’s data access providers can do this for you.) The <code>IDisposable</code> model is still useful here. When you ask a resource pool for a resource, it usually provides a wrapper around the real resource, and when you dispose that wrapper, it returns the resource to the pool instead of freeing it. So calling <code>Dispose</code> is really just a way of saying, “I’m done with this object,” and it’s up to the <code>IDisposable</code> implementation to decide what to do next with the resource it represents.</p>
</div>
<p class="pagebreak-after">Implementations of <code>IDisposable</code> are required to tolerate multiple calls to <code>Dispose</code>. Although this means consumers can call <code>Dispose</code> multiple times without harm, they should not attempt to use an object after it has been disposed. In fact, the runtime libraries define a special exception that objects can throw if you misuse them in this way: <code>ObjectDisposedException</code>. (I will discuss exceptions in <a data-type="xref" href="ch08.xhtml#ch_exceptions">Chapter 8</a>.)</p>
<p>You’re free to call <code>Dispose</code> directly, of course, but C# also supports <code>IDisposable</code> in <a data-primary="using statement" data-type="indexterm" id="idm45884815357184"/>three ways: <code>foreach</code> loops, <code>using</code> statements, and <code>using</code> declarations. A <code>using</code> statement is a way to ensure that you reliably dispose an object that implements <code>IDisposable</code> once you’re done with it. <a data-type="xref" href="#a_using_statement">Example 7-9</a> shows how to use it.</p>
<div data-type="example" id="a_using_statement">
<h5><span class="label">Example 7-9. </span>A <code>using</code> statement</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">using</code> <code class="p">(</code><code class="n">StreamReader</code> <code class="n">reader</code> <code class="p">=</code> <code class="n">File</code><code class="p">.</code><code class="n">OpenText</code><code class="p">(</code><code class="s">@"C:\temp\File.txt"</code><code class="p">))</code>
<code class="p">{</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">reader</code><code class="p">.</code><code class="n">ReadToEnd</code><code class="p">());</code>
<code class="p">}</code></pre></div>
<p>This is equivalent to the code in <a data-type="xref" href="#how_using_statements_expand">Example 7-10</a>. The <code>try</code> and <code>finally</code> keywords are part of C#’s exception handling system, which I’ll discuss in detail in <a data-type="xref" href="ch08.xhtml#ch_exceptions">Chapter 8</a>. In this case, they’re being used to ensure that the call to <code>Dispose</code> inside the <code>finally</code> block executes even if something goes wrong in the code inside the <code>try</code> block. This also ensures that <code>Dispose</code> gets called if you execute a <code>return</code> statement in the middle of the block. (It even works if you use <a data-primary="goto statement" data-type="indexterm" id="idm45884815309584"/>a <code>goto</code> statement to jump out of it.)</p>
<div data-type="example" id="how_using_statements_expand">
<h5><span class="label">Example 7-10. </span>How <code>using</code> statements expand</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="p">{</code>
    <code class="n">StreamReader</code> <code class="n">reader</code> <code class="p">=</code> <code class="n">File</code><code class="p">.</code><code class="n">OpenText</code><code class="p">(</code><code class="s">@"C:\temp\File.txt"</code><code class="p">);</code>
    <code class="k">try</code>
    <code class="p">{</code>
        <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">reader</code><code class="p">.</code><code class="n">ReadToEnd</code><code class="p">());</code>
    <code class="p">}</code>
    <code class="k">finally</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">reader</code> <code class="p">!=</code> <code class="k">null</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="p">((</code><code class="n">IDisposable</code><code class="p">)</code> <code class="n">reader</code><code class="p">).</code><code class="n">Dispose</code><code class="p">();</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>If the variable type of the declaration in the <code>using</code> statement is a value type, C# will not generate the code that checks for <code>null</code> and will just invoke <code>Dispose</code> directly.</p>
<p class="widows_4"><a data-primary="using declaration" data-type="indexterm" id="idm45884815209504"/>C# supports a simpler alternative, a <code>using</code> declaration, shown in <a data-type="xref" href="#a_using_declaration">Example 7-11</a>. The difference is that we don’t need to provide a block. A <code>using</code> declaration disposes its variable when the variable goes out of scope. It still generates <code>try</code> and <code>finally</code> blocks, so in cases where a <code>using</code> statement’s block happens to finish at the end of some other block (e.g., it finishes at the end of a method), you can change to a <code>using</code> declaration with no change of behavior. This reduces the number of nested blocks, which can make your code easier to read. (On the other hand, with an ordinary <code>using</code> block, it may be easier to see exactly when the object is no longer used. So each style has its pros and cons.)</p>
<div data-type="example" id="a_using_declaration">
<h5><span class="label">Example 7-11. </span>A <code>using</code> declaration</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">using</code> <code class="nn">StreamReader</code> <code class="n">reader</code> <code class="p">=</code> <code class="n">File</code><code class="p">.</code><code class="n">OpenText</code><code class="p">(</code><code class="s">@"C:\temp\File.txt"</code><code class="p">);</code>
<code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">reader</code><code class="p">.</code><code class="n">ReadToEnd</code><code class="p">());</code></pre></div>
<p>If you need to use multiple disposable resources within the same scope, and you want to use a <code>using</code> statement, not a declaration (e.g., because you want to dispose the resources at the earliest opportunity instead of waiting for the relevant variables to go out of scope), you can nest them, but it might be easier to read if you stack multiple <code>using</code> statements in front of a single block. <a data-type="xref" href="#stacking_using_statements">Example 7-12</a> uses this to copy the contents of one file to another.</p>
<div data-type="example" id="stacking_using_statements">
<h5><span class="label">Example 7-12. </span>Stacking <code>using</code> statements</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">using</code> <code class="p">(</code><code class="n">Stream</code> <code class="n">source</code> <code class="p">=</code> <code class="n">File</code><code class="p">.</code><code class="n">OpenRead</code><code class="p">(</code><code class="s">@"C:\temp\File.txt"</code><code class="p">))</code>
<code class="k">using</code> <code class="p">(</code><code class="n">Stream</code> <code class="n">copy</code> <code class="p">=</code> <code class="n">File</code><code class="p">.</code><code class="n">Create</code><code class="p">(</code><code class="s">@"C:\temp\Copy.txt"</code><code class="p">))</code>
<code class="p">{</code>
    <code class="n">source</code><code class="p">.</code><code class="n">CopyTo</code><code class="p">(</code><code class="n">copy</code><code class="p">);</code>
<code class="p">}</code></pre></div>
<p>Stacking <code>using</code> statements is not a special syntax; it’s just an upshot of the fact that a <code>using</code> statement is always followed by a single embedded statement, which will be executed before <code>Dispose</code> gets called. Normally, that statement is a block, but in <a data-type="xref" href="#stacking_using_statements">Example 7-12</a>, the first <code>using</code> statement’s embedded statement is the second <code>using</code> statement. If you use <code>using</code> declarations instead, stacking is unnecessary because these don’t have an associated embedded statement.</p>
<p>A <code>foreach</code> loop generates code that will use <code>IDisposable</code> if the enumerator implements it. <a data-type="xref" href="#a_foreach_loop">Example 7-13</a> shows a <code>foreach</code> loop that uses just such an enumerator.</p>
<div data-type="example" id="a_foreach_loop">
<h5><span class="label">Example 7-13. </span>A <code>foreach</code> loop</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">foreach</code> <code class="p">(</code><code class="kt">string</code> <code class="n">file</code> <code class="k">in</code> <code class="n">Directory</code><code class="p">.</code><code class="n">EnumerateFiles</code><code class="p">(</code><code class="s">@"C:\temp"</code><code class="p">))</code>
<code class="p">{</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">file</code><code class="p">);</code>
<code class="p">}</code></pre></div>
<p class="pagebreak-before">The <code>Directory</code> class’s <code>EnumerateFiles</code> method returns an <code>IEnumerable&lt;string&gt;</code>. As you saw in <a data-type="xref" href="ch05.xhtml#ch_collections">Chapter 5</a>, this has a <code>GetEnumerator</code> method that returns an <code>IEnumer⁠ator​&lt;string&gt;</code>, an interface that inherits from <code>IDisposable</code>. Consequently, the C# compiler will produce code equivalent to <a data-type="xref" href="#how_foreach_loops_expand">Example 7-14</a>.</p>
<div data-type="example" id="how_foreach_loops_expand">
<h5><span class="label">Example 7-14. </span>How <code>foreach</code> loops expand</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="p">{</code>
    <code class="n">IEnumerator</code><code class="p">&lt;</code><code class="kt">string</code><code class="p">&gt;</code> <code class="n">e</code> <code class="p">=</code>
        <code class="n">Directory</code><code class="p">.</code><code class="n">EnumerateFiles</code><code class="p">(</code><code class="s">@"C:\temp"</code><code class="p">).</code><code class="n">GetEnumerator</code><code class="p">();</code>
    <code class="k">try</code>
    <code class="p">{</code>
        <code class="k">while</code> <code class="p">(</code><code class="n">e</code><code class="p">.</code><code class="n">MoveNext</code><code class="p">())</code>
        <code class="p">{</code>
            <code class="kt">string</code> <code class="n">file</code> <code class="p">=</code> <code class="n">e</code><code class="p">.</code><code class="n">Current</code><code class="p">;</code>
            <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">file</code><code class="p">);</code>
        <code class="p">}</code>
    <code class="p">}</code>
    <code class="k">finally</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">e</code> <code class="p">!=</code> <code class="k">null</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="p">((</code><code class="n">IDisposable</code><code class="p">)</code> <code class="n">e</code><code class="p">).</code><code class="n">Dispose</code><code class="p">();</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>There are a few variations the compiler can produce, depending on the collection’s enumerator type. If it’s a value type that implements <code>IDisposable</code>, the compiler won’t generate the check for <code>null</code> in the <code>finally</code> block (just as in a <code>using</code> statement). If the static type of the enumerator does not implement <code>IDisposable</code>, the outcome depends on whether the type is open for inheritance. If it is sealed, or if it is a value type, the compiler will not generate code that attempts to call <code>Dispose</code> at all. If it is not sealed, the compiler generates code in the <code>finally</code> block that tests at runtime whether the enumerator implements <code>IDisposable</code>, calling <code>Dispose</code> if it does and doing nothing otherwise.</p>
<p>The <code>IDisposable</code> interface is easiest to consume when you obtain a resource and finish using it in the same method, because you can write a <code>using</code> statement (or where applicable, a <code>foreach</code> loop) to ensure that you call <code>Dispose</code>. But sometimes, you will write a class that creates a disposable object and puts a reference to it in a field, because it will need to use that object over a longer timescale. For example, you might write a logging class, and if a logger object writes data to a file, it might hold on to a <code>StreamWriter</code> object. C# provides no automatic help here, so it’s up to you to ensure that any contained objects get disposed. You would write your own implementation of <code>IDisposable</code> that disposes the other objects, as <a data-type="xref" href="#disposing_a_contained_instance">Example 7-15</a> does. Note that this example sets <code>_file</code> to <code>null</code>, so it will not attempt to dispose the file twice. This is not strictly necessary, because the <code>StreamWriter</code> will tolerate multiple calls to <code>Dispose</code>. But it does give the <code>Logger</code> object an easy way to know that it is in a disposed state, so if we were to add some real methods, we could check <code>_file</code> and throw an <code>ObjectDisposedException</code> if it is <code>null</code>.</p>
<div data-type="example" id="disposing_a_contained_instance">
<h5><span class="label">Example 7-15. </span>Disposing a contained instance</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">sealed</code> <code class="k">class</code> <code class="nc">Logger</code> <code class="p">:</code> <code class="n">IDisposable</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="n">StreamWriter</code><code class="p">?</code> <code class="n">_file</code><code class="p">;</code>

    <code class="k">public</code> <code class="nf">Logger</code><code class="p">(</code><code class="kt">string</code> <code class="n">filePath</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">_file</code> <code class="p">=</code> <code class="n">File</code><code class="p">.</code><code class="n">CreateText</code><code class="p">(</code><code class="n">filePath</code><code class="p">);</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Dispose</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">_file</code> <code class="p">!=</code> <code class="k">null</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="n">_file</code><code class="p">.</code><code class="n">Dispose</code><code class="p">();</code>
            <code class="n">_file</code> <code class="p">=</code> <code class="k">null</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code>
    <code class="c1">// A real class would go on to do something with the StreamWriter, of course</code>
<code class="p">}</code></pre></div>
<p>This example dodges an important problem. The class is sealed, which avoids the issue of how to cope with inheritance. If you write an unsealed class that implements <code>IDisposable</code>, you should provide a way for a derived class to add its own disposal logic. The most straightforward solution would be to make <code>Dispose</code> virtual so that a derived class can override it, performing its own cleanup in addition to calling your base implementation. However, there is a more complicated pattern that you will see from time to time in .NET.</p>
<p>Some objects implement <code>IDisposable</code> and also have a finalizer. Since the introduction of <code>SafeHandle</code> and related classes, it’s relatively unusual for a class to need to provide both (unless it derives from <code>SafeHandle</code>). Only wrappers for handles <span class="keep-together">normally</span> need finalization, and classes that use handles now typically defer to a <span class="keep-together"><code>SafeHandle</code></span> to provide that, rather than implementing their own finalizers. However, there are exceptions, and some library types implement a pattern designed to support both finalization and <code>IDisposable</code>, allowing you to provide custom behaviors for both in derived classes. For example, the <code>Stream</code> base class works this way.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>This pattern is called the <em>dispose pattern</em>, but do not take that to mean that you should normally use this when implementing <code>IDisposable</code>. On the contrary, it is extremely unusual to need this pattern. Even back when it was invented, few classes needed it, and now that we have <code>SafeHandle</code>, it is almost never necessary. (<code>SafeHandle</code> was introduced in .NET 2.0, so it has been a very long time since the dispose pattern was broadly useful.) Unfortunately, some people misunderstood the narrow utility of this pattern, so you will find a certain amount of well-intentioned but utterly wrong advice telling you that you should use this for all <code>IDisposable</code> implementations. Ignore it. The pattern’s main relevance today is that you sometimes encounter it in old types such as <code>Stream</code>.</p>
</div>
<p>The pattern is to define a protected overload of <code>Dispose</code> that takes a single <code>bool</code> argument. The base class calls this from its public <code>Dispose</code> method and also its destructor, passing in <code>true</code> or <code>false</code>, respectively. That way, you have to override only one method, the protected <code>Dispose</code>. It can contain logic common to both finalization and disposal, such as closing handles, but you can also perform any disposal-specific or finalization-specific logic because the argument tells you which sort of cleanup is being performed. <a data-type="xref" href="#custom_finalization_and_disposal_logic">Example 7-16</a> shows how this might look. (This is for illustration only—the <code>MyCustomLibraryInteropWrapper</code> class has been made up for this example.)</p>
<div data-type="example" id="custom_finalization_and_disposal_logic">
<h5><span class="label">Example 7-16. </span>Custom finalization and disposal logic</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">public</code> <code class="k">class</code> <code class="nc">MyFunkyStream</code> <code class="p">:</code> <code class="n">Stream</code>
<code class="p">{</code>
    <code class="c1">// For illustration purposes only. Usually better to avoid this whole</code>
    <code class="c1">// pattern and to use some type derived from SafeHandle instead.</code>
    <code class="k">private</code> <code class="n">IntPtr</code> <code class="n">_myCustomLibraryHandle</code><code class="p">;</code>
    <code class="k">private</code> <code class="n">Logger</code><code class="p">?</code> <code class="n">_log</code><code class="p">;</code>

    <code class="k">protected</code> <code class="k">override</code> <code class="k">void</code> <code class="nf">Dispose</code><code class="p">(</code><code class="kt">bool</code> <code class="n">disposing</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="k">base</code><code class="p">.</code><code class="n">Dispose</code><code class="p">(</code><code class="n">disposing</code><code class="p">);</code>

        <code class="k">if</code> <code class="p">(</code><code class="n">_myCustomLibraryHandle</code> <code class="p">!=</code> <code class="n">IntPtr</code><code class="p">.</code><code class="n">Zero</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="n">MyCustomLibraryInteropWrapper</code><code class="p">.</code><code class="n">Close</code><code class="p">(</code><code class="n">_myCustomLibraryHandle</code><code class="p">);</code>
            <code class="n">_myCustomLibraryHandle</code> <code class="p">=</code> <code class="n">IntPtr</code><code class="p">.</code><code class="n">Zero</code><code class="p">;</code>
        <code class="p">}</code>
        <code class="k">if</code> <code class="p">(</code><code class="n">disposing</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="k">if</code> <code class="p">(</code><code class="n">_log</code> <code class="p">!=</code> <code class="k">null</code><code class="p">)</code>
            <code class="p">{</code>
                <code class="n">_log</code><code class="p">.</code><code class="n">Dispose</code><code class="p">();</code>
                <code class="n">_log</code> <code class="p">=</code> <code class="k">null</code><code class="p">;</code>
            <code class="p">}</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="c1">// ...overloads of Stream's abstract methods would go here</code>
<code class="p">}</code></pre></div>
<p>This hypothetical example is a custom implementation of the <code>Stream</code> abstraction that uses some external non-.NET library that provides handle-based access to resources. We prefer to close the handle when the public <code>Dispose</code> method is called, but if that hasn’t happened by the time our finalizer runs, we want to close the handle then. So the code checks to see if the handle is still open and closes it if necessary, and it does this whether the call to the <code>Dispose(bool)</code> overload happened as a result of the object being explicitly disposed or being finalized—we need to ensure that the handle is closed in either case. However, this class also appears to use an instance of the <code>Logger</code> class from <a data-type="xref" href="#disposing_a_contained_instance">Example 7-15</a>. Because that’s an ordinary object, we shouldn’t attempt to use it during finalization, so we attempt to dispose it only if our object is being disposed. If we are being finalized, then although <code>Logger</code> itself is not finalizable, it uses a <code>FileStream</code>, which is finalizable; and it’s quite possible that the <code>FileStream</code> finalizer will already have run by the time our <code>MyFunkyStream</code> class’s finalizer runs, so it would be a bad idea to call methods on the <code>Logger</code>.</p>
<p>When a base class provides this virtual protected form of <code>Dispose</code>, it should call <code>GC.SuppressFinalization</code> in its public <code>Dispose</code>. The <code>Stream</code> base class does this. More generally, if you find yourself writing a class that offers both <code>Dispose</code> and a finalizer, then whether or not you choose to support inheritance with this pattern, you should in any case suppress finalization when <code>Dispose</code> is called.</p>
<p>Since I’ve recommended avoiding this pattern, what should code like <a data-type="xref" href="#disposing_a_contained_instance">Example 7-15</a> do if using <code>sealed</code> is unacceptable? The answer is straightforward: if you are writing a class that implements <code>IDisposable</code> and you want that class to be open for inheritance (i.e., not <code>sealed</code>), make your <code>Dispose</code> method <code>virtual</code>. That way, derived types can override it to add their own disposal logic (and these overrides should always call the base class’s <code>Dispose</code>).</p>
<section data-pdf-bookmark="Optional Disposal" data-type="sect2"><div class="sect2" id="optional_disposal">
<h2>Optional Disposal</h2>
<p><a data-primary="disposal" data-secondary="optional" data-type="indexterm" id="idm45884814676640"/>Although you should call <code>Dispose</code> at some point on most objects that implement <code>IDisposable</code>, there are a few exceptions. For example, the Reactive Extensions for .NET (described in <a data-type="xref" href="ch11.xhtml#ch_reactive_extensions">Chapter 11</a>) provide <code>IDisposable</code> objects that represent subscriptions to streams of events. You can call <code>Dispose</code> to unsubscribe, but some event sources come to a natural end, automatically shutting down any subscriptions. If that happens, you are not required to call <code>Dispose</code>. Also, the <code>Task</code> type, which is used extensively in conjunction with the asynchronous programming techniques described in <a data-type="xref" href="ch17.xhtml#ch_asynchronous_language_features">Chapter 17</a>, implements <code>IDisposable</code> but does not need to be disposed unless you cause it to allocate a <code>WaitHandle</code>, something that will not occur in normal usage. The way <code>Task</code> is generally used makes it particularly awkward to find a good time to call <code>Dispose</code> on it, so it’s fortunate that it’s not normally necessary.<a data-startref="ix_ch07-asciidoc25" data-type="indexterm" id="idm45884814669008"/></p>
<p><a data-primary="HttpClient class" data-type="indexterm" id="idm45884814667872"/>The <code>HttpClient</code> class is another exception to the normal rules but in a different way. We rarely call <code>Dispose</code> on instances of this type, but in this case it’s because we are encouraged to reuse instances. If you construct, use, and dispose an <code>HttpClient</code> each time you need one, you will defeat its ability to reuse existing connections when making multiple requests to the same server. This can cause two problems. First, opening an HTTP connection can sometimes take longer than sending the request and receiving the response, so preventing <code>HttpClient</code> from reusing connections to send multiple requests over time can cause significant performance problems. Connection reuse only works if you reuse the <code>HttpClient</code>.<sup><a data-type="noteref" href="ch07.xhtml#idm45884814664400" id="idm45884814664400-marker">9</a></sup> Second, the TCP protocol (which underpins HTTP) has characteristics that mean the OS cannot always instantly reclaim all the resources associated with a connection: it may need to keep the connection’s TCP port reserved for a considerable time (maybe a few minutes) after you’ve told the OS to close the connection, and it’s possible to run out of ports, preventing all further communication.</p>
<p>Such exceptions are unusual. It is only safe to omit calls to <code>Dispose</code> when the documentation for the class you’re using explicitly states that it is not required.<a data-startref="ix_ch07-asciidoc24" data-type="indexterm" id="idm45884814660976"/><a data-startref="ix_ch07-asciidoc23" data-type="indexterm" id="idm45884814660272"/><a data-startref="ix_ch07-asciidoc22" data-type="indexterm" id="idm45884814659600"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Boxing" data-type="sect1"><div class="sect1" id="boxing">
<h1>Boxing</h1>
<p><a data-primary="boxing" data-type="indexterm" id="ix_ch07-asciidoc26"/><a data-primary="object lifetime" data-secondary="boxing" data-type="indexterm" id="ix_ch07-asciidoc27"/>While I’m discussing GC and object lifetime, there’s one more topic I should talk about in this chapter: <em>boxing</em>. Boxing is the process that enables a variable of type <code>object</code> to refer to a value type. An <code>object</code> variable is capable only of holding a reference to something on the heap, so how can it refer to an <code>int</code>? What happens when the code in <a data-type="xref" href="#using_an_int_as_an_object">Example 7-17</a> runs?</p>
<div data-type="example" id="using_an_int_as_an_object">
<h5><span class="label">Example 7-17. </span>Using an <code>int</code> as an object</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">static</code> <code class="k">void</code> <code class="nf">Show</code><code class="p">(</code><code class="kt">object</code> <code class="n">o</code><code class="p">)</code>
<code class="p">{</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">o</code><code class="p">.</code><code class="n">ToString</code><code class="p">());</code>
<code class="p">}</code>

<code class="kt">int</code> <code class="n">num</code> <code class="p">=</code> <code class="m">42</code><code class="p">;</code>
<code class="n">Show</code><code class="p">(</code><code class="n">num</code><code class="p">);</code></pre></div>
<p>The <code>Show</code> method expects an object, and I’m passing it <code>num</code>, which is a local variable of the value type <code>int</code>. In these circumstances, C# generates a box, which is essentially a reference type wrapper for a value. The CLR can automatically provide a box for any value type, although if it didn’t, you could write your own class that does something similar. <a data-type="xref" href="#not_actually_how_a_box_works">Example 7-18</a> shows a hand-built box.</p>
<div data-type="example" id="not_actually_how_a_box_works">
<h5><span class="label">Example 7-18. </span>Not actually how a box works</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="c1">// Not a real box but similar in effect.</code>
<code class="k">public</code> <code class="k">class</code> <code class="nc">Box</code><code class="p">&lt;</code><code class="n">T</code><code class="p">&gt;</code>
    <code class="k">where</code> <code class="n">T</code> <code class="p">:</code> <code class="k">struct</code>
<code class="p">{</code>
    <code class="k">public</code> <code class="k">readonly</code> <code class="n">T</code> <code class="n">Value</code><code class="p">;</code>
    <code class="k">public</code> <code class="nf">Box</code><code class="p">(</code><code class="n">T</code> <code class="n">v</code><code class="p">)</code>
    <code class="p">{</code>
        <code class="n">Value</code> <code class="p">=</code> <code class="n">v</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="k">public</code> <code class="k">override</code> <code class="kt">string?</code> <code class="n">ToString</code><code class="p">()</code> <code class="p">=&gt;</code> <code class="n">Value</code><code class="p">.</code><code class="n">ToString</code><code class="p">();</code>
    <code class="k">public</code> <code class="k">override</code> <code class="kt">bool</code> <code class="nf">Equals</code><code class="p">(</code><code class="kt">object?</code> <code class="n">obj</code><code class="p">)</code> <code class="p">=&gt;</code> <code class="n">Value</code><code class="p">.</code><code class="n">Equals</code><code class="p">(</code><code class="n">obj</code><code class="p">);</code>
    <code class="k">public</code> <code class="k">override</code> <code class="kt">int</code> <code class="nf">GetHashCode</code><code class="p">()</code> <code class="p">=&gt;</code> <code class="n">Value</code><code class="p">.</code><code class="n">GetHashCode</code><code class="p">();</code>
<code class="p">}</code></pre></div>
<p>This is a fairly ordinary class that contains a single instance of a value type as its only field. If you invoke the standard members of <code>object</code> on the box, this class’s overrides make it look as though you invoked them directly on the field itself. So, if I passed <code>new Box&lt;int&gt;(num)</code> as the argument to <code>Show</code> in <a data-type="xref" href="#using_an_int_as_an_object">Example 7-17</a>, <code>Show</code> would receive a reference to that box. When <code>Show</code> called <code>ToString</code>, the box would call the <code>int</code> field’s <code>ToString</code>, so you’d expect the program to display 42.</p>
<p>We don’t need to write <a data-type="xref" href="#not_actually_how_a_box_works">Example 7-18</a>, because the CLR will build the box for us. It will create an object on the heap that contains a copy of the boxed value and forward the standard <code>object</code> methods to the boxed value. And it does some things that we can’t. If you ask a boxed <code>int</code> its type by calling <code>GetType</code>, it will return the same <code>Type</code> object as you’d get if you called <code>GetType</code> directly on an <code>int</code> variable—I can’t do that with my custom <code>Box&lt;T&gt;</code>, because <code>GetType</code> is not virtual. <a data-primary="unbox operation" data-type="indexterm" id="idm45884814473088"/>Also, getting back the underlying value is easier than it would be with a hand-built box, because unboxing is an intrinsic CLR feature.</p>
<p>If you have a reference of type <code>object</code>, and you cast it to <code>int</code>, the CLR checks to see if the reference does indeed refer to a boxed <code>int</code>; if it does, the CLR returns a copy of the boxed value. <a data-primary="InvalidCastException type" data-type="indexterm" id="idm45884814470496"/>(If not, it throws an <code>InvalidCastException</code>.) So, inside the <code>Show</code> method of <a data-type="xref" href="#using_an_int_as_an_object">Example 7-17</a>, I could write <code>(int) o</code> to get back a copy of the original value, whereas if I were using the class in <a data-type="xref" href="#not_actually_how_a_box_works">Example 7-18</a>, I’d need the more convoluted <code>((Box&lt;int&gt;) o).Value</code>.</p>
<p>I can also use pattern matching to extract a boxed value. <a data-type="xref" href="#unboxing_with_a_type_pattern">Example 7-19</a> uses a declaration pattern to detect whether the variable <code>o</code> contains a reference to a boxed <code>int</code>, and if it does, it extracts that into the local variable <code>i</code>. As we saw in <a data-type="xref" href="ch02.xhtml#ch_basic_coding">Chapter 2</a>, when you use a pattern with the <code>is</code> operator like this, the resulting expression evaluates to <code>true</code> if the pattern matches and <code>false</code> if it does not. So the body of this <code>if</code> statement runs only if there was an <code>int</code> value there to be unboxed.</p>
<div data-type="example" id="unboxing_with_a_type_pattern">
<h5><span class="label">Example 7-19. </span>Unboxing a value with a type pattern</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">if</code> <code class="p">(</code><code class="n">o</code> <code class="k">is</code> <code class="kt">int</code> <code class="n">i</code><code class="p">)</code>
<code class="p">{</code>
    <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="n">i</code> <code class="p">*</code> <code class="m">2</code><code class="p">);</code>
<code class="p">}</code></pre></div>
<p>Boxes are automatically available for all structs,<sup><a data-type="noteref" href="ch07.xhtml#idm45884814438672" id="idm45884814438672-marker">10</a></sup> not just the built-in value types. If the struct implements any interfaces, the box will provide all the same interfaces. (That’s another trick that <a data-type="xref" href="#not_actually_how_a_box_works">Example 7-18</a> cannot perform.)</p>
<p><a data-primary="conversions" data-secondary="implicit" data-type="indexterm" id="idm45884814436320"/><a data-primary="implicit conversions" data-secondary="boxing and" data-type="indexterm" id="idm45884814435344"/>Some implicit conversions cause boxing. You can see this in <a data-type="xref" href="#using_an_int_as_an_object">Example 7-17</a>. I have passed an expression of type <code>int</code> where <code>object</code> was required, without needing an explicit cast. Implicit conversions also exist between a value and any of the interfaces that value’s type implements. For example, you can assign a value of type <code>int</code> into a variable of type <code>IComparable&lt;int&gt;</code> (or pass it as a method argument of that type) without needing a cast. This causes a box to be created, because variables of any interface type are like variables of type <code>object</code>, in that they can hold only a reference to an item on the garbage-collected heap.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a data-primary="conversions" data-secondary="reference" data-type="indexterm" id="idm45884814430480"/><a data-primary="reference conversions" data-type="indexterm" id="idm45884814429280"/>Implicit boxing conversions are not implicit reference conversions. This means that they do not come into play with covariance or contravariance. For example, <code>IEnumerable&lt;int&gt;</code> is not compatible with <code>IEnumerable&lt;object&gt;</code> despite the existence of an implicit conversion from <code>int</code> to <code>object</code>, because that is not an implicit reference conversion.</p>
</div>
<p>Implicit boxing can occasionally cause problems for one of two reasons. First, it makes it easy to generate extra work for the GC. The CLR does not attempt to cache boxes, so if you write a loop that executes 100,000 times, and that loop contains an expression that uses an implicit boxing conversion, you’ll end up generating 100,000 boxes, which the GC will eventually have to clean up just like anything else on the heap. Second, each box operation (and each unbox) copies the value, which might not provide the semantics you were expecting. <a data-type="xref" href="#illustrating_the_pitfalls_of_mutable_str">Example 7-20</a> illustrates some potentially surprising behavior.</p>
<div data-type="example" id="illustrating_the_pitfalls_of_mutable_str">
<h5><span class="label">Example 7-20. </span>Illustrating the pitfalls of mutable structs</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="k">static</code> <code class="k">void</code> <code class="nf">CallDispose</code><code class="p">(</code><code class="n">IDisposable</code> <code class="n">o</code><code class="p">)</code>
<code class="p">{</code>
    <code class="n">o</code><code class="p">.</code><code class="n">Dispose</code><code class="p">();</code>
<code class="p">}</code>

<code class="n">DisposableValue</code> <code class="n">dv</code> <code class="p">=</code> <code class="k">new</code> <code class="p">();</code>
<code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Passing value variable:"</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">dv</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">dv</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">dv</code><code class="p">);</code>

<code class="n">IDisposable</code> <code class="n">id</code> <code class="p">=</code> <code class="n">dv</code><code class="p">;</code>
<code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Passing interface variable:"</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">id</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">id</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">id</code><code class="p">);</code>

<code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Calling Dispose directly on value variable:"</code><code class="p">);</code>
<code class="n">dv</code><code class="p">.</code><code class="n">Dispose</code><code class="p">();</code>
<code class="n">dv</code><code class="p">.</code><code class="n">Dispose</code><code class="p">();</code>
<code class="n">dv</code><code class="p">.</code><code class="n">Dispose</code><code class="p">();</code>

<code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Passing value variable:"</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">dv</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">dv</code><code class="p">);</code>
<code class="n">CallDispose</code><code class="p">(</code><code class="n">dv</code><code class="p">);</code>

<code class="k">public</code> <code class="k">struct</code> <code class="nc">DisposableValue</code> <code class="p">:</code> <code class="n">IDisposable</code>
<code class="p">{</code>
    <code class="k">private</code> <code class="kt">bool</code> <code class="n">_disposedYet</code><code class="p">;</code>

    <code class="k">public</code> <code class="k">void</code> <code class="nf">Dispose</code><code class="p">()</code>
    <code class="p">{</code>
        <code class="k">if</code> <code class="p">(!</code><code class="n">_disposedYet</code><code class="p">)</code>
        <code class="p">{</code>
            <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Disposing for first time"</code><code class="p">);</code>
            <code class="n">_disposedYet</code> <code class="p">=</code> <code class="k">true</code><code class="p">;</code>
        <code class="p">}</code>
        <code class="k">else</code>
        <code class="p">{</code>
            <code class="n">Console</code><code class="p">.</code><code class="n">WriteLine</code><code class="p">(</code><code class="s">"Was already disposed"</code><code class="p">);</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<p>The <code>DisposableValue</code> struct implements the <code>IDisposable</code> interface we saw earlier. It keeps track of whether it has been disposed already. The program contains a <code>CallDispose</code> method that calls <code>Dispose</code> on any <code>IDisposable</code> instance. The program declares a single variable of type <code>DisposableValue</code> and passes this to <code>CallDispose</code> three times. Here’s the output from that part of the program:</p>
<pre data-type="programlisting">Passing value variable:
Disposing for first time
Disposing for first time
Disposing for first time</pre>
<p>On all three occasions, the struct seems to think this is the first time we’ve called <code>Dispose</code> on it. That’s because each call to <code>CallDispose</code> created a new box—we are not really passing the <code>dv</code> variable; we are passing a newly boxed copy each time, so the <span class="keep-together"><code>CallDispose</code></span> method is working on a different instance of the struct each time. This is consistent with how value types normally work—even when there’s no boxing, when you pass one as an argument, you get a copy (unless you use the <code>ref</code> or <code>in</code> keywords).</p>
<p>The next part of the program ends up generating just a single box—it assigns the value into another local variable of type <code>IDisposable</code>. This uses the same implicit conversion as we did when passing the variable directly as an argument, so this creates yet another box, but it does so only once. We then pass the same reference to this particular box three times over, which explains why the output from this phase of the program looks different:</p>
<pre data-type="programlisting">Passing interface variable:
Disposing for first time
Was already disposed
Was already disposed</pre>
<p>These three calls to <code>CallDispose</code> all use the same box, which contains an instance of our struct, and so after the first call, it remembers that it has been disposed already. Next, our program calls <code>Dispose</code> directly on the local variable, producing this output:</p>
<pre data-type="programlisting">Calling Dispose directly on value variable:
Disposing for first time
Was already disposed
Was already disposed</pre>
<p>No boxing at all is involved here, so we are modifying the state of the local variable. Someone who only glanced at the code might not have expected this output—we have already passed the <code>dv</code> variable to a method that called <code>Dispose</code> on its argument, so it might be surprising to see that it thinks it hasn’t been disposed the first time around. But once you understand that <code>CallDispose</code> requires a reference and therefore cannot use a value directly, it’s clear that every call to <code>Dispose</code> before this point has operated on some boxed copy, and not the local variable.</p>
<p>Finally, we make three more calls passing the <code>dv</code> directly to <code>CallDispose</code> again. This is exactly what we did at the start of the code, so these calls generate yet more boxed copies. But this time, we are copying a value that’s already in the state of having been disposed, so we see different output:</p>
<pre data-type="programlisting">Passing value variable:
Was already disposed
Was already disposed
Was already disposed</pre>
<p>The behavior is all straightforward when you understand what’s going on, but it requires you to be mindful that you’re dealing with a value type and to understand when boxing causes implicit copying. This is one of the reasons Microsoft discourages developers from writing value types that can change their state—if a value cannot change, then a boxed value of that type also cannot change. It matters less whether you’re dealing with the original or a boxed copy, so there’s less scope for confusion, although it is still useful to understand when boxing will occur to avoid performance penalties.</p>
<p>Boxing used to be a much more common occurrence in early versions of .NET. Before generics arrived in .NET 2.0, collection classes all worked in terms of <code>object</code>, so if you wanted a resizable list of integers, you’d end up with a box for each <code>int</code> in the list. Generic collection classes do not cause boxing—a <code>List&lt;int&gt;</code> is able to store unboxed values directly.</p>
<section data-pdf-bookmark="Boxing Nullable&lt;T&gt;" data-type="sect2"><div class="sect2" id="boxing_nullableltg">
<h2>Boxing Nullable&lt;T&gt;</h2>
<p><a data-primary="Nullable&lt;T&gt; type" data-type="indexterm" id="idm45884814183936"/><a data-type="xref" href="ch03.xhtml#ch_types">Chapter 3</a> described the <code>Nullable&lt;T&gt;</code> type, a wrapper that adds null value support to any value type. Remember, C# has special syntax for this, in which you can just put a question mark on the end of a value type name, so we’d normally write <code>int?</code> instead of <code>Nullable&lt;int&gt;</code>. The CLR has special support for <code>Nullable&lt;T&gt;</code> when it comes to boxing.</p>
<p><code>Nullable&lt;T&gt;</code> itself is a value type, so if you attempt to get a reference to it, the compiler will generate code that attempts to box it, as it would with any other value type. However, at runtime, the CLR will not produce a box containing a copy of the <code>Nullable&lt;T&gt;</code> itself. Instead, it checks to see if the value is in a null state (i.e., its <code>HasValue</code> property returns <code>false</code>), and if so, it just returns <code>null</code>. Otherwise, it boxes the contained value. For example, if a <code>Nullable&lt;int&gt;</code> has a value, boxing it will produce a box of type <code>int</code>. This will be indistinguishable from the box you’d get if you had started with an ordinary <code>int</code> value. (One upshot of this is that the pattern matching shown in <a data-type="xref" href="#unboxing_with_a_type_pattern">Example 7-19</a> works whether the type of variable originally boxed was an <code>int</code> or an <code>int?</code>. You use <code>int</code> in the declaration pattern in either case.)</p>
<p><a data-primary="unbox operation" data-type="indexterm" id="idm45884814174448"/>You can unbox a boxed <code>int</code> into variables of either type <code>int?</code> or <code>int</code>. So all three unboxing operations in <a data-type="xref" href="#unboxing_an_int_to_nullable_and_nonnulla">Example 7-21</a> will succeed. They would also succeed if the first line were modified to initialize the <code>boxed</code> variable from a <code>Nullable&lt;int&gt;</code> that was not in the null state. (If you were to initialize <code>boxed</code> from a <code>Nullable&lt;int&gt;</code> in the null state, that would have the same effect as initializing it to <code>null</code>, in which case the final line of this example would throw a <code>NullReferenceException</code>.)</p>
<div data-type="example" id="unboxing_an_int_to_nullable_and_nonnulla">
<h5><span class="label">Example 7-21. </span>Unboxing an <code>int</code> to nullable and non-nullable variables</h5>
<pre data-code-language="csharp" data-type="programlisting"><code class="kt">object</code> <code class="n">boxed</code> <code class="p">=</code> <code class="m">42</code><code class="p">;</code>
<code class="kt">int?</code> <code class="n">nv</code> <code class="p">=</code> <code class="n">boxed</code> <code class="k">as</code> <code class="kt">int?</code><code class="p">;</code>
<code class="kt">int?</code> <code class="n">nv2</code> <code class="p">=</code> <code class="p">(</code><code class="kt">int?</code><code class="p">)</code> <code class="n">boxed</code><code class="p">;</code>
<code class="kt">int</code> <code class="n">v</code> <code class="p">=</code> <code class="p">(</code><code class="kt">int</code><code class="p">)</code> <code class="n">boxed</code><code class="p">;</code></pre></div>
<p>This is a runtime feature, and not simply the compiler being clever. The IL <code>box</code> instruction, which is what C# generates when it wants to box a value, detects <code>Nulla⁠ble​&lt;T&gt;</code> values; the <code>unbox</code> and <code>unbox.any</code> IL instructions are able to produce a <code>Nulla⁠ble​&lt;T&gt;</code> value from either a <code>null</code> or a reference to a boxed value of the underlying type. So, if you wrote your own wrapper type that looked like <code>Nullable&lt;T&gt;</code>, it would not behave in the same way; if you assigned a value of your type into an <code>object</code>, it would box your whole wrapper just like any other value. It’s only because the CLR knows about <code>Nullable&lt;T&gt;</code> that it behaves differently.<a data-startref="ix_ch07-asciidoc27" data-type="indexterm" id="idm45884814157584"/><a data-startref="ix_ch07-asciidoc26" data-type="indexterm" id="idm45884814140688"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="summary-id6">
<h1>Summary</h1>
<p>In this chapter, I described the heap that the runtime provides. I showed the strategy that the CLR uses to determine which heap objects can still be reached by your code, and the generation-based mechanism it uses to reclaim the memory occupied by objects that are no longer in use. The GC is not clairvoyant, so if your program keeps an object reachable, the GC has to assume that you might use that object in the future. This means you will sometimes need to be careful to make sure you don’t cause memory leaks by accidentally keeping hold of objects for too long. We looked at the finalization mechanism, and its various limitations and performance issues, and we also looked at <code>IDisposable</code>, which is the preferred system for cleaning up nonmemory resources. Finally, we saw how value types can act like reference types thanks to boxing.<a data-startref="ix_ch07-asciidoc0" data-type="indexterm" id="idm45884814138544"/></p>
<p>In the next chapter, I will show how C# presents the error-handling mechanisms of the CLR.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="CHP-7-FN-1"><sup><a href="ch07.xhtml#CHP-7-FN-1-marker">1</a></sup> The acronym GC is used throughout this chapter to refer to both the <em>garbage collector</em> mechanism and also <em>garbage collection</em>, which is what the garbage collector does.</p><p data-type="footnote" id="idm45884816407152"><sup><a href="ch07.xhtml#idm45884816407152-marker">2</a></sup> The Mono runtime’s GC shares no code with the .NET GC, even though both now live in the same GitHub repository. Nonetheless, they both use the same approach here.</p><p data-type="footnote" id="idm45884816405152"><sup><a href="ch07.xhtml#idm45884816405152-marker">3</a></sup> Value types defined with <code>ref struct</code> are an exception: they always live on the stack. <a data-type="xref" href="ch18.xhtml#ch_memory_efficiency">Chapter 18</a> discusses these.</p><p data-type="footnote" id="CHP-7-FN-2"><sup><a href="ch07.xhtml#CHP-7-FN-2-marker">4</a></sup> The CLR doesn’t always wait until it runs out of memory. I will discuss the details later. For now, the important point is that from time to time, it will try to free up some space.</p><p data-type="footnote" id="idm45884815650576"><sup><a href="ch07.xhtml#idm45884815650576-marker">5</a></sup> The Mono runtime uses a slightly simpler scheme, but it still relies on the basic principle of treating new and old objects differently.</p><p data-type="footnote" id="idm45884815632912"><sup><a href="ch07.xhtml#idm45884815632912-marker">6</a></sup> .NET provides a configuration setting that lets you change this threshold.</p><p data-type="footnote" id="idm45884815551344"><sup><a href="ch07.xhtml#idm45884815551344-marker">7</a></sup> Rare though single-core CPUs are these days, it’s still common to run in virtual machines that present only one core to the code they host. This is often the case if your application runs on a cloud-hosted service using a consumption-based tariff, for example.</p><p data-type="footnote" id="CHP-7-FN-3"><sup><a href="ch07.xhtml#CHP-7-FN-3-marker">8</a></sup> You can do this with a free Microsoft tool called PerfView. Alternatively, the free BenchmarkDotNet tool has a memory diagnosis feature.</p><p data-type="footnote" id="idm45884814664400"><sup><a href="ch07.xhtml#idm45884814664400-marker">9</a></sup> Strictly speaking, it’s the underlying <code>MessageHandler</code> that needs to be reused. If you obtain an <code>HttpClient</code> from an <code>IHttpClientFactory</code>, it is harmless to dispose it because the factory holds on to the handler and reuses it across <code>HttpClient</code> instances.</p><p data-type="footnote" id="idm45884814438672"><sup><a href="ch07.xhtml#idm45884814438672-marker">10</a></sup> Except for <code>ref struct</code> types, because those invariably live on the stack.</p></div></div></section></div></body></html>