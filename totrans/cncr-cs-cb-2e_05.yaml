- en: Chapter 5\. Dataflow Basics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 数据流基础
- en: 'TPL Dataflow is a powerful library that enables you to create a mesh or pipeline
    and then (asynchronously) send your data through it. Dataflow is a very declarative
    style of coding: normally, you completely define the mesh first and then start
    processing data. The mesh ends up being a structure through which your data flows.
    This requires you to think about your application a bit differently, but once
    you make that leap, dataflow becomes a natural fit for many scenarios.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: TPL Dataflow 是一个强大的库，它允许你创建一个网格或管道，然后（异步地）通过它发送数据。Dataflow 是一种非常声明式的编程风格：通常情况下，你先完全定义网格，然后开始处理数据。网格最终成为一个结构，通过它你的数据流动。这需要你用一种不同的方式来思考你的应用，但一旦你跨越了这一步，数据流就变成了许多场景的自然选择。
- en: Each mesh is comprised of various blocks that are linked to each other. The
    individual blocks are simple and are responsible for a single step in the data
    processing. When a block finishes working on its data, it will pass its result
    along to any linked blocks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每个网格由相互链接的各种块组成。单个块很简单，负责数据处理的一个步骤。当块完成对其数据的处理时，它会将结果传递给任何链接的块。
- en: To use TPL Dataflow, install the NuGet package [`System.Threading.Tasks.Dataflow`](http://bit.ly/nuget-df)
    into your application.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 TPL Dataflow，在你的应用程序中安装 NuGet 包 [`System.Threading.Tasks.Dataflow`](http://bit.ly/nuget-df)。
- en: 5.1 Linking Blocks
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.1 链接块
- en: Problem
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to link dataflow blocks to one another to create a mesh.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将数据流块链接到彼此以创建一个网格。
- en: Solution
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The blocks provided by the TPL Dataflow library define only the most basic
    members. Many of the useful TPL Dataflow methods are actually extension methods.
    The `LinkTo` extension method provides an easy way to link dataflow blocks together:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: TPL Dataflow 库提供的块仅定义了最基本的成员。许多有用的 TPL Dataflow 方法实际上是扩展方法。`LinkTo` 扩展方法提供了一种将数据流块连接在一起的简单方法：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'By default, linked dataflow blocks only propagate data; they do not propagate
    completion (or errors). If your dataflow is linear (like a pipeline), then you
    will probably want to propagate completion. To propagate completion (and errors),
    you can set the `PropagateCompletion` option on the link:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，链接的数据流块仅传播数据；它们不传播完成状态（或错误）。如果你的数据流是线性的（像一个管道），那么你可能希望传播完成状态。要传播完成状态（和错误），你可以在链接上设置
    `PropagateCompletion` 选项：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Discussion
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Once linked, data will flow automatically from the source block to the target
    block. The `PropagateCompletion` option flows completion in addition to data;
    however, at each step in the pipeline, a faulting block will propagate its exception
    to the next block wrapped in an `AggregateException`. So, if you have a long pipeline
    that propagates completions, the original error may be nested in multiple `AggregateException`
    instances. `AggregateException` has several members, such as `Flatten`, that assist
    with error handling in this situation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦链接，数据将自动从源块流向目标块。`PropagateCompletion` 选项可以在传递数据的同时传递完成状态；然而，在管道的每一步中，故障块会将其异常传播给下一个块，并封装在
    `AggregateException` 中。因此，如果你有一个传播完成的长管道，原始错误可能会嵌套在多个 `AggregateException` 实例中。`AggregateException`
    有几个成员，例如 `Flatten`，可以帮助处理这种情况中的错误。
- en: It is possible to link dataflow blocks in many ways; your mesh can have forks
    and joins and even loops. However, the simple, linear pipeline is sufficient for
    most scenarios. We’ll be dealing mainly with pipelines (and briefly cover forks);
    more advanced scenarios are beyond the scope of this book.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用多种方式链接数据流块；你的网格可以有分支和汇合甚至循环。然而，对于大多数场景，简单的线性管道就足够了。我们主要处理管道（并简要涵盖分支）；更高级的场景超出了本书的范围。
- en: The `DataflowLinkOptions` type gives you several different options you can set
    on a link (such as the `PropagateCompletion` option used in this solution), and
    the `LinkTo` overload can also take a predicate that you can use to filter which
    data can go over a link. If data doesn’t pass the filter, it is not dropped. Data
    that passes the filter travels over that link; data that doesn’t pass the filter
    attempts to pass over an alternate link, and stays in the block if there’s no
    other link for it to take. If a data item gets stuck in a block like this, then
    that block won’t produce any other data items; the entire block becomes stalled
    until that data item is removed.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataflowLinkOptions`类型为您提供了几种不同的选项，您可以在链接上设置这些选项（例如在此解决方案中使用的`PropagateCompletion`选项），并且`LinkTo`重载还可以接受一个谓词，您可以使用它来过滤通过链接的数据。如果数据未通过过滤器，则不会被丢弃。通过过滤器的数据通过该链接传输；未通过过滤器的数据尝试通过备用链接传输，并且如果没有其他链接可供其使用，则留在块中。如果数据项在块中被卡住，那么该块将不会生成任何其他数据项；直到移除该数据项为止，整个块都将处于停滞状态。'
- en: See Also
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '[Recipe 5.2](#recipe-dataflow-errors) covers propagating errors along links.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[菜谱 5.2](#recipe-dataflow-errors)涵盖了沿着链路传播错误的方法。'
- en: '[Recipe 5.3](#recipe-dataflow-unlinking) covers removing links between blocks.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[菜谱 5.3](#recipe-dataflow-unlinking)介绍了如何移除块之间的链接。'
- en: '[Recipe 8.8](ch08.html#recipe-rx-interop-dataflow) covers how to link dataflow
    blocks to System.Reactive observable streams.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[菜谱 8.8](ch08.html#recipe-rx-interop-dataflow)介绍了如何将数据流块链接到System.Reactive的可观测流。'
- en: 5.2 Propagating Errors
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.2 传播错误
- en: Problem
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need a way to respond to errors that can happen in your dataflow mesh.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一种方法来响应数据流网格中可能发生的错误。
- en: Solution
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'If a delegate passed to a dataflow block throws an exception, then that block
    will enter a faulted state. When a block is in a faulted state, it will drop all
    of its data (and stop accepting new data). The block in the following code will
    never produce any output data; the first value raises an exception, and the second
    value is just dropped:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传递给数据流块的委托引发异常，那么该块将进入故障状态。当块处于故障状态时，它将丢弃所有数据（并停止接受新数据）。下面的代码中的块永远不会生成任何输出数据；第一个值引发异常，第二个值则被丢弃：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To catch exceptions from a dataflow block, you should `await` its `Completion`
    property. The `Completion` property returns a `Task` that will complete when the
    block is completed, and if the block faults, the `Completion` task is also faulted:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要捕获数据流块的异常，您应该`await`其`Completion`属性。`Completion`属性返回一个`Task`，当块完成时完成，如果块故障，则`Completion`任务也将故障：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you propagate completion using the `PropagateCompletion` link option,
    errors are also propagated. However, the exception is passed to the next block
    wrapped in an `AggregateException`. The following example catches the exception
    from the end of a pipeline, so it would catch `AggregateException` if an exception
    was propagated from earlier blocks:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`PropagateCompletion`链接选项传播完成时，错误也会被传播。但是，异常会被包装在`AggregateException`中传递到下一个块。以下示例从管道末端捕获异常，因此如果从先前的块传播异常，则会捕获`AggregateException`：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Each block wraps incoming errors in an `AggregateException`, even if the incoming
    error is already an `AggregateException`. If an error occurs early in a pipeline
    and travels down several links before it’s observed, the original error will be
    wrapped in multiple layers of `AggregateException`. The `AggregateException.Flatten`
    method simplifies error handling in this scenario.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个块都将传入的错误包装在`AggregateException`中，即使传入的错误已经是`AggregateException`。如果在管道的早期发生错误并在几个链接下行之前被观察到，则原始错误将被包装在多层`AggregateException`中。`AggregateException.Flatten`方法简化了这种情况下的错误处理。
- en: Discussion
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: When you build your mesh (or pipeline), consider how errors should be handled.
    In simpler situations, it can be best to just propagate the errors and catch them
    once at the end. In more complex meshes, you may need to observe each block when
    the dataflow has completed.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建网格（或管道）时，请考虑如何处理错误。在较简单的情况下，最好只传播错误并在最后一次捕获它们。在更复杂的网格中，您可能需要在数据流完成时观察每个块。
- en: Alternatively, if you want your blocks to remain viable in the face of exceptions,
    you can choose to treat exceptions as another kind of data and let them flow through
    your mesh along with your correctly processed data items. Using that pattern,
    you can keep your dataflow mesh operational, since the blocks themselves don’t
    fault and continue processing the next data item. See [Recipe 14.6](ch14.html#recipe-railway-dataflow)
    for more details.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你希望你的块在面对异常时仍然可用，你可以选择将异常视为另一种数据，让它们与正确处理的数据一起流过网格。使用这种模式，你可以保持数据流网格的操作性，因为块本身不会故障，并且会继续处理下一个数据项。参见
    [配方 14.6](ch14.html#recipe-railway-dataflow) 了解更多详情。
- en: See Also
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Recipe 5.1](#recipe-dataflow-linking) covers establishing links between blocks.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[配方 5.1](#recipe-dataflow-linking) 讲述了如何建立块之间的链接。'
- en: '[Recipe 5.3](#recipe-dataflow-unlinking) covers breaking links between blocks.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[配方 5.3](#recipe-dataflow-unlinking) 讲述了如何断开块之间的链接。'
- en: '[Recipe 14.6](ch14.html#recipe-railway-dataflow) covers flowing exceptions
    alongside data in a dataflow mesh.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[配方 14.6](ch14.html#recipe-railway-dataflow) 讲述了如何在数据流网格中同时传递异常和数据。'
- en: 5.3 Unlinking Blocks
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.3 取消链接块
- en: Problem
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: During processing, you need to dynamically change the structure of your dataflow.
    This is an advanced scenario that is hardly ever needed.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理过程中，您需要动态更改数据流的结构。这是一个几乎不常见的高级场景。
- en: Solution
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: You can link or unlink dataflow blocks at any time; data can be freely passing
    through the mesh and it’s still safe to link or unlink at any time. Both linking
    and unlinking are fully threadsafe.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以随时链接或取消链接数据流块；数据可以自由地通过网格流动，随时链接或取消链接都是安全的。链接和取消链接都是完全线程安全的。
- en: 'When you create a dataflow block link, keep the `IDisposable` returned by the
    `LinkTo` method, and dispose of it when you want to unlink the blocks:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当您创建数据流块链接时，请保留 `LinkTo` 方法返回的 `IDisposable`，并在希望取消链接块时将其处理掉：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Discussion
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Unless you can guarantee that the link is idle, there will be race conditions
    when you unlink it. However, these race conditions are usually not a concern;
    data will either flow over the link before the link is broken, or it won’t. There
    are no race conditions that would cause duplication or loss of data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你能保证链接是空闲的，否则在取消链接时可能会出现竞态条件。然而，通常这些竞态条件并不是一个问题；数据要么在断开链接之前流过链接，要么根本不会。没有竞态条件会导致数据的重复或丢失。
- en: Unlinking is an advanced scenario, but it can be useful in a handful of situations.
    As one example, there’s no way to change the filter for a link. To change the
    filter on an existing link, you’d have to unlink the old one and create a new
    link with the new filter (optionally setting `DataflowLinkOptions.Append` to false).
    As another example, unlinking at a strategic point can be used to pause a dataflow
    mesh.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 取消链接是一个高级场景，但在少数情况下非常有用。举例来说，没有办法改变链接的过滤器。要改变现有链接的过滤器，你需要取消旧的链接并创建一个新的链接，并可以选择设置
    `DataflowLinkOptions.Append` 为 false。另一个例子是，在战略性的点上取消链接可以用来暂停数据流网格。
- en: See Also
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Recipe 5.1](#recipe-dataflow-linking) covers establishing links between blocks.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[配方 5.1](#recipe-dataflow-linking) 讲述了如何建立块之间的链接。'
- en: 5.4 Throttling Blocks
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.4 限流块
- en: Problem
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You have a fork scenario in your dataflow mesh and want the data to flow in
    a load-balancing way.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的数据流网格中存在分叉场景，并希望数据以负载平衡的方式流动。
- en: Solution
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: By default, when a block produces output data, it’ll examine all of its links
    (in the order they were created) and attempt to flow the data down each link one
    at a time. Also, by default, each block will maintain an input buffer and accept
    any amount of data before it’s ready to process it.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，当块产生输出数据时，它会检查所有链接（按创建顺序），并尝试逐个将数据流过每个链接。此外，每个块默认会维护一个输入缓冲区，在准备好处理数据之前可以接受任意数量的数据。
- en: 'This causes a problem in a fork scenario, where one source block is linked
    to two target blocks: the second block is then starved. As the source block produces
    data, it will try to flow the data down each link. The first target block would
    always accept the data and buffer it, and so the source block would never try
    to flow the data to the second target block. This problem can be fixed by throttling
    the target blocks using the `BoundedCapacity` block option. By default, `BoundedCapacity`
    is set to `DataflowBlockOptions.Unbounded`, which causes the first target block
    to buffer *all* the data even if it isn’t ready to process it yet.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在分支场景中，这会造成问题，其中一个源块链接到两个目标块：然后第二个块就会饿死。当源块生成数据时，它会尝试将数据流向每个链接。第一个目标块将始终接受数据并缓冲它，因此源块永远不会尝试将数据流向第二个目标块。可以通过使用`BoundedCapacity`块选项节流目标块来解决此问题。默认情况下，`BoundedCapacity`设置为`DataflowBlockOptions.Unbounded`，这会导致第一个目标块即使没有准备好处理数据也缓冲*所有*数据。
- en: '`BoundedCapacity` can be set to any value greater than zero (or, of course,
    `DataflowBlockOptions.Unbounded`). As long as the target blocks can keep up with
    the data coming from the source blocks, a simple value of 1 will suffice:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`BoundedCapacity`可以设置为大于零的任意值（或者当然是`DataflowBlockOptions.Unbounded`）。只要目标块能够跟得上来自源块的数据，简单的值为
    1 就足够了：'
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Discussion
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Throttling is useful for load balancing in fork scenarios, but it can be used
    anywhere else you want throttling behavior. For example, if you’re populating
    your dataflow mesh with data from an I/O operation, you can apply `BoundedCapacity`
    to the blocks in your mesh. That way, you won’t read too much I/O data until your
    mesh is ready for it, and your mesh won’t end up buffering all the input data
    before it’s able to process it.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 节流在分支场景中进行负载平衡非常有用，但可以在任何需要节流行为的地方使用。例如，如果您正在从 I/O 操作中填充数据流网格的数据，可以在网格中的块上应用`BoundedCapacity`。这样，直到网格准备好处理数据之前，您都不会读取太多
    I/O 数据，并且在能够处理它之前，您的网格不会最终缓冲所有输入数据。
- en: See Also
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '[Recipe 5.1](#recipe-dataflow-linking) covers linking blocks together.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[Recipe 5.1](#recipe-dataflow-linking)介绍如何将块链接在一起。'
- en: 5.5 Parallel Processing with Dataflow Blocks
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.5 使用数据流块进行并行处理
- en: Problem
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to perform some parallel processing within your dataflow mesh.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望在数据流网格中进行一些并行处理。
- en: Solution
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: By default, each dataflow block is independent from each other block. When you
    link two blocks together, they will process independently. So, every dataflow
    mesh has some natural parallelism built in.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每个数据流块彼此独立。当您将两个块链接在一起时，它们将独立处理。因此，每个数据流网格内建有一些自然的并行性。
- en: If you need to go beyond this—for example, if you have one particular block
    that does heavy CPU computations—then you can instruct that block to operate in
    parallel on its input data by setting the `MaxDegreeOfParallelism` option. By
    default, this option is set to 1, so each dataflow block will only process one
    piece of data at a time.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要进一步的操作，例如，如果有一个执行大量 CPU 计算的特定块，则可以通过设置`MaxDegreeOfParallelism`选项，使该块并行处理其输入数据。默认情况下，此选项设置为
    1，因此每个数据流块一次只处理一个数据片段。
- en: '`BoundedCapacity` can be set to `DataflowBlockOptions.Unbounded` or any value
    greater than zero. The following example permits any number of tasks to be multiplying
    data simultaneously:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`BoundedCapacity`可以设置为`DataflowBlockOptions.Unbounded`或大于零的任何值。以下示例允许任意数量的任务同时乘以数据：'
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Discussion
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The `MaxDegreeOfParallelism` option makes parallel processing within a block
    easy to do. What is not so easy is determining which blocks need it. One technique
    is to pause dataflow execution in the debugger, where you can see the number of
    data items queued up (i.e., the ones that haven’t yet been processed by the block).
    An unexpected number of data items can be an indication that some restructuring
    or parallelization would be helpful.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`MaxDegreeOfParallelism`选项使得块内的并行处理变得容易。不那么容易的是确定哪些块需要它。一种技术是在调试器中暂停数据流执行，在那里您可以看到排队的数据项数量（即尚未由块处理的数据项）。意外数量的数据项可能表明某些重组或并行化将有所帮助。'
- en: '`MaxDegreeOfParallelism` also works if the dataflow block does asynchronous
    processing. In this case, the `MaxDegreeOfParallelism` option specifies the level
    of concurrency—a certain number of *slots*. Each data item takes up a slot when
    the block begins processing it and only leaves that slot when the asynchronous
    processing is fully completed.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据流块进行异步处理，`MaxDegreeOfParallelism`也适用。在这种情况下，`MaxDegreeOfParallelism`选项指定并发级别——一定数量的*槽*。每个数据项在开始处理时占据一个槽，并且只有在异步处理完全完成时才释放该槽。
- en: See Also
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Recipe 5.1](#recipe-dataflow-linking) covers linking blocks together.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[食谱 5.1](#recipe-dataflow-linking)涵盖了将块链接在一起。'
- en: 5.6 Creating Custom Blocks
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.6 创建自定义块
- en: Problem
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You have reusable logic that you want to place into a custom dataflow block.
    Doing so enables you to create larger blocks that contain complex logic.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您有要放置到自定义数据流块中的可重用逻辑。这样做可以创建包含复杂逻辑的较大块。
- en: Solution
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'You can cut out any part of a dataflow mesh that has a single input and output
    block by using the `Encapsulate` method. `Encapsulate` will create a single block
    out of the two endpoints. Propagating data *and completion* between those endpoints
    is your responsibility. The following code creates a custom dataflow block out
    of two blocks, propagating data and completion:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`Encapsulate`方法剪切具有单个输入和输出块的任何数据流网格的部分。`Encapsulate`将从两个端点创建一个单一的块。在这些端点之间传播数据和*完成*是您的责任。以下代码创建了一个自定义数据流块，将数据和完成状态传播到两个块之间：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Discussion
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: When you encapsulate a mesh into a custom block, consider what kind of options
    you want to expose to your users. Consider how each block option should (or shouldn’t)
    be passed on to your inner mesh; in many cases, some block options don’t apply
    or don’t make sense. For this reason, it’s common for custom blocks to define
    their own custom options instead of accepting a `DataflowBlockOptions` parameter.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将网格封装为自定义块时，请考虑要向用户公开的选项类型。考虑每个块选项应该（或不应该）传递给内部网格；在许多情况下，某些块选项不适用或没有意义。因此，常见的做法是自定义块定义自己的自定义选项，而不是接受`DataflowBlockOptions`参数。
- en: '`DataflowBlock.Encapsulate` will only encapsulate a mesh with one input block
    and one output block. If you have a reusable mesh with multiple inputs and/or
    outputs, you should encapsulate it within a custom object and expose the inputs
    and outputs as properties of type `ITargetBlock<T>` (for inputs) and `IReceivableSourceBlock<T>`
    (for outputs).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataflowBlock.Encapsulate`仅封装具有一个输入块和一个输出块的网格。如果您具有具有多个输入和/或输出的可重用网格，则应将其封装在自定义对象中，并将输入和输出作为类型为`ITargetBlock<T>`（用于输入）和`IReceivableSourceBlock<T>`（用于输出）的属性公开。'
- en: These examples all use `Encapsulate` to create a custom block. It is also possible
    to implement the dataflow interfaces yourself, but it’s much more difficult. Microsoft
    has [a paper](http://bit.ly/tpl-dataflow) that describes advanced techniques for
    creating your own custom dataflow blocks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例都使用`Encapsulate`创建自定义块。也可以自己实现数据流接口，但这要困难得多。Microsoft有[一篇论文](http://bit.ly/tpl-dataflow)描述了创建自定义数据流块的高级技术。
- en: See Also
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Recipe 5.1](#recipe-dataflow-linking) covers linking blocks together.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[食谱 5.1](#recipe-dataflow-linking)涵盖了将块链接在一起。'
- en: '[Recipe 5.2](#recipe-dataflow-errors) covers propagating errors along block
    links.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[食谱 5.2](#recipe-dataflow-errors)涵盖了沿着块链接传播错误。'
