- en: Chapter 6\. Programming Asynchronously
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It used to be that most of the code anyone wrote was synchronous. Things like
    concurrency, thread pools, and parallel programming were the domain of specialized
    experts who sometimes still got it wrong. Historical internet forums, UseNet,
    and even books were full of warnings to not try multithreading unless you know
    what you’re doing and have a strong requirement for it. However, that’s changed.
  prefs: []
  type: TYPE_NORMAL
- en: In 2010, Microsoft introduced the Task Parallel Library (TPL), which made it
    a lot easier to write multithreaded code. This coincided with the common availability
    of multithread/multicore CPU architectures. One of the TPL primitives was the
    `Task` class, which represented a promise to perform some work, on a separate
    thread, and return the results. Interestingly, PLINQ, which is covered in [Recipe
    4.10](ch04.xhtml#querying_in_parallel), shipped in the same time frame. TPL is
    still an important part of the developer’s toolkit for in-process CPU-intensive
    multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: Building on the concepts of `Task`, from TPL, Microsoft introduced async via
    specialized language syntax in C# 4\. While we had asynchronous programming since
    C# 1, through delegates, it was more complex and less efficient. In C# 5, async
    simplified this by introducing the `async/await` keywords and making the code
    and its order of execution very similar to synchronous code. In addition to simplification,
    a primary use case for C# async is out-of-process communication, as opposed to
    where TPL shines for in-process CPU intensive work. When going out-of-process,
    think about accessing the file system, making a database query, or calling a REST
    API. Behind the scenes, async manages the threads for these operations so they
    don’t block and improves application performance and scalability. With async,
    we could reason about our logic in a simple way and still have the benefits and
    sophistication of asynchronous operation.
  prefs: []
  type: TYPE_NORMAL
- en: Since its introduction, Microsoft has continued to improve async, both via language
    features and .NET Framework libraries. This chapter covers these new features,
    such as async `Main` methods, the new `ValueTask` type, async iterators, and async
    disposal. There are also original capabilities of async that deserve special attention,
    such as writing safe async libraries, managing concurrent async tasks, cancellation,
    and progress reporting.
  prefs: []
  type: TYPE_NORMAL
- en: The theme of this chapter is checkout, where a customer has products in their
    shopping cart, they’ve started the checkout process, and the code needs to process
    each checkout request. We’ll start with the proper way to use async with console
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Creating Async Console Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to use a library in a console application, but it only has an async
    API.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This class has async methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the old way to write an async console app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the new recommended way to write an async console app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When first introduced, async was nearly everywhere and immediately useful. Still,
    there were edge cases, such as `Main` methods and `catch` and `finally` blocks,
    where async couldn’t be used. Fortunately, Microsoft fixed this in C# 7.1 and
    added more support in other parts of the .NET Framework that were lacking, for
    instance, async `ActionResult` in ASP.NET MVC. [Recipe 6.3](#creating_async_iterators)
    shows how async iterators solve another async problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'A prominent async addition, described in this section, is async `Main`. The
    problem was that, just like the `CheckoutService` class in the solution, many
    .NET Framework types and third-party libraries were written for async. However,
    without async `Main`, developers had to write problematic code. To demonstrate
    the problem, the solution includes two versions of a `Main` method: the old synchronous
    way and the new async approach.'
  prefs: []
  type: TYPE_NORMAL
- en: With the old synchronous technique, developers were forced to use `Wait()` and
    `Result`, which are typical async antipatterns because of thread blocking and
    potential thread deadlocks and race conditions. [Recipe 6.4](#writing_safe_async_libraries)
    explains a scenario where writing code like this can cause a deadlock (and how
    to avoid it). These are members of the `Task` type, which async methods return.
    Unfortunately, this was the only choice in the first iteration of async if you
    wanted to write a command-line utility, text-based app, or demo app.
  prefs: []
  type: TYPE_NORMAL
- en: The second `Main` in the solution shows the new syntax, with the `async` modifier
    and the `Task` return type. All we have to do is `await` the call to `checkoutSvc.Start​A⁠sync()`
    and the code works fine.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you know, `Main` can return `void` or `int`. The solution example with `Task`
    is for a `void` return. You can change that to `Task<int>` for an `int` return.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, Microsoft hasn’t recommended a safe way to call from synchronous
    code into asynchronous code. So this was a welcome addition that makes it much
    easier to write console apps that call async code. Also, notice that the entire
    call chain, from `Main` to `CheckoutService.StartAsync` and to other `CheckoutService`
    methods, is all async. Ideally, the entire call chain is async, but occasionally
    you will have an async method that only calls synchronous methods; you can learn
    more about that in [Recipe 6.6](#calling_synchronous_code_from_async_code).
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.3, “Creating Async Iterators”](#creating_async_iterators)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.4, “Writing Safe Async Libraries”](#writing_safe_async_libraries)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.6, “Calling Synchronous Code from Async Code”](#calling_synchronous_code_from_async_code)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Reducing Memory Allocations for Async Return Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to reduce memory consumption for your async code.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here’s how to use `ValueTask` instead of `Task` in async methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'And here’s the app that consumes that class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the beginning of async, we’ve returned types by either `Task` or `Task<T>`.
    That has always worked and will continue to work fine for any async code. Over
    time, though, people identified specific circumstances that open new performance
    opportunities concerning the fact that `Task` is a reference type and the runtime
    caches `Tasks`.
  prefs: []
  type: TYPE_NORMAL
- en: The `Task` class, by definition, is a reference type. That means the runtime
    allocates heap memory every time an async method returns a `Task`. As you know,
    value types allocate memory where they are defined, but they don’t cause garbage
    collector overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps not as obvious, another feature of `Tasks` is that the runtime caches
    them. Rather than `await` a method, it’s possible to reference the returned `Task`
    from an `async` method. With that `Task` reference, you can perform concurrent
    invocations on multiple tasks. You could also invoke that task more than once.
    The important point here is that the runtime has cached the task, resulting in
    more memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, in normal coding a `Task` works fine and you might not care. However,
    think about high-performance scenarios where a lot of `Task` objects get allocated
    and you are interested in finding ways to improve performance and scalability.
    The solution simulates a concept where this might matter. Imagine a business that
    needs to process a high volume of shopping cart checkouts each day. In that case,
    eliminating any overhead for object allocation, garbage collection, and memory
    pressure could be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: To address these concerns, Microsoft added support for `ValueTask` (and `ValueTask<T>`)
    as async return types. As its name suggests, `ValueTask` is a value type. Because
    it’s a value type, the only memory allocation it incurs is wherever the value
    resides, on the stack in this case. By definition of a value type, there isn’t
    any unique heap allocation or garbage collection just for that value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Further, the runtime does not cache `ValueType`, resulting in less memory allocation
    and cache management. This works great in high-performance/scalability scenarios.
    The `CheckoutService` in the solution demonstrates how to use `ValueTask`: just
    use it in place of `Task`. The assumption here is that the code will always `await`
    the method and never try to reuse the `ValueTask`. In the solution, that’s exactly
    what happens.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you’re writing a reusable library for other developers, consider whether
    `ValueTask` is appropriate. By using `ValueTask`, you eliminate the ability of
    consuming code to perform concurrent task operations or any other advanced scenarios
    for where a `Task` is more appropriate. `Task` gives the most flexibility in this
    case.
  prefs: []
  type: TYPE_NORMAL
- en: As is with most things, there’s a trade-off. All of the scenarios for which
    the runtime `Task` cache were useful are no longer options for `ValueTask`. With
    `ValueTask`, you can’t combine operations or reuse a `ValueTask` after the first
    time. Recipes [6.7](#waiting_for_parallel_tasks_to_complete) and [6.8](#handling_parallel_tasks_as_they_complete)
    show a couple of scenarios where `ValueTask` doesn’t work.
  prefs: []
  type: TYPE_NORMAL
- en: To recap, use `ValueTask` when performance and scalability are a concern, and
    you’re free to use `Task` any other time.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.7, “Waiting for Parallel Tasks to Complete”](#waiting_for_parallel_tasks_to_complete)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.8, “Handling Parallel Tasks as They Complete”](#handling_parallel_tasks_as_they_complete)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Creating Async Iterators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’re working with async code and a classical synchronous iterator won’t work.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here’s the data for the checkout process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the checkout process for each request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The async iterator processes each request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the application consumes the iterator to process each request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While iterators are essential for .NET Framework collections like `List<T>`
    or a custom collection you’ve written, they can also be useful abstractions that
    hide complex data acquisition logic. The solution demonstrates a related scenario
    where an iterator might be useful—processing a stream of `CheckoutRequests` as
    if it were a collection.
  prefs: []
  type: TYPE_NORMAL
- en: An important aspect of the solution is that it’s impractical to hold too many
    `Check​ou⁠t​Request` instances in memory. If a system continuously receives orders,
    it needs to scale. In the solution, we imagine a polling implementation that continuously
    gets the next batch of `CheckoutRequests`. This reduces memory pressure and the
    iterator provides an abstraction that hides the complex details of how the program
    receives orders.
  prefs: []
  type: TYPE_NORMAL
- en: In the early days of async, it would have been more complex to perform a task
    like this because the polling is asynchronous, making an out-of-process request.
    It’s clearly possible to find a library that lets this happen synchronously, but
    that ignores the benefit of async. The solution solves this problem with a newer
    interface for async streams, `IAsyncEnumerable`.
  prefs: []
  type: TYPE_NORMAL
- en: The `CheckoutStream` class has an iterator named `GetRequestsAsync`, returning
    `IAsyncEnumerable<CheckoutRequest>`. This is the async equivalent of the `IEnumerable<T>`
    for synchronous iterators. Although the `while` loop continues forever in this
    demo and you’ll need to manually stop the app, [Recipe 6.9](#cancelling_async_operations)
    shows how to cancel the process gracefully. This iterator gets a new batch of
    `CheckoutRequests`, yields each item in the batch, and sleeps for a second before
    getting the next batch. The sleep, `Task.Delay`, is for demo purposes so you can
    see the output.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `yield` keyword is syntactic sugar to help turn type members into iterators.
    `IEnumerable<T>` types, including `IAsync​Enumer⁠able​<T>`, have `MoveNext` and
    `Current` members, where `MoveNext` loads `Current` with the next value it reads.
    Behind the scenes, when the C# compiler sees an iterator, it generates a new class
    with the `MoveNext` and `Current` members. When invoking `yield`, such as in `yield
    return request` in `GetRequestsAsync`, the C# compiler instantiates that new class,
    calls `MoveNext`, and returns `Current`.
  prefs: []
  type: TYPE_NORMAL
- en: The `GetNextBatchAsync` method only returns a list of `CheckoutRequests`. However,
    imagine that this is really an async call to a network endpoint, queue, or service
    bus that has the next set of `CheckoutRequest` instances ready. Recipes [1.9](ch01.xhtml#designing_a_custom_exception),
    [3.7](ch03.xhtml#rethrowing_exceptions), and [3.9](ch03.xhtml#building_resilient_network_connections)
    demonstrate some of the issues you’ll care about when doing this. By moving all
    this complexity into the iterator, application code can consume data in a much
    simpler manner.
  prefs: []
  type: TYPE_NORMAL
- en: The `Main` method shows how to consume an async iterator. The first thing to
    notice is the `async` modifier on the `foreach` loop. This was a new addition
    to C# for async streams. As you can see, it allows `foreach` to work with an `IAsyncEnumerable<T>`
    iterator.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 1.9, “Designing a Custom Exception”](ch01.xhtml#designing_a_custom_exception)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 3.7, “Rethrowing Exceptions”](ch03.xhtml#rethrowing_exceptions)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 3.9, “Building Resilient Network Connections”](ch03.xhtml#building_resilient_network_connections)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.9, “Cancelling Async Operations”](#cancelling_async_operations)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Writing Safe Async Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your async code is causing a deadlock with the UI thread.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This class marshals the code off of the UI thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the program that calls it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: UI technology such as Windows Forms, Windows Presentation Foundation (WPF),
    and WinUI run on a single thread—the UI thread. This simplifies the work a developer
    needs to do when working with UI code. However, if you’re using async or writing
    multithreaded logic, it’s easy for things to go wrong. In particular, if another
    thread attempts to do anything with the UI or run in the same logic of the UI
    thread, you run the risk of race conditions and deadlocks. To understand how bad
    the problem can be, consider that your application often runs perfectly in the
    development, QA, and production environments. Then, without notice, the UI locks
    up, customers begin to complain, and you can’t reproduce the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In some cases, depending on the UI you’re using and the .NET version, you might
    get an exception like the following when accessing the UI from a non-UI thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This is good because at least you know there’s a problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.1](#creating_async_console_applications) explained how calling `Wait`
    or assigning `Result` on a `Task` could cause a deadlock. The problem here occurs
    because `Wait` and `Result` block the UI thread, waiting on a response. The called
    async code executes, returns, and tries to run on the same thread. However, as
    just mentioned, the UI thread is blocked, causing a deadlock.'
  prefs: []
  type: TYPE_NORMAL
- en: The solution fixes this problem in the `CheckoutService.StartAsync` method.
    Notice how it calls `ConfigureAwait(false)`—the only difference between this code
    and the solution in [Recipe 6.1](#creating_async_console_applications). What this
    does is marshal execution off of the calling thread (the UI thread) and onto a
    new thread. Now, when the thread returns from the async call, it won’t cause a
    deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '`ConfigureAwait(true)` is the default condition when awaiting a `Task`. Changing
    this default is only needed in advanced scenarios that are out of the scope of
    practical everyday engineering. If you ever see it in code, it might be good to
    question why someone needed it.'
  prefs: []
  type: TYPE_NORMAL
- en: A significant point to be made here is that the problem statement clearly says
    *libraries*. When writing a library, you want the code to work regardless of what
    code called it. Therefore, the library code must be independent and unaware of
    who the caller is. This is an example, as stated in [Recipe 1.5](ch01.xhtml#designing_application_layers),
    where separation of concerns is important. If the library code doesn’t manipulate
    the UI, which it never should, you’ll avoid threading problems like race conditions
    and deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that if one `await` is on `ConfigureAwait(false)`, all
    `awaits` in a method should be also. The reason is that some methods execute so
    quickly that they execute synchronously, and `ConfigureAwait(false)` doesn’t marshal
    the thread. If another `await` then runs asynchronously, without `ConfigureAwait(false)`,
    you’ll have the same threading problems as if `ConfigureAwait(false)` was never
    called.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Visual Studio analyzers set warnings on all non-UI code with async calls missing
    `ConfigureAwait(false)`. It might be tedious to add these, but you still should.
    Even if you think the first `await` of a method is guaranteed to run asynchronously,
    logic changes over time with maintenance, and you might inadvertently cause threading
    problems. It’s safer to leave this analyzer enabled and follow the recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Another benefit of `ConfigureAwait(false)` is that it slightly improves efficiency.
    The default, `ConfigureAwait(true)`, incurs overhead for setting up a callback
    that marshals the completed thread onto the UI thread. `ConfigureAwait(false)`
    avoids this.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the point about `ConfigureAwait(false)` being appropriate for
    library code, there are times when you don’t want to use it. More specifically,
    you don’t want to call `ConfigureAwait(false)` in UI code, in particular event
    handlers. Think about an event handler and what it does. It gets called in response
    to some user action, like a button click, and it sets status, updates waiting
    indicators, disables controls that the user shouldn’t interact with, makes the
    call, and afterward resets the UI. All of this work is happening on the UI thread,
    as it should. In this case, you don’t want to marshal off the UI thread with `ConfigureAwait(false)`
    because that will cause multithreaded UI problems.
  prefs: []
  type: TYPE_NORMAL
- en: Although library code should never know about a UI, there are times when the
    code should communicate progress or status. Rather than accessing UI code directly,
    there’s another way to communicate status, as discussed in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 1.5, “Designing Application Layers”](ch01.xhtml#designing_application_layers)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.5, “Updating Progress Asynchronously”](#updating_progress_asynchronously)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.5 Updating Progress Asynchronously
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to display the status from an async task without blocking the UI thread.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This class holds progress status info:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This method reports progress:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the program that initializes and consumes progress updates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As explained in [Recipe 6.4](#writing_safe_async_libraries), library code should
    never update the UI directly. If properly written, it will be running on a separate
    thread and be oblivious to who its caller is. That said, there are times when
    the business layer or library code might want to inform a caller of progress or
    status. The solution shows a situation where an iterator updates the UI with progress,
    defined in the `CheckoutRequestProgress` class. Essentially, the library code
    defines what type of progress information it offers and the calling code works
    with that. In this case, it’s the total number of orders processed and some message
    indicating status.
  prefs: []
  type: TYPE_NORMAL
- en: The `GetRequestAsync` method accepts a parameter of `IProgress<CheckoutRequestProgress>`,
    `progress`. The `IProgress<T>` is part of the .NET Framework, as is the `Progress<T>`
    class, which implements `IProgress<T>`. With the progress instance, `GetRequestsAsync`
    calls `Report`, passing an instance of `CheckoutRequestProgress` with populated
    properties. This sends the progress to a handler in the UI.
  prefs: []
  type: TYPE_NORMAL
- en: The `Main` method sets up reporting by instantiating a `Progress<CheckoutRequest​Pro⁠gress>`
    and assigning it to `progress`, an `IProgress<CheckoutRequestProgress>`. The `Progress<T>`
    constructor accepts an `Action` delegate, and `Main` assigns a lambda that writes
    progress to the console. Every time `GetRequestsAsync` calls `Report`, this lambda
    executes. Going full circle, `Main` passes `progress` as an argument to the `Get​Re⁠questsAsync`
    call, so it can reference the same object to report on.
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that `GetRequestAsync` is running asynchronously, and
    the `await` on `GetNextBatchAsync` and `Task.Delay` also call `ConfigureAwait(false)`.
    If that code runs on another thread, other than the UI thread, what’s the possibility
    of a deadlock? None, because `Progress<T>` marshals the call back onto the UI
    thread so the code can safely interact with the UI. Remember, the library code,
    `GetRequests​A⁠sync`, has no knowledge of the lambda argument for the `Process<T>`
    constructor’s `Action` parameter. That means the lambda can safely access any
    UI code as necessary for displaying progress.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.4, “Writing Safe Async Libraries”](#writing_safe_async_libraries)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.6 Calling Synchronous Code from Async Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The only code inside your async method is synchronous and you want to `await`
    it asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This class demonstrates how to return asynchronous results from synchronous
    logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the code that runs the app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For simplicity, previous sections of this chapter call synchronous code from
    asynchronous code. One of the things you might have noticed is that Visual Studio
    (same as other IDEs) shows green squiggly underlines when an async method doesn’t
    `await` anything. You’ll also receive the following warning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: It’s good the compiler emits this warning because it could be an error. It’s
    possible you forgot to add the `await` modifier to an async method call. In that
    case, program execution doesn’t stop at the awaited method. Both the async method
    and the code that calls it run. The async method that wasn’t awaited might not
    complete if the program exits.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem is that if the async method that wasn’t awaited throws an exception,
    it won’t be caught because the calling code continued to run. A similar problem
    happens with `async` `void` methods where you can’t `await` them and there’s no
    way to catch exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A couple of places in this chapter describe compiler warnings associated with
    async code. In a lot of circumstances, these warnings represent error conditions.
    Too often, I’ve encountered applications with unmanageable warning walls. It’s
    as if the developers somehow don’t believe warnings are a problem or aren’t paying
    attention. Understanding the implications of how a warning could be serious, especially
    accidentally forgetting to `await` an async method or failing to add `ConfigureAwait(false)`,
    as described in [Recipe 6.4](#writing_safe_async_libraries), might provide the
    motivation to prioritize cleaning up and maintaining warnings.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes the code inside of an async method is genuinely synchronous. It might
    have originally been async but changed in maintenance, or you have to implement
    an interface. In this case, you have a couple of approaches. One is to remove
    the `async/await` keywords in the call chain until you reach a higher-level method
    that requires async. If there are multiple callers awaiting that method or it’s
    part of a public interface for multiple applications, you might not want to do
    that refactoring right away. The other approach, demonstrated in the solution,
    is to `await` `Task.FromResult<T>`.
  prefs: []
  type: TYPE_NORMAL
- en: You can see how this works in the `CheckoutService`, for `StartAsync`, where
    each method returns the result of awaiting `Task.FromResult<T>`. The `Task.From​Re⁠sult​<T>`
    method is generic, so you can use it on any type.
  prefs: []
  type: TYPE_NORMAL
- en: Awaiting `Task.FromResult<T>` works when the method needs to return a value.
    However, the `FinalizeTaskAsync` method only returns `Task`. Notice how that method
    simply awaits `Task.CompletedTask`.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things you might be thinking is that this is extra work just to get
    rid of a warning. While that’s true, consider the benefits. You do clear the warning
    and enjoy the productivity boost in keeping the warning wall trimmed. More importantly,
    the code explicitly states its intention, and developers doing maintenance will
    clearly see there isn’t an error from a missing `await`—the code is correct.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.4, “Writing Safe Async Libraries”](#writing_safe_async_libraries)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.7 Waiting for Parallel Tasks to Complete
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have multiple tasks, running in parallel, and need to wait for all of them
    to complete before continuing.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This code runs parallel tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the app that requests and handles parallel task results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When performing an action, such as shopping cart checkout, you don’t want the
    user to wait too long for the app to return. Running too many operations sequentially
    can make the wait longer. One of the ways to improve that user experience is to
    run independent operations concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: In the solution, the `CheckoutService` has four different async services. Here
    we assume that three of those operations, `ValidateAddress​A⁠sync`, `ValidateCredit​A⁠sync`,
    and `GetShoppingCart​A⁠sync`, don’t have any dependencies on each other. This
    makes them good candidates for running at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: The `StartAsync` method does this by creating a `List<Task>`. If you recall,
    awaiting a method is really an `await` on the returned `Task`. Without the `await`,
    each method returns a `Task`, but its logic doesn’t run until that task is awaited.
  prefs: []
  type: TYPE_NORMAL
- en: The `Task` class has a `WhenAll` method, whose purpose is to run all of the
    tasks, specified by the `checkoutTasks` argument, concurrently. `WhenAll` waits
    until all of the `Tasks` complete before returning.
  prefs: []
  type: TYPE_NORMAL
- en: Awaiting a single method with a return type is straightforward from the perspective
    that you assign the return value to a single variable. However, when running tasks
    concurrently, you need to correlate responses because `WhenAll` returns all tasks
    at the same time. Making an assumption about which tasks occur in which position
    of the collection could be error prone and cumbersome in maintenance. The code
    needs to know which response goes with which `Task`.
  prefs: []
  type: TYPE_NORMAL
- en: The solution does this via a tuple, where the `string` is the name of the method
    and `bool` is the response. The tuple and choice of contents was specific for
    this demo, and you would shape the task type in whatever way that makes sense
    for your app. This lets us know which task goes with which result. The `GetResultsAsync`
    method does this by iterating through the task array, and building the `WhenAllResult`,
    based on the method parameter of each response.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the first line of `ValidateAddressAsync` is a commented statement
    that throws an `ArgumentException`. Uncommenting and running the app again results
    in an exception during the call to `WhenAll`. The `Main` method handles that exception
    with a `catch` on `AggregateException`. Since all tasks are running concurrently,
    one or more of them could throw an exception. The `AggregateException` collects
    those exceptions. Normally, you would look in the `InnerException` property for
    exception details. However, `AggregateException` has another property, `InnerExceptions`.
    The difference is that the `AggregateException` property is plural, which is intentional.
    For proper debugging, you can find all exceptions in the `InnerExceptions` property.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.8, “Handling Parallel Tasks as They Complete”](#handling_parallel_tasks_as_they_complete)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.8 Handling Parallel Tasks as They Complete
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You thought calling `Task.WhenAny` would be an efficient use of resources for
    processing results as they complete, but cost and performance are terrible.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a sequential implementation for calling multiple tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a parallel implementation for calling multiple tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The next implementation processes tasks in parallel but handles each one as
    it returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This method shows how to get the first task that completes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Main` method offers a choice of which method to start with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The problem in this section explores the role of `Task.WhenAny`. If you try
    to use `Task.WhenAny` for processing tasks as they return, you might be surprised
    because it doesn’t work the way you expect.
  prefs: []
  type: TYPE_NORMAL
- en: For the most part, the concept and organization of this solution operates similar
    to [Recipe 6.7](#waiting_for_parallel_tasks_to_complete)—the difference being
    that this solution shows different ways to run tasks and explains what you need
    to know to make the proper design decisions.
  prefs: []
  type: TYPE_NORMAL
- en: The `StartBigONAsync` method operates like previous sections of this chapter
    that ran sequentially. Its performance is O(N) because it processes N tasks, one
    after the other.
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.7](#waiting_for_parallel_tasks_to_complete) showed how to speed up
    program execution when tasks don’t depend on each other. It uses `Task.WhenAll`,
    shown in `StartBigO1Async`. The performance boost comes from its approximately
    O(1) performance—instead of performing N operations, it does 1\. To be more accurate,
    this is O(2) because `FinalizeCheckout​A⁠sync` runs after the other three complete.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to `Task.WhenAll`, you can use `Task.WhenAny`. It might be natural
    to think that `Task.WhenAny` is a good way to run multiple tasks in parallel and
    then be able to process each task while the others are running. However, `Task.WhenAny`
    doesn’t work the way you think it does. Look at `StartBigONSquaredAsync` and follow
    the following logic:'
  prefs: []
  type: TYPE_NORMAL
- en: The `while` loop iterates as long as `checkoutTasks` still has contents.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Task.WhenAny` starts all of the tasks in parallel.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The fastest task returns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since that task returned, remove it from `checkoutTasks` so we don’t run it
    again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect the results from that task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do the loop again on the remaining tasks or stop when `checkoutTasks` is empty.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first surprising mental hurdle in this algorithm is incorrectly thinking
    that subsequent loops operate on the same tasks, each returning as they complete.
    The reality is that each subsequent loop starts a brand-new set of tasks. This
    is how async works—you can `await` a task multiple times, but each `await` starts
    a new task. That means the code continuously starts new instances of remaining
    tasks on every loop. This looping pattern, with `Task.WhenAny`, doesn’t result
    in the O(1) performance you might have expected, like with `Task.WhenAll`, but
    rather O(N²). This solution only has three tasks, but imagine how performance
    would increasingly suffer as the task list grows.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This chapter discusses performance with Big O notation. Especially when looking
    at algorithms that are O(N²), there’s a threshold of when too many operations
    ruin performance. [Recipe 3.10](ch03.xhtml#measuring_performance) shows how to
    measure application performance and find what that threshold is, based on your
    performance requirements.
  prefs: []
  type: TYPE_NORMAL
- en: To pile on, take that number of tasks and multiply it by the number of checkout
    operations that occur over a period of time. Not only would your application performance
    be bad, you might slow down servers with excessive network traffic and endpoint
    server processing. This might affect not only your own system, but other systems
    running concurrently too. Also, think about times when those network requests
    might be to cloud services on a consumption plan and how expensive that would
    get. This particular use case might be considered an antipattern, unless it’s
    used with a small number of tasks where the impact is minimal.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: On the internet, you’ll find articles explaining `Task.WhenAny` as a technique
    for running tasks in parallel and processing each as they complete. While that
    might work for a few tasks, this section explains the hazards of using `Task.WhenAny`
    for that use case.
  prefs: []
  type: TYPE_NORMAL
- en: That said, there is a use case where `Task.WhenAny` is effective—first task
    wins. In the solution, there’s a `ValidateCreditAsync` method showing this strategy.
    The scenario is that you have multiple sources to learn if a customer has good
    credit and a response from any one of those sources is reliable. Each service
    has different performance characteristics and you’re only interested in the one
    that returns first. You can discard the rest. This keeps performance at O(1).
  prefs: []
  type: TYPE_NORMAL
- en: '`ValidateCreditAsync` has a list of tasks to run. `Task.WhenAny` runs those
    tasks in parallel and the first task to complete comes back. The code processes
    that task and returns.'
  prefs: []
  type: TYPE_NORMAL
- en: The side effect in this solution is that tasks other than the first that returned
    continue running. However, you don’t have access to them because only one task
    is returned. For this scenario, you don’t care about those tasks but should stop
    them to avoid using more resources than necessary. You can learn how to do that
    in the next section on cancelling tasks.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 3.10, “Measuring Performance”](ch03.xhtml#measuring_performance)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.7, “Waiting for Parallel Tasks to Complete”](#waiting_for_parallel_tasks_to_complete)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.9, “Cancelling Async Operations”](#cancelling_async_operations)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.9 Cancelling Async Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have an async process in progress and need to stop it.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This class demonstrates multiple ways to cancel tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the app that initializes cancellation and shows how to cancel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.3](#creating_async_iterators) has an async iterator with a `while`
    loop that never ends. That worked for a demo, but real applications often need
    a way to stop long-running processes. Think about a dialog that pops up with ongoing
    process status and offers a Cancel button, allowing you to stop the operation.
    Task cancellation has been around since the introduction of TPL and is instrumental
    in cancelling async operations too.'
  prefs: []
  type: TYPE_NORMAL
- en: In the solution, the `Main` method shows how to initialize cancellation. The
    `Cancel​la⁠tionTokenSource`, `cancelSource`, provides both tokens and control
    over cancellation. See how the parameter to the `CheckoutStream` constructor is
    a `Cancellation​To⁠ken`, set via the `Token` property from `cancelSource`.
  prefs: []
  type: TYPE_NORMAL
- en: Because `cancelSource` can manage cancellation for all the code in its scope,
    you can pass a `CancellationToken` as a parameter to any constructors or methods
    with a `Cancel​la⁠tionToken` parameter, allowing you to cancel any operations
    from a single place, `cancelSource`. The solution doesn’t have a button and cancels
    after processing 10 `CheckoutRequests`. You can see how that works with the `count`
    variable that’s incremented in each loop, checks the number of requests, and breaks
    out of the loop after `10`. This program never gets to `10` because of the check
    on `count >= 5`, calling `cancelSource.Cancel()`.
  prefs: []
  type: TYPE_NORMAL
- en: The call to `cancelSource.Cancel` sends the message that the process should
    be cancelled, but you still have to write code that recognizes the need to cancel.
    It’s proper to cancel as soon as possible, and `GetRequestsAsync` has several
    checks on `cancelToken.IsCancellationRequested`. The `IsCancellationRequested`
    property is `true` when `Cancel` is called on the `CancellationTokenSource` instance
    that passed the `CancelToken`.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the loop, `IsCancellationRequested` breaks. Outside the loop, `IsCancellationRequested`
    sends an `IProgress<T>` status message to let the caller know that the operation
    was properly cancelled.
  prefs: []
  type: TYPE_NORMAL
- en: The `GetNextBatchAsync` method shows another way to handle cancellation, by
    throwing an `OperationCancelledException`. If you recall, the reason a method
    throws is because it is unable to complete the operation it was designed to do.
    In this case, `GetNextBatchAsync` did not retrieve records, so this could be a
    semantically correct way to respond. Even if this wasn’t a design decision that
    you would make, consider that `GetNextBatchAsync` might `await` another method,
    passing its `cancelToken`. When cancelled, that awaited async method could throw
    `OperationCancelled​Excep⁠tion`. Therefore, when handling cancellation, it’s safe
    to anticipate and handle `OperationCancelledException`. The solution does this
    by wrapping the call to `GetNextBatchAsync` in a `try/catch`, breaking the loop,
    and letting existing code report the cancelled status to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever cancelling an operation, you might also need to clean up resources.
    The next section, [Recipe 6.10](#disposing_async_resources), discusses how to
    do that.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 6.3, “Creating Async Iterators”](#creating_async_iterators)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.10, “Disposing of Async Resources”](#disposing_async_resources)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.10 Disposing of Async Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have an async process with resources that must be disposed.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This class shows how to properly implement the async dispose pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the app that demonstrates how to use an async disposable object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 1.1](ch01.xhtml#managing_object_lifetime) describes the dispose pattern
    and how it solves the problem of releasing resources when an object lifetime ends.
    That works well for synchronous code but not for asynchronous code. This section
    shows how to dispose of async resources with the async dispose pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the solution, `CheckoutStream` has two fields: a `FileStream`, `asyncDisposeObj`,
    and an `HttpClient`, `syncDisposeObj`. Normally these would have names representing
    their purpose in the application, but in this instance, their names represent
    how they’re used in the solution to help follow a complex set of logic. As their
    names suggest, `asyncDisposeObj` references a resource that must be disposed of
    asynchronously; `syncDisposeObj` references a resource that must be disposed of
    synchronously. It’s important to think about both asynchronous and synchronous
    disposal at the same time, because it explains why their disposal processes are
    now intertwined.'
  prefs: []
  type: TYPE_NORMAL
- en: For asynchronous and synchronous disposal, `CheckoutService` implements `IAsyncDisposable`
    and `IDisposable`, respectively. As discussed in [Recipe 1.1](ch01.xhtml#managing_object_lifetime),
    `IDisposable` specifies that classes must implement `Dispose`, with no parameters,
    and we add a virtual `Dispose(bool)`, with a `bool` parameter, and an optional
    destructor to implement the pattern. The solution doesn’t implement the optional
    destructor. For `IAsyncDisposable`, `CheckoutService` implements the required
    `DisposeAsync` method and a virtual `DisposeAsyncCore` method, neither of which
    have parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Both disposal paths, asynchronous and synchronous, could run, so they both must
    be prepared to release resources. On the synchronous path, `Dispose(bool)` not
    only calls `Dispose` on `syncDisposeObj`, but also attempts to call `Dispose`
    on `asyncDisposeObj`. Notice that `Dispose(bool)` also calls `DisposeThisObject`,
    which holds the same code that the asynchronous path needs to call too—it reduces
    duplication.
  prefs: []
  type: TYPE_NORMAL
- en: While `Dispose` and `DisposeAsync` are interface members, `Dispose(bool)` and
    `DisposeAsyncCore` are conventions. Also notice that they’re both `virtual`. This
    is part of the pattern, where derived classes can implement disposal by overriding
    these methods and calling them, via `base.Dispose(bool)` and `base.DisposeAsyncCore`,
    to ensure release of resources up the entire inheritance hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Both `Dispose` and `DisposeAsync` call `Dispose(bool)`, but `DisposeAsync` sets
    the `disposing` argument to `false`. If you recall, `disposing` is a flag for
    `Dispose(bool)` to release managed resources when set to `true`. Remember that
    `Dispose(bool)` is the synchronous path. Instead, `DisposeAsync` calls `DisposeAsyncCore`
    to release asynchronous resources.
  prefs: []
  type: TYPE_NORMAL
- en: As with `Dispose(true)`, `DisposeAsyncCore` attempts to release all managed
    resources. The async case is obvious. However, synchronous objects have a couple
    of possibilities. What if the synchronous object, now or in the future, implements
    `IAsyncDisposable`? Then, attempting to call `DisposeAsync` is the better choice
    when the code is on the asynchronous path. Otherwise, call the synchronous path,
    with `Dispose`.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, both `Dispose(bool)` and `DisposeAsyncCore` call `DisposeThisObject`.
    In the solution scenario, the `GetRequestsAsync` iterator implements cancellation,
    as explained in [Recipe 6.9](#cancelling_async_operations). Depending on the situation,
    it might be good to cancel during the dispose process. For instance, what if the
    code needs to persist its latest good state or has a closure protocol with a network
    endpoint? It’s good to think through your situation, and the dispose and async
    dispose patterns can help.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, notice how the `Main` method awaits a using statement on the `CheckoutStream`
    instance. This is the same `using` statement discussed in [Recipe 2.2](ch02.xhtml#simplifying_instance_cleanup),
    except that now it has an `await`. This ensures the code calls `DisposeAsync`
    at the end of the `Main` method.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Recipe 1.1, “Managing Object End-of-Lifetime”](ch01.xhtml#managing_object_lifetime)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 2.2, “Simplifying Instance Cleanup”](ch02.xhtml#simplifying_instance_cleanup)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Recipe 6.9, “Cancelling Async Operations”](#cancelling_async_operations)'
  prefs: []
  type: TYPE_NORMAL
