# Chapter 7\. Logging, Monitoring, and Instrumentation for .NET

Back in 2007, when people were setting up their Nintendo Wii and dreaming of owning Apple’s revolutionary new touchscreen cellphone, James was working his first job as a graduate software engineer. Not in web-based SaaS applications where he works today, however, but starting an engineering career writing industrial control software for production lines, oil rigs, cruise liners, and the military. Of all the weird and exciting projects James had a chance to work on back then, the most fun was designing the control system software for a roller coaster. Let us tell you how that worked.

This was a theme park ride with several cars on wheels going around a typical roller coaster track. Each car carried four people and there were between three and five cars going around the track simultaneously at any one time. The cars would be sent off from the station, making their way up the chain-driven incline to the top of the track, then rolling down under gravity to make an intense, exciting, and most importantly *safe* ride.

The code that operated the roller coaster was incredibly simple: the software read an input for the “GO” button being pressed by a ride operator. This then commanded the brakes to release, sending the car from the station into the starting blocks of the incline. There, with no further control inputs from the software, the car would be picked up by the chain-lift mechanism, carried up to the top of the ramp, and then sent off around the track. The brakes, hidden under the track along the platform, would then be re-armed, ready to catch the car and stop it gently on return.

With multiple cars hurtling around a roller coaster track at the same time, however, it is not hard to see what could go wrong. What if one of them got stuck? What if a car didn’t have enough momentum to make it to the top of an incline or a fault on the track caused it to slow down or stop? With multiple cars on the track this can present a very real danger, potentially even risking human life. If one car stopped, we had to stop all the cars on the ride until an engineer could be sent out to fix the issue. For this reason, we had sensors and emergency brakes all over the track. We had code to detect cars entering “blocks” around the track in the same way a railroad signaling system works to prevent collisions. We had multiple sensors placed in a row to measure the speed of the cars at multiple points around the track.^([1](ch07.xhtml#idm45599651192176)) Every speed sensor, motion detector, emergency brake, *backup* emergency brake, all of this had to be coded in the software. The volume of all this code greatly surpassed that which we had to actually operate the ride. Ninety-five percent of the code that runs on the control system of a roller coaster is monitoring, logging, alarming, and triggering emergency brakes.

Your distributed cloud-based system is a roller coaster. The amount of code you need to perform the main function may be small, but the number and variety of things that can go wrong is large, and you may end up adding a lot more complexity into your system to account for the rare instances of something going wrong, in order to maintain a high level of service to your users.

In this chapter, we are going to look at what we can build, configure, or simply enable in AWS that will improve our ability to monitor a cloud-based application. The majority of the services we will visit are not .NET specific; however, AWS does provide .NET SDKs for many of the tools we are about to cover. This helps you dig deep into your C# source code to identify the cause of an error or performance bottleneck. We will start by introducing the most important page you will visit on the Management Console when it comes to logging and monitoring: CloudWatch.

# AWS CloudWatch

[AWS CloudWatch](https://aws.amazon.com/cloudwatch) is a service (or rather a collection of services) from AWS that allow you to monitor, analyze, and act on events generated by your AWS resources. If you have some code deployed to and running on AWS, you will probably be able to monitor it using CloudWatch. [Figure 7-1](#Figure-7-1) shows the four core pillars of AWS CloudWatch: Collect, Monitor, Act, and Analyze. These pillars work together to allow you to iteratively improve the availability and scalability of your system.

![doac 0701](assets/doac_0701.png)

###### Figure 7-1\. The four pillars of AWS CloudWatch

You *Collect* log events emitted by your AWS services, *Monitor* them with dashboards and metrics, *Act* on exceptional cases using alarms, and periodically *Analyze* your application(s) in order to make architectural improvements. These four pillars are shown in a line in [Figure 7-1](#Figure-7-1); however, it is more accurately thought of as a feedback loop. Analysis of your logs and metrics will allow you to improve what logs are collected and fine-tune when to trigger alarms, thus guiding you to make changes to your resources. The benefit of this is to ensure your system is running with the most efficient amount of headroom. You will be able to allocate enough resources to keep your performance within a desired range, but not so much that it becomes unnecessarily expensive to run.

## Collecting CloudWatch Logs

CloudWatch collects and stores log messages from the services you have deployed to AWS. Many AWS services natively publish CloudWatch log messages with information about the execution of that service. You can also manually set up log collection or, as we will demonstrate in this chapter, you can programmatically post log messages using the AWS .NET SDK.

Some of the AWS services that natively publish logs to CloudWatch include:

API Gateway

Can be configured to send errors, request and response parameters, payloads, and execution traces.

Elastic Beanstalk

Application and system log files from your Elastic Beanstalk application can be read in CloudWatch.

AWS CodeBuild

Sends full verbose build logs for all your cloud builds.

Amazon Cognito

Authentication and user management metrics can be sent to CloudWatch.

Route 53

Amazon’s Domain Name System (DNS) service can be configured to log DNS queries, amongst other things.

AWS Lambda

Lambda functions are automatically set up to send metrics and execution logs to CloudWatch.

Simple Notification Service (SNS)

Mobile text messaging (SMS) deliveries from SNS are automatically logged.

These are just a few examples; a vast majority of AWS services do publish log messages, either completely automatically, or with a little configuration. For a full list of AWS services that can publish logs to CloudWatch, visit the AWS documentation page [“AWS services that publish logs to CloudWatch”](https://oreil.ly/dlbYK). Next we are going to explore logging from some of these services in more detail.

### Logs from AWS Lambda functions

In the example for [“Developing with AWS Lambda and C#”](ch04.xhtml#4-developing-with-lambda), we created a new AWS Lambda function using the .NET CLI:

[PRE0]

If you followed this you may have noticed that as well as creating the function, the CLI also creates an IAM execution role under which the Lambda function will execute. If you navigate to this execution role in the IAM Management Console, you can see that one of the default permissions policies added to the role is called AWSLambdaBasicExecutionRole.^([2](ch07.xhtml#idm45599651136560)) This role is managed by AWS and is there to grant any new Lambda function the permission to be able to create a log group, create a stream, and then post log messages to CloudWatch. [Figure 7-2](#Figure-7-2) shows the policy JSON that is included in this policy.

Any service that posts log messages to AWS CloudWatch must be running under an IAM role that grants these permissions. Through their names, these permissions introduce us to three important concepts in CloudWatch logging.

![doac 0702](assets/doac_0702.png)

###### Figure 7-2\. CloudWatch permissions that are added to every new Lambda function

### Groups, streams, and events

CloudWatch stores log messages (or “events”) in streams, and then groups each set of streams by the service or instance that sent them. For example, if we were logging messages from the execution of a Lambda function, then each stream of events on one Lambda invocation will be written to the same *log stream*. Multiple concurrent invocations of the Lambda function would create separate log streams; however, these would still be grouped under the same *log group*. The log group corresponds, in this case, to the individual Lambda function. So in your CloudWatch console you will have a log group for each Lambda, EC2 instance, S3 bucket, CodeBuild project, or any service you are logging from. Under each log group will be multiple streams, each containing multiple messages. [Figure 7-3](#Figure-7-3) shows the log messages from one invocation of an AWS Lambda function. You can browse the groups, streams, and logs through the Logs section in the CloudWatch Management Console. It is also possible to view CloudWatch logs directly in Visual Studio if you have the AWS Toolkit for Visual Studio installed. Navigate to CloudWatch Logs in the AWS Explorer window, right-click on a log group, and select View Log Stream.

![doac 0703](assets/doac_0703.png)

###### Figure 7-3\. (1) CloudWatch log groups, (2) log stream, and (3) log event messages

Now we have a bit of familiarity with how CloudWatch log events are stored and accessed, let’s see how we can take advantage of this to use CloudWatch to save custom log messages from our application.

### Sending Logs from C#

Out of the box AWS Lambda will forward any calls made to `Console.WriteLine()` to CloudWatch, but you can also push logs directly to CloudWatch from our C# application with the help of the AWSSDK.CloudWatchLogs NuGet package, part of the AWS SDK for .NET. With the package installed, create a new .NET 6 Console Application to log a test message, as shown in [Example 7-1](#ex_7-1).

##### Example 7-1\. Program.cs

[PRE1]

Since we haven’t yet created the `TestCloudWatchLogPublishing.CloudWatchLogger` class, this will fail to compile, but you can see all we are doing here is creating a new instance of a logger and writing a couple of log lines. The `using` block in this example is there as a handy way of scoping our logger instance over a few lines of code. The messages will be batched up and then flushed (sent to CloudWatch) when the `DisposeAsync()` method is called on the last line.^([3](ch07.xhtml#idm45599651054496))

Here is the code for our `TestCloudWatchLogPublishing.CloudWatchLogger` class that batches up and sends the log messages to AWS CloudWatch:

[PRE2]

[![1](assets/1.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO1-1)

The log group name in our example is simply hardcoded. We will most likely want to create a new log group during the deployment of this code to AWS, reading it perhaps through an environment variable.

[![2](assets/2.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO1-2)

Log messages will be written to this list and then “flushed” when the class is disposed.

[![3](assets/3.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO1-3)

Log streams should have a unique name. We are prefixing this with the date so it can be easily sorted.

[![4](assets/4.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO1-4)

A new log stream is created for each instance of our logger class.

[![5](assets/5.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO1-5)

All batched log messages are sent to CloudWatch here, using the `P⁠u⁠t⁠L⁠o⁠g⁠E⁠v⁠e⁠n⁠t⁠s​A⁠s⁠y⁠n⁠c⁠(⁠)` method from the AWS SDK.

Running this Console App gives the output shown back in [Figure 7-3](#Figure-7-3) when we view the logs in the [AWS Management Console](https://oreil.ly/067XH).

###### Tip

When running .NET applications locally, the AWS SDK will look for your AWS credentials in a series of places in order to connect to AWS and post the log messages to CloudWatch. On Windows environments there is a JSON file called the *SDK Store* located in *%USERPROFILE%\AppData\Local\AWSToolkit\RegisteredAccounts.json* or you can use the shared AWS credentials file. For information on all the available options for configuring your local connection to AWS visit [this documentation page](https://oreil.ly/O57Zy).

In the preceding example, we used `CloudWatchLogger` directly but, due to AWS Lambda’s ability to forward calls to `Console.WriteLine()` to CloudWatch, we can also use any of the popular logging packages for .NET that write to the console, and then allow AWS Lambda to forward that to CloudWatch for us.

For example, here is a configuration for Serilog that adds a `Serilog.Sinks.Console` logging sink, which AWS Lambda will send to CloudWatch:

[PRE3]

We can save this JSON to our *appsettings.json* file and with Serilog and the Serilog.Sinks.Console package installed, our Lambda function will send logs to CloudWatch.

You can find plugins for using other popular third-party logging libraries on the GitHub repository for [AWS Logging .NET0](https://oreil.ly/PYPL1).

## Metrics

So far we have only looked at log messages that capture a single event in time. This is great for debugging the execution of your application and capturing specific events, but for long-term monitoring and analysis of your system, we need to also capture metrics.

A *metric* is the measure of a specific data point over a given period of time. For example, you might have an application that logs the response time for each HTTP request it processes, and you decide to measure the *average* response time *per minute*. This measure of average HTTP response time per minute is a metric, and it allows you to plot a time-series like the example shown in [Figure 7-4](#Figure-7-4). You can create and explore suggested metrics in the CloudWatch Management Console under Metrics → All Metrics.

It is also possible to publish custom metric data points from your C# code using the `AmazonCloudWatchClient` class, found in the AWSSDK.CloudWatch NuGet package.^([4](ch07.xhtml#idm45599650581152))

![doac 0704](assets/doac_0704.png)

###### Figure 7-4\. API Gateway average latency metric

[Example 7-2](#ex_7-2) sends the number of processes currently running on your local machine to CloudWatch:

##### Example 7-2\. Program.cs

[PRE4]

You can see the results of repeatedly running this in [Figure 7-5](#Figure-7-5). Note that CloudWatch automatically created the namespace “MyApplication” and the metric “ProcessCount” for us.

![doac 0705](assets/doac_0705.png)

###### Figure 7-5\. (1) Results of sending a custom metric with namespace, (2) metric name, and (3) the number of running processes

So now that we have metrics going into CloudWatch, where do we go from here? Next, we are going to look at how we can build CloudWatch dashboards to visually monitor our system at a glance. Following on from that, we will look at how we can set up alarms to trigger when a metric passes a certain threshold.

## Monitoring with CloudWatch Dashboards

Dashboards allow you to monitor your AWS resources at a glance. You can monitor multiple resources across your entire AWS account at once by creating custom dashboards, picking out key metrics that you want to be able to monitor quickly and efficiently. CloudWatch generates *automatic* dashboards for your AWS services, and you can use these as a starting point to create your own.

Navigate to CloudWatch → Dashboards → Automatic Dashboards in the Management Console to view the available automatic dashboards. You can add widgets from the automatic dashboards onto a new, custom dashboard, or you can view and tweak the underlying metrics query by selecting “view in metrics” in the context menu of each widget. [Figure 7-6](#Figure-7-6) shows the custom dashboard generated for our Simple Storage Service (S3) buckets. You can see trends for bucket size and number of objects.

![doac 0706](assets/doac_0706.png)

###### Figure 7-6\. Automatic CloudWatch dashboard for Simple Storage Service (S3) buckets

Dashboards allow you to visualize changes to your metrics over time, but what about if you want to actually perform some action when a metric hits a certain value? In [Figure 7-6](#Figure-7-6), you can see the `BucketSizeBytes` value for one of our S3 buckets was creeping up slowly over a long period of time (the sawtoothed line that drops suddenly on the first chart). Well, if we wanted we could set an upper limit to how many bytes we are comfortable storing in this S3 bucket, for cost reasons perhaps, and then perform some action if the bucket size exceeds this limit. For that, we use CloudWatch alarms.

### CloudWatch alarms

We introduced this chapter by talking about the monitoring software that keeps a roller coaster running safely. In industrial control software, such as with roller coasters, if an input is read outside some predetermined threshold for more than a set number of seconds, it will trigger an alarm. In an industrial application, these alarms will be connected to physical alarms that emit a loud audible tone alerting nearby operators to the condition being out of bounds. This could be a temperature setpoint being too low or too high for several seconds, or a discrete input such as a laser beam being broken. In the context of your distributed AWS system, you can configure alarms to trigger when your metrics go outside of the limits you have deemed “normal.” Alarms are there to trigger actions, either manually by a systems administrator, or automatically by triggering a function inside your system.

In CloudWatch, you can configure an alarm on any single metric, an expression derived from multiple metrics, or even other alarms. An alarm can be in one of three possible states:

OK

The metric for this alarm is within the defined bounds, and the alarm is not triggered.

IN ALARM

The metric is outside the defined bounds, and the alarm is triggered.

INSUFFICIENT_DATA

There is not enough data (yet) to determine the alarm state.

Let’s add an alarm to the custom metric we created in [Figure 7-5](#Figure-7-5). To do this, navigate to CloudWatch in the Management Console and create the alarm, selecting MyApplication → Metrics with no dimensions → ProcessCount as the metric to monitor. In the example in [Figure 7-5](#Figure-7-5), we had between 287 and 292 processes being reported in our custom metric, so we could set our alarm threshold to 290, which will make it easy to test. On the next screen select “Create a new topic” to have AWS create a new Simple Notification Service (SNS) topic. We introduced SNS in [“Developing with SQS and SNS”](ch04.xhtml#4-sqs-and-sns); it is a service that allows publishers and subscribers to create and listen to events, respectively. For the purposes of this alarm, we will be publishing a message to SNS when the alarm is triggered, that is, when the `ProcessCount` metric goes above our threshold of 290.

[Figure 7-7](#Figure-7-7) shows this alarm after we have created it and waited a few minutes for it to have enough data to leave the *INSUFFICIENT_DATA* state. You can see from this graph that we have a horizontal line at 290, indicating this is the threshold above which our alarm will trigger.

![doac 0707](assets/doac_0707.png)

###### Figure 7-7\. CloudWatch alarm monitoring our custom metric

We said at the start of this section that you can also configure an alarm to trigger on multiple metrics. That can be achieved with metric math, which we dig into next.

### Metric math

Metrics are data points that change over time and, as such, you can perform arithmetic operations on them over the same time period. CloudWatch enables a whole host of different expressions you can use to combine multiple metrics into one. There are too many to cover in this book; however, a full list of functions and expressions can be found [here](https://oreil.ly/2oYRC).

Using these arithmetic functions on our metrics, we can create *new* metrics that can be both added to a dashboard and used to trigger alarms. In [Figure 7-8](#Figure-7-8), we have created a new expression by combining the `ProcessCount` from our earlier example, with another custom metric that records the CPU usage of our local machine. This allows us to create a new metric for *Average CPU Per Process*, entered into the customizable “Label” field in the table in [Figure 7-8](#Figure-7-8).

![doac 0708](assets/doac_0708.png)

###### Figure 7-8\. Average CPU per process metric created using metric math

We created this expression from the Add Math context menu option above the metrics table and selected “Start with empty expression.” The expression in this example is `m2 / m1` where `m1` and `m2` are the default identifiers given to our two custom metrics in the list. You can view/change this metric ID by editing the “ID” field in the table in [Figure 7-8](#Figure-7-8).

By using metric math, we can create complex graphs and alarm conditions to monitor any parameter inside our system we like. There is even an `IF(condition, trueValue, falseValue)` condition available in metric math that allows us to do things such as filter out data points from a time series. Perhaps we want to filter out the first 10 minutes of data points after a system reboot, or during a software update. This is possible by building up new metric expressions using metric math in AWS CloudWatch.

### CloudWatch anomaly detection

It is also possible to trigger CloudWatch alarms using a feature called *anomaly detection*. This is a machine learning algorithm that continuously monitors your metric and determines a normal baseline by means of a range of *expected values*. The alarm can then be triggered if the metric deviates too far outside this range. The model used by CloudWatch’s anomaly detection can asses hourly, daily, and weekly patterns using the historical values of your metric. This allows it to generate a range of expected values even for metrics that naturally change to follow a regular pattern over time—such as metrics related to usage patterns of your application. To create a CloudWatch alarm based on anomaly detection, look out for the Anomaly detection option under the Alarm → Graphed Metrics → Conditions section of the alarm configuration in the [CloudWatch console](https://oreil.ly/Ag1Tq).

Next, we are going to move on from metrics and look at tracing the execution path of your code using a service from AWS called X-Ray.

# Distributed Tracing with X-Ray

AWS X-Ray is a service that offers end-to-end tracing for your cloud-hosted applications, giving you insights into the way your code is executing. You can set up X-Ray tracing for HTTP requests for example, and view the execution path through any downstream service calls this HTTP request results in. This gives you the ability to debug your application as it is running in the cloud, helping you understand the root causes of any issues. You can also use AWS X-Ray to find performance bottlenecks in the execution path of your code.

In order to leverage the tools AWS X-Ray provides, you need to set up your services to publish trace events to X-Ray. X-Ray tracing events can be configured automatically for a lot of native AWS services such as AWS Lambda and DynamoDB. Enabling tracing on a Lambda function is a simple case of toggling the “Active tracing” switch in the Management Console for any Lambda function (shown in [Figure 7-9](#Figure-7-9)).

![doac 0709](assets/doac_0709.png)

###### Figure 7-9\. X-Ray can be enabled in the configuration settings for many native AWS services

If you have your infrastructure controlled by an Infrastructure as Code (IaC) framework such as [“Serverless Application Model (SAM)”](ch04.xhtml#4-serverless-application-model), you can enable active tracing in your configuration so it is set when you deploy changes to your resources. Here is the SAM configuration to enable X-Ray on a Lambda function; we have added `Tracing:Active` to the properties object:

[PRE5]

Not all AWS services can be enabled like this; however, for these we do have options to use the SDK for .NET.

## Setting Up X-Ray Using the SDK for .NET

While enabling X-Ray for native services such as AWS Lambda is a simple case of toggling a switch (as shown in [Figure 7-9](#Figure-7-9)), if your code is instead running inside an EC2 container (including Elastic Beanstalk) or on App Runner, then you will need to configure some things yourself. You will need to install or enable the X-Ray daemon, which runs in the background on your EC2 instance collecting X-Ray trace messages, batching them up, and forwarding them on to AWS X-Ray. You will also need to use the X-Ray SDK for .NET in your C# code to send traces to the daemon.

On an EC2 instance, you can download and install the X-Ray daemon to run automatically when you launch the instance by running:

[PRE6]

If you are using Elastic Beanstalk, you can enable it in the Management Console under Configuration → Software Settings → X-Ray daemon. There is also an option on the publish page in the AWS Toolkit for Visual Studio. Check “Enable AWS X-Ray Tracing Support” when publishing your application to Elastic Beanstalk and the AWS Toolkit will enable the daemon for you.

You can also run the X-Ray daemon process locally on your development machine. You can find instructions for running the daemon locally on Windows, Linux, Mac OS, and even in a Docker container by visiting [the X-Ray setup guide](https://oreil.ly/Spc0P).

Once the daemon is installed on your EC2 instance, you will be able to use the X-Ray SDK in your application to send trace messages to X-Ray. To do this, start by installing the NuGet package AWSXRayRecorder, then add the following three lines to the *Program.cs* of your .NET 6 web application:

[PRE7]

[![1](assets/1.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO2-1)

Initializes the AWS X-Ray recorder for this application.

[![2](assets/2.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO2-2)

Add this line if you are using the AWS SDK to make calls to other AWS services inside your application. This will allow X-Ray to trace requests through these downstream services.

[![3](assets/3.png)](#co_logging__monitoring__and___span_class__keep_together__instrumentation_for__net__span__CO2-3)

Add X-Ray tracing to the routes in your web application. The name “ElasticBeanstalkAppExample” will be used to identify this application in X-Ray.

Adding these three lines will send trace messages to X-Ray for each HTTP request that comes into your web application. You will be able to measure the duration of the request, including any synchronous calls to downstream AWS services. X-Ray has a concept it calls “segments,” which are measurable portions of the execution path of your code. The entire HTTP request is the parent “segment,” and any downstream calls that are made as a part of this request will be “subsegments” inside. You can also configure your own subsegments using the X-Ray SDK, allowing you to measure timings for custom parts of your code. In the following example, we have set a subsegment for the duration of the code inside the controller action. We are then invoking an AWS Lambda function from our code called `TracedLambdaFunction`. X-Ray will also create a subsegment for that Lambda invocation.

##### Example 7-3\. Program.cs

[PRE8]

We will be able to view the trace results for this example in the X-Ray traces section of the CloudWatch Management Console. [Figure 7-10](#Figure-7-10) shows the trace results for this controller method. You can see the Lambda function execution took 2.45 seconds to return. The controller action subsegment we set up with `AWSXRayRecorder.Instance.BeginSubsegment(...)` took 2.67 seconds, and the entire HTTP request was 2.76 seconds.

![doac 0710](assets/doac_0710.png)

###### Figure 7-10\. Trace view of our web application controller call

With X-Ray tracing you can quickly find performance bottlenecks in your code and refactor or rearchitect your code paths accordingly. There is another feature of X-Ray that is enabled by adding tracing to your applications and services, and that is the *Service Map*.

## X-Ray Service Map

The Service Map is now found under the X-Ray traces section of the AWS CloudWatch Management Console, and it is a visualization of all your X-Ray enabled services and how they interact.^([5](ch07.xhtml#idm45599650100960)) [Figure 7-11](#Figure-7-11) shows the Service Map for the previous example. You can see we have our web application ElasticBeanstalkAppExample that makes a call off to the Lambda function `TracedLambdaFunction`. Because we used the X-Ray SDK and called `AWSSDKHandler.RegisterXRayForAllServices()` in our web application, X-Ray was able to determine that this Lambda invocation was called from within the .NET web application we deployed to Elastic Beanstalk.

![doac 0711](assets/doac_0711.png)

###### Figure 7-11\. X-Ray can be enabled in the configuration settings for many native AWS services

You can click on the services in the Service Map interface to trace the execution path(s) through them and see performance metrics such as latency and 5xx error rates. In [Figure 7-11](#Figure-7-11), we have the “ElasticBeanstalkAppExample” selected.

Next we are going to look at using X-Ray with OpenTelemetry, an open source observability framework that provides a common framework for instrumentation across multiple cloud providers, including AWS.

## OpenTelemetry and App Runner

For all the previous services we have been using the X-Ray SDK and/or simply taking advantage of built in X-Ray tracing functionality, such as with AWS Lambda. It is also possible to use X-Ray with OpenTelemetry to send tracing information to X-Ray without as much vendor lock-in. This is the solution if you want to take advantage of X-Ray tracing from within a containerized application, such as one running on Amazon ECS or Amazon EKS.

With the OpenTelemetry SDK added in your codebase, the [AWS Distro for OpenTelemetry](https://aws.amazon.com/otel) can be used to then instrument your .NET application and send the metrics to X-Ray. You can find more information about setting up OpenTelemetry for your .NET Core/6+ application by visiting [Getting Started with the .NET SDK on Traces Instrumentation](https://oreil.ly/xGe4T).

# Resource Health and Synthetics Canaries

If you have explored around the CloudWatch Management Console by now, you may have visited the Application monitoring section. Under this topic are several services from AWS that help us monitor our resources. Let’s take a quick look at two of these: Resource Health and Synthetics Canaries.

The Resource Health view was previously a part of ServiceLens and shows you health and performance data for all your running EC2 hosts. You can customize your view by selecting from three dimensions: CPU Utilization, Memory Utilization, and Status Check. The Management Console window will show blocks of colored squares for each EC2 host in the current region. This gives you an easy-to-read and accessible view of the alarm status of most or all of your hosts.^([6](ch07.xhtml#idm45599650082128))

Synthetics Canaries is another great tool tucked away under the Application monitoring section of CloudWatch. A “canary” in systems monitoring is an active monitoring technique that uses a script or other scheduled task to regularly probe the status of a system.^([7](ch07.xhtml#idm45599650080256))

You can create several types of canary in AWS using the templates (or “blueprints”) provided:

*   Heartbeat monitoring

*   API canary

*   Broken link checker

*   Canary recorder

*   GUI workflow builder

*   Visual monitoring

The idea behind a synthetic canary is to replicate behavior that approximates the real usage your application will be asked to perform for its users. So, for example, an API canary can be configured to make series requests to your API that mirror what a frontend would do under normal operation.

Synthetics can be easily integrated with X-Ray by selecting “Trace my service with AWS X-Ray” when creating your canary. Refer back to [“Distributed Tracing with X-Ray”](#7-x-ray) for configuration and familiarity with X-Ray.

# Using AWS CloudTrail for Security Auditing

So far in this chapter we have been looking at AWS CloudWatch for logging monitoring of your deployed services in order to find and fix issues. Before we leave the topic of logging and monitoring, however, let’s just have a quick look at what AWS has to offer for the auditing of your account itself.

CloudTrail is a service from AWS that records all requests to the AWS APIs in your account and logs them against the user that made the request. These API requests can be made from anywhere, including through the AWS CLI, the Management Console, or from an SDK such as the AWS SDK for .NET (see [“AWS SDK for .NET documentation”](ch01.xhtml#one-aws-sdk)). You can even monitor requests made by another AWS service in CloudTrail. CloudTrail has its own section in the AWS Management Console, so to access it and view your audit logs, search for “CloudTrail” in the search bar.

###### Tip

For Google Chrome users, you can move focus to the search bar at any time while navigating the AWS Management Console by using ALT+S (Option+S on a Mac). Another handy feature of the Management Console is the favorites “star” next to each service in the search results. Clicking this causes a link to that service to appear permanently in the header bar of the Management Console window and persists as you navigate around the various AWS services.

To get started with CloudTrail, click “Create a Trail” and run through the setup to configure attributes for your trail, primarily a name and S3 bucket in which to store the logs. You can choose to monitor any or all of these event types:

Management events

Operations performed on your AWS resources, for example attaching a policy to an IAM role or creating a subnet in EC2.

Data events

Actions performed on an instance of a resource. Data events include deleting, creating, or updating S3 objects, DynamoDB records, and executing Lambda functions.

Insights events

AWS logs these events when it detects unusual activity on your account. They monitor write operations on the AWS API and use mathematical models to spot abnormal levels of operations and/or errors.

Once you have created a trail, AWS will begin logging records to the S3 bucket and you will be able to view and analyze your audit logs in the Management Console.

# Practical Example: A CloudWatch Circuit Breaker

In this chapter, we have explored some of the features available in AWS CloudWatch. We have looked at collecting logs, metrics, tracing, and sending custom metric data from your C# application to CloudWatch. We have also looked at monitoring dashboards and setting up alarms to trigger when a metric goes outside a predetermined threshold. Let’s tie all this together with an example that spans many of the concepts covered in this chapter. For this example, we will be implementing the circuit breaker pattern using serverless AWS components and CloudWatch.

###### Note

The circuit breaker is a well-established architectural pattern for handling failures in one part of your application, introducing logic to fall back to a secondary behavior when a failure is detected. This has the benefit of preventing a failure from propagating to downstream components and allows you to maintain a certain level of service to your application users even in the event of one component failing. You can watch an animated example of how this pattern is implemented on [YouTube](https://youtu.be/e5pnfD0rudY).

In order to implement the circuit breaker pattern on AWS, we will first need an application in which we might have a failure. For this example, we have a website that wants to display the latest currency exchange rate to all our visitors. The exchange rate, in this case from USD to GBP, will come from an external API that we will call every time somebody loads our web page. Exchange rates fluctuate as currencies are traded around the world, so by making this API call every time the page loads we can be sure we are showing our website visitors the most up-to-date rate. [Figure 7-12](#Figure-7-12) shows how we make this exchange-rate lookup call from our website. The call is proxied through an instance of API Gateway that we control and passed directly through to the third-party service we are using to retrieve the latest rate.

![doac 0712](assets/doac_0712.png)

###### Figure 7-12\. External API calls being proxied through API Gateway to our website

The CloudFormation template to set up a simple API Gateway proxy to a third-party API like this would be:

[PRE9]

## What Could Go Wrong?

Calling this third-party API every time a visitor loads our web page is great for displaying the most up-to-date value; however, we are now heavily dependent on the availability of an API we do not own or control. What happens if this third-party service goes down or begins to respond slowly? As it stands, the response time of our API call is directly proportional to the response time of the external API. If this external API begins responding incredibly slowly, so will our API gateway call, and our users will have to wait for their exchange rate to appear on the website. Perhaps they will even end up seeing a timeout error instead of the USD to GBP rate that they expect. So what can we do?

Using CloudWatch we can monitor the latency of this endpoint, and set up an alarm to trigger when the external API begins to respond slowly. Head over to the CloudWatch Management Console and create a new alarm for the *latency* metric on our API Gateway resource, as shown in [Figure 7-13](#Figure-7-13).

###### Warning

You may need to enable “Detailed route metrics” in API Gateway to get the latency for each route as shown in [Figure 7-13](#Figure-7-13).

![doac 0713](assets/doac_0713.png)

###### Figure 7-13\. Configuring a new alarm on the latency of our API Gateway resource

For the notification action of our alarm, we will set up an SNS topic and link it to a Lambda function called `TriggerCircuitBreaker`. We will create this Lambda function next.

## Breaking the Circuit

Now we have a way to detect the external API’s latency increasing, we need to decide what to do to keep our application running. For our example website, we have made the business decision that in the event that the exchange rate lookup API is not responding quickly enough we will return a *cached* exchange rate from our distributed memory cache. Perhaps we have another Lambda function that runs on a schedule and saves the current exchange rate to this cache periodically. For our distributed cache we can use [Amazon ElastiCache](https://aws.amazon.com/elasticache), which allows us to use both Redis and Memcached, two extremely popular open source in-memory stores. In [Figure 7-14](#Figure-7-14), you can see we have configured our API Gateway with a second “fallback” integration that invokes a Lambda function to retrieve the most recent exchange rate from the cache.

![doac 0714](assets/doac_0714.png)

###### Figure 7-14\. Additional AWS Lambda integration added into API Gateway as a fallback

Our circuit breaker could operate by detecting high latency on the third-party API and switching our API Gateway to use this fallback integration. This would not affect our website as the API calls from the frontend are still coming into the gateway, but instead of proxying those calls to our third-party service, we will be sending them to the Lambda function `GetCachedExchangeRate`.

Making this switch in API Gateway can be done from a simple C# Lambda function, using the `AmazonApiGatewayV2Client` from the NuGet package AWSSDK.ApiGatewayV2:

[PRE10]

Here we have hardcoded the IDs for our API Gateway instance, route, and integration; however, these could of course be read in from environment variables or looked up at runtime using methods on the `AmazonApiGatewayV2Client`.

## Resetting the Tripped State

What we have achieved here through switching the integration in API Gateway is we have provided our users with *some* information on the website. It may not be the latest exchange rate but it should be recent enough and, crucially, we have guarded against an unpredictably slow third-party API. The next thing to consider is how we reset our circuit breaker when the API is no longer experiencing high latency.

The circuit breaker pattern offers a solution for resetting once the initial condition has been resolved, and that is by periodically testing our external API in what the pattern calls a “half open state.” We can create yet another Lambda function to do this:

[PRE11]

Here we have a function that makes the API call to our third-party exchange rate API and measures the response time. This is then sent back to CloudWatch as a custom metric called “ExchangeRateProbeLatency.” We can then set up a second alarm to track this new metric using a *Lower than* threshold. In the alarm configuration window in CloudWatch, there is also a “Datapoints to alarm” setting that we can take advantage of. Setting this (shown in [Figure 7-15](#Figure-7-15)) will result in our alarm being triggered if 10 API calls to our probe fall below our maximum allowed latency.

![doac 0715](assets/doac_0715.png)

###### Figure 7-15\. Datapoints to alarm configuration

Finally, here is our entire example as a flow diagram in [Figure 7-16](#Figure-7-16). We are using an EventBridge rule to schedule calling the `ProbeExchangeRateEndpoint` Lambda function until the latency has reduced back down to an acceptable level.

![doac 0716](assets/doac_0716.png)

###### Figure 7-16\. Flowchart of our circuit breaker with probing and reset

# Conclusion

No system is architected or configured to perfection. Systems evolve over time and as the scale of your application changes you will need to make changes to the way your services talk to each other. This is especially true for growing systems that start small with only a handful of users, and grow, sometimes exponentially, to serve thousands of users all across the world. Architectural decisions that made sense when an application was small can end up hindering performance as adoption increases. You will also learn more about the usage patterns of your services as you scale as more users provide more detailed insight into how your application is used and where the bottlenecks will emerge.

It is therefore vitally important to have logging, monitoring, and instrumentation in place so you can observe these changes happening and respond to them quickly, efficiently, and with the greatest amount of useful data at your disposal. For operations engineers, site reliability engineers, DevOps, and security engineers, AWS CloudWatch is an extremely powerful set of tools that can give you the data you need if some time is invested in getting the most out of it.

For the final chapter of this book, we are going to be jumping back into our application code and exploring more deeply the AWS SDK for .NET. We will also be looking at some of the tooling for Visual Studio that can make interacting with AWS feel much more natural and integrated with your development workflow.

# Critical Thinking Discussion Questions

*   Why would an engineering manager say logging, monitoring, and instrumentation are essential to software engineering?

*   What is another way to describe the four pillars of AWS CloudWatch?

*   What are the three of four most important metrics you should look at when building and deploying AWS Lambda services?

*   What real-world problems does a service like X-Ray solve?

*   How could security auditing using AWS CloudTrail help prevent a ransomware attack at your company?

# Exercises

*   Build a C# Console App that queries AWS CloudTrail.

*   Write custom CloudWatch logging into an AWS CodeBuild job that builds a .NET project.

*   Log the incoming API Gateway `POST` requests for a .NET web service to AWS CloudTrail.

*   Log the incoming Elastic Beanstalk `POST` requests for a .NET web service to AWS CloudTrail.

*   Build a C# Console App that finds anomalies in AWS CloudTrail events.

^([1](ch07.xhtml#idm45599651192176-marker)) The weight of the riders can greatly affect the speed of a roller coaster car under gravity. If you see four grown adults in a kiddie roller coaster car it might look funny, but the increased momentum that car will have coming back into the station can really test the strength of the braking system.

^([2](ch07.xhtml#idm45599651136560-marker)) Despite being called “AWSLambdaBasicExecutionRole,” this is actually not a role but a *policy*—a permissions set that can be applied to a role to grant or deny access to certain resources.

^([3](ch07.xhtml#idm45599651054496-marker)) The IAsyncDisposable interface was introduced in C# 8.0 and allows us to call asynchronous code in a `DisposeAsync()` method by adding “await” before our “using” statement.

^([4](ch07.xhtml#idm45599650581152-marker)) AWSSDK.CloudWatch and AWSSDK.CloudWatchLogs are two different packages with different clients; you will need both of these packages if you need to publish custom log messages *and* custom metric data points to CloudWatch.

^([5](ch07.xhtml#idm45599650100960-marker)) Service Map was previously accessed through a product AWS calls “Service Lens,” so you may find it referenced as a part of that in documentation online.

^([6](ch07.xhtml#idm45599650082128-marker)) You can view up to 500 hosts in one view using the Resource Health window.

^([7](ch07.xhtml#idm45599650080256-marker)) The term “canary” has a rather dark past. In the days before electronic gas detectors, and indeed also before animal welfare rights, canary birds would be taken into coal mines in a cage and hung up in the area being worked in. If the bird succumbed to toxic fumes down in the mine, the workers would notice the expiry of the poor bird and take it as a sign to raise the alarm and evacuate.